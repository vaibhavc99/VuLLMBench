model,precision,recall,f1-score
o3-mini,0.842140921409214,0.8784452296819788,0.8599100657212038
gpt5-mini-reasoning,0.7598204264870931,0.9568904593639576,0.8470441038473568
gpt5-reasoning,0.7515118196811434,0.9660777385159011,0.8453927025355596
gpt5,0.6159712875729026,0.9703180212014134,0.7535675082327113
gpt5-mini,0.5756457564575646,0.992226148409894,0.7285936689154126
gpt4o-mini,0.5504807692307693,0.9710247349823321,0.7026335975453848
gpt4o,0.533940083428138,0.995053003533569,0.6949654491609082
llama3.1-70b,0.5589028776978417,0.8784452296819788,0.683154712833196
llama3.1-8b,0.5145631067961165,0.9738515901060071,0.6733447349132665
codellama-70b,0.5175097276264592,0.9399293286219081,0.6675031367628608
deepcoder-14b,0.6512890094979648,0.6784452296819788,0.6645898234683282
gemma2-9b,0.5332190312901843,0.8791519434628975,0.663820704375667
deepseek-coder-v2-16b,0.527672158850866,0.8826855123674912,0.6604970914859862
phi3-14b,0.5492890995260663,0.8190812720848056,0.6575886524822695
mixtral-8x22b,0.5732954545454545,0.7130742049469965,0.6355905511811024
codegemma-7b,0.5737398879900436,0.6515901060070671,0.6101919258769027
qwen2-72b,0.5741595253790376,0.615547703180212,0.5941336971350614
qwen3coder-30b,0.5671641791044776,0.5639575971731449,0.5655563430191354
mixtral-8x7b,0.5726172465960666,0.5349823321554771,0.5531603945926197
gemma2-27b,0.6314699792960663,0.43109540636042404,0.5123897522049559
granite3.3-8b,0.5641025641025641,0.2954063604240283,0.3877551020408163
mistral-nemo-12b,0.5898959881129272,0.280565371024735,0.38026819923371646
qwen2-7b,0.5982905982905983,0.24734982332155478,0.35
gpt3.5-turbo,0.6044303797468354,0.13498233215547703,0.22068168688619294