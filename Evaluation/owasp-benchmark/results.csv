model,precision,recall,f1-score
gpt5-reasoning,0.7803790412486065,0.9893992932862191,0.8725459644749143
o3-mini,0.8201669877970456,0.9024734982332155,0.8593539703903096
gpt5-mini-reasoning,0.7238449283058949,0.9632508833922262,0.8265615524560339
gpt5,0.611062335381914,0.9837455830388693,0.7538586515028433
gpt4o,0.5851636966431828,0.9978798586572438,0.7377220480668757
deepcoder-14b,0.7003968253968254,0.7484098939929329,0.7236077895456099
llama3.1-70b,0.5734858110969928,0.9568904593639576,0.7171610169491526
gpt5-mini,0.5382565664255805,0.9992932862190813,0.6996536368134587
gpt4o-mini,0.5403194390338917,0.9802120141342756,0.6966348568558514
gpt3.5-turbo,0.5403194390338917,0.9802120141342756,0.6966348568558514
gemma2-9b,0.5268494179496808,0.9915194346289753,0.6880823933300637
codegemma-7b,0.5720358998582901,0.8558303886925795,0.6857304643261608
phi3-14b,0.5334928229665071,0.945583038869258,0.6821310221769055
codellama-70b,0.5186150409530901,0.984452296819788,0.6793465008534504
deepseek-coder-v2-16b,0.5169741697416974,0.9901060070671378,0.6792727272727273
qwen3coder-30b,0.5870488322717622,0.781625441696113,0.6705062140042437
qwen2-72b,0.5884931506849315,0.7590106007067138,0.662962962962963
llama3.1-8b,0.5275523280649295,0.872791519434629,0.6576144834930777
mixtral-8x22b,0.5623721881390593,0.7773851590106007,0.6526253337288639
mixtral-8x7b,0.5910194174757282,0.688339222614841,0.6359777995429318
gemma2-27b,0.5866141732283464,0.6318021201413427,0.6083701939435182
granite3.3-8b,0.6136701337295691,0.5837455830388693,0.5983339369793553
mistral-nemo-12b,0.588897827835881,0.5173144876325089,0.5507900677200903
qwen2-7b,0.5529411764705883,0.3321554770318021,0.41501103752759383