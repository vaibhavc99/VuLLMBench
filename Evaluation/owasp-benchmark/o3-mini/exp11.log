2025-08-14 11:23:18,353 - VuLLMBench - INFO - Experiment exp11 started...
2025-08-14 11:23:18,398 - Controller - INFO - Loaded 2740 examples from the owasp dataset.
2025-08-14 11:23:19,096 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:19,096 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:19,101 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:19,101 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:19,107 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:19,107 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:19,107 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:19,107 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:19,110 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:19,110 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:19,113 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:19,113 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:19,114 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:19,114 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:19,114 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:19,114 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:19,171 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:19,171 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:19,177 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:19,177 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:21,138 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:21,138 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:21,142 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:21,142 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:21,147 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:21,147 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:21,154 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:21,155 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:21,155 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:21,155 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:21,157 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:21,157 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:21,165 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:21,165 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:21,165 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:21,165 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:21,213 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:21,213 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:21,217 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:21,217 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:23,181 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:23,181 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:23,182 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:23,182 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:23,194 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:23,194 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:23,198 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:23,198 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:23,203 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:23,203 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:23,206 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:23,206 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:23,207 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:23,207 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:23,215 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:23,215 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:23,255 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:23,255 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:23,257 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:23,257 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:25,223 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:25,223 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:25,224 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:25,224 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:25,240 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:25,240 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:25,246 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:25,247 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:25,247 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:25,247 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:25,250 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:25,250 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:25,254 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:25,254 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:25,256 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:25,256 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:25,297 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:25,297 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:25,297 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:25,297 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:27,266 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:27,266 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:27,266 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:27,266 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:27,285 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:27,285 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:27,291 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:27,291 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:27,292 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:27,292 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:27,296 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:27,297 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:27,297 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:27,297 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:27,304 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:27,304 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:27,339 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:27,339 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:27,348 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:27,348 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:29,308 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:29,309 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:29,309 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:29,309 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:29,329 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:29,329 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:29,337 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:29,337 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:29,338 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:29,338 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:29,341 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:29,341 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:29,344 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:29,344 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:29,347 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:29,347 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:29,381 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:29,381 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:29,388 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:29,388 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:31,352 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:31,352 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:31,352 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:31,352 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:31,376 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:31,376 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:31,382 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:31,382 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:31,383 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:31,384 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:31,386 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:31,386 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:31,387 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:31,387 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:31,395 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:31,395 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:31,422 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:31,422 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:31,428 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:31,428 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:33,395 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:33,395 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:33,397 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:33,397 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:33,421 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:33,421 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:33,426 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:33,426 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:33,426 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:33,426 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:33,432 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:33,432 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:33,437 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:33,437 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:33,440 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:33,440 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:33,462 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:33,462 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:33,465 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:33,465 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:35,437 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:35,438 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:35,439 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:35,439 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:35,473 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:35,473 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:35,477 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:35,477 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:35,478 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:35,478 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:35,480 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:35,480 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:35,484 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:35,484 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:35,501 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:35,501 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:35,505 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:35,505 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:35,514 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:35,514 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:37,482 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:37,483 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:37,483 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:37,483 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:37,516 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:37,516 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:37,523 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:37,524 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:37,524 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:37,524 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:37,529 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:37,529 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:37,533 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:37,534 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:37,541 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:37,541 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:37,544 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:37,544 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:23:37,554 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:23:37,555 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:03,500 - VuLLMBench - INFO - Experiment exp11 started...
2025-08-14 11:24:03,516 - Controller - INFO - Loaded 2740 examples from the owasp dataset.
2025-08-14 11:24:04,128 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:04,128 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:04,133 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:04,134 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:04,134 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:04,134 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:04,148 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:04,148 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:04,152 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:04,152 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:04,152 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:04,152 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:04,155 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:04,155 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:04,159 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:04,160 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:04,161 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:04,161 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:04,199 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:04,199 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:06,170 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:06,170 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:06,176 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:06,176 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:06,183 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:06,183 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:06,192 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:06,192 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:06,201 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:06,201 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:06,201 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:06,201 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:06,203 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:06,203 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:06,206 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:06,206 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:06,240 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:06,240 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:06,260 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:06,260 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:08,212 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:08,212 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:08,224 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:08,224 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:08,241 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:08,242 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:08,243 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:08,243 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:08,250 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:08,250 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:08,252 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:08,252 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:08,253 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:08,253 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:08,262 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:08,262 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:08,282 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:08,282 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:08,308 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:08,308 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:10,255 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:10,255 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:10,274 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:10,274 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:10,290 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:10,290 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:10,292 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:10,293 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:10,293 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:10,293 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:10,296 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:10,296 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:10,301 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:10,301 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:10,303 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:10,303 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:10,330 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:10,330 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:10,349 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:10,349 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:12,298 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:12,298 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:12,322 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:12,322 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:12,331 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:12,332 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:12,338 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:12,338 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:12,339 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:12,339 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:12,341 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:12,341 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:12,341 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:12,341 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:12,351 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:12,351 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:12,378 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:12,378 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:12,391 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:12,391 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:14,340 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:14,341 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:14,370 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:14,370 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:14,373 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:14,373 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:14,381 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:14,381 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:14,382 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:14,382 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:14,386 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:14,386 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:14,388 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:14,388 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:14,399 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:14,399 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:14,426 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:14,426 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:14,470 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:14,470 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:16,385 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:16,385 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:16,413 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:16,413 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:16,418 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:16,418 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:16,426 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:16,426 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:16,428 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:16,428 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:16,429 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:16,429 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:16,430 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:16,430 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:16,447 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:16,447 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:16,474 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:16,474 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:16,511 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:24:16,511 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:24:36,935 - VuLLMBench - INFO - Experiment exp11 started...
2025-08-14 11:24:36,952 - Controller - INFO - Loaded 2740 examples from the owasp dataset.
2025-08-14 11:24:37,615 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,615 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,617 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,617 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00001
2025-08-14 11:24:37,617 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,619 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00002
2025-08-14 11:24:37,627 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,627 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,628 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00003
2025-08-14 11:24:37,632 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,633 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,643 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,644 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,644 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,644 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,656 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,656 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,677 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,677 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,682 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,682 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,683 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00004
2025-08-14 11:24:37,695 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,696 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,697 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00005
2025-08-14 11:24:37,697 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00006
2025-08-14 11:24:37,697 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00007
2025-08-14 11:24:37,698 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,698 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00008
2025-08-14 11:24:37,698 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,698 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00009
2025-08-14 11:24:37,700 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,700 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,713 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,713 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,715 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,715 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,716 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,716 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,718 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00010
2025-08-14 11:24:37,718 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00011
2025-08-14 11:24:37,718 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00012
2025-08-14 11:24:37,718 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00013
2025-08-14 11:24:37,718 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00014
2025-08-14 11:24:37,720 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,720 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,721 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00015
2025-08-14 11:24:37,721 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00016
2025-08-14 11:24:37,729 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,729 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,730 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00017
2025-08-14 11:24:37,740 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,740 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,741 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00018
2025-08-14 11:24:37,753 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,753 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,754 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00019
2025-08-14 11:24:37,766 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,766 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,768 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,768 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,781 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,781 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,793 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,793 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,797 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,797 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,797 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,797 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,799 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00020
2025-08-14 11:24:37,800 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00021
2025-08-14 11:24:37,800 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00022
2025-08-14 11:24:37,800 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00023
2025-08-14 11:24:37,800 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00024
2025-08-14 11:24:37,803 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,803 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,804 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,804 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,821 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,821 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,833 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,833 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,834 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00025
2025-08-14 11:24:37,835 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00026
2025-08-14 11:24:37,835 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00027
2025-08-14 11:24:37,835 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00028
2025-08-14 11:24:37,835 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00029
2025-08-14 11:24:37,840 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,840 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,857 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,857 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,858 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00030
2025-08-14 11:24:37,858 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00031
2025-08-14 11:24:37,860 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,860 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,861 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00032
2025-08-14 11:24:37,869 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,870 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,870 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,870 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,872 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00033
2025-08-14 11:24:37,873 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,874 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,875 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00034
2025-08-14 11:24:37,878 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,878 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,885 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,885 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,887 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,887 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,888 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00035
2025-08-14 11:24:37,888 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00036
2025-08-14 11:24:37,888 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00037
2025-08-14 11:24:37,888 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00038
2025-08-14 11:24:37,912 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,912 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,924 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,924 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,928 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,929 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,930 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00039
2025-08-14 11:24:37,930 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00040
2025-08-14 11:24:37,930 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00041
2025-08-14 11:24:37,930 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,930 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,932 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00042
2025-08-14 11:24:37,939 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,940 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,941 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00043
2025-08-14 11:24:37,942 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,942 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,944 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00044
2025-08-14 11:24:37,951 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,951 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,958 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,958 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,960 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,960 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,961 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00045
2025-08-14 11:24:37,961 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00046
2025-08-14 11:24:37,961 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00047
2025-08-14 11:24:37,976 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,976 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,977 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00048
2025-08-14 11:24:37,995 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:37,995 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:37,999 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,000 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,004 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,004 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,006 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,006 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,019 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,019 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,021 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,021 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,031 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,031 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,035 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,035 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,060 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,060 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,062 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,062 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,068 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,068 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,074 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,074 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,080 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,080 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,081 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00049
2025-08-14 11:24:38,081 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00050
2025-08-14 11:24:38,081 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00051
2025-08-14 11:24:38,081 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00052
2025-08-14 11:24:38,081 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00053
2025-08-14 11:24:38,081 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00054
2025-08-14 11:24:38,081 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00055
2025-08-14 11:24:38,082 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00056
2025-08-14 11:24:38,082 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00057
2025-08-14 11:24:38,082 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00058
2025-08-14 11:24:38,082 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00059
2025-08-14 11:24:38,082 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00060
2025-08-14 11:24:38,082 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00061
2025-08-14 11:24:38,085 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,085 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,086 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,086 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,088 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00062
2025-08-14 11:24:38,093 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,093 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,094 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00063
2025-08-14 11:24:38,094 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00064
2025-08-14 11:24:38,112 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,112 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,125 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,125 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,127 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00065
2025-08-14 11:24:38,127 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00066
2025-08-14 11:24:38,130 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,130 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,137 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,137 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,142 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,143 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,156 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,156 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,158 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,158 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,160 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,160 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,162 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00067
2025-08-14 11:24:38,162 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00068
2025-08-14 11:24:38,162 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00069
2025-08-14 11:24:38,162 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00070
2025-08-14 11:24:38,162 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00071
2025-08-14 11:24:38,162 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00072
2025-08-14 11:24:38,163 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,163 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,164 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00073
2025-08-14 11:24:38,173 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,173 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,174 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00074
2025-08-14 11:24:38,195 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,195 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,196 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00075
2025-08-14 11:24:38,201 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,201 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,215 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,216 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,217 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,217 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00076
2025-08-14 11:24:38,218 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,218 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00077
2025-08-14 11:24:38,219 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00078
2025-08-14 11:24:38,222 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,222 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,230 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,231 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,231 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,231 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,232 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00079
2025-08-14 11:24:38,233 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00080
2025-08-14 11:24:38,241 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,241 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,243 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,243 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00081
2025-08-14 11:24:38,243 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00082
2025-08-14 11:24:38,243 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,244 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00083
2025-08-14 11:24:38,259 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,259 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,260 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00084
2025-08-14 11:24:38,270 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,270 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,274 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,274 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,275 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00085
2025-08-14 11:24:38,275 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00086
2025-08-14 11:24:38,288 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,289 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,291 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,291 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,292 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00087
2025-08-14 11:24:38,293 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,293 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,294 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00088
2025-08-14 11:24:38,294 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00089
2025-08-14 11:24:38,297 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,297 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,298 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00090
2025-08-14 11:24:38,301 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,301 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,302 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00091
2025-08-14 11:24:38,319 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,319 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,326 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,327 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,328 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00092
2025-08-14 11:24:38,328 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00093
2025-08-14 11:24:38,333 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,333 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,334 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00094
2025-08-14 11:24:38,340 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,340 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,342 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00095
2025-08-14 11:24:38,350 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,350 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,351 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00096
2025-08-14 11:24:38,354 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,354 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,355 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00097
2025-08-14 11:24:38,362 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,362 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,363 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00098
2025-08-14 11:24:38,366 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,366 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,370 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,370 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,371 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,372 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,373 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00099
2025-08-14 11:24:38,373 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00100
2025-08-14 11:24:38,373 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00101
2025-08-14 11:24:38,395 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,395 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,396 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00102
2025-08-14 11:24:38,408 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,408 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,413 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,413 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,414 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00103
2025-08-14 11:24:38,414 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00104
2025-08-14 11:24:38,416 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,416 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,417 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00105
2025-08-14 11:24:38,432 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,432 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,433 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,433 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,435 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,435 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,441 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,442 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,442 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,442 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,443 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00106
2025-08-14 11:24:38,445 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00107
2025-08-14 11:24:38,445 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00108
2025-08-14 11:24:38,445 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00109
2025-08-14 11:24:38,445 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00110
2025-08-14 11:24:38,452 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,452 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,453 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00111
2025-08-14 11:24:38,471 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,471 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,472 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00112
2025-08-14 11:24:38,479 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,479 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,480 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00113
2025-08-14 11:24:38,485 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,485 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,501 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,501 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,503 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,503 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,504 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00114
2025-08-14 11:24:38,504 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00115
2025-08-14 11:24:38,504 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00116
2025-08-14 11:24:38,505 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,505 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,508 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,509 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,509 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,509 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,511 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00117
2025-08-14 11:24:38,511 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00118
2025-08-14 11:24:38,512 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00119
2025-08-14 11:24:38,519 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,519 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,520 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00120
2025-08-14 11:24:38,522 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,522 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,523 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00121
2025-08-14 11:24:38,552 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,553 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,553 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,553 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,554 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00122
2025-08-14 11:24:38,556 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,556 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00123
2025-08-14 11:24:38,556 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,558 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00124
2025-08-14 11:24:38,568 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,568 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,573 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,573 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,577 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,577 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,578 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00125
2025-08-14 11:24:38,581 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,581 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,588 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,588 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,589 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00126
2025-08-14 11:24:38,590 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00127
2025-08-14 11:24:38,590 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00128
2025-08-14 11:24:38,590 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00129
2025-08-14 11:24:38,595 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,595 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,623 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,623 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,637 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,637 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,638 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,638 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,640 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,640 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,646 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,646 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,653 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,654 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,654 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,654 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,655 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,655 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,659 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00130
2025-08-14 11:24:38,659 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00131
2025-08-14 11:24:38,659 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00132
2025-08-14 11:24:38,659 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00133
2025-08-14 11:24:38,659 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00134
2025-08-14 11:24:38,659 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00135
2025-08-14 11:24:38,659 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00136
2025-08-14 11:24:38,659 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00137
2025-08-14 11:24:38,659 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00138
2025-08-14 11:24:38,669 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,669 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,684 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,684 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,686 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00139
2025-08-14 11:24:38,686 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00140
2025-08-14 11:24:38,693 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,693 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,694 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00141
2025-08-14 11:24:38,711 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,711 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,712 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,713 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,723 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,723 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,724 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00142
2025-08-14 11:24:38,725 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,725 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,726 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,726 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,730 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,731 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,743 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,744 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,744 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,744 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,746 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00143
2025-08-14 11:24:38,746 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00144
2025-08-14 11:24:38,746 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00145
2025-08-14 11:24:38,746 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00146
2025-08-14 11:24:38,746 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00147
2025-08-14 11:24:38,746 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00148
2025-08-14 11:24:38,747 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00149
2025-08-14 11:24:38,765 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,765 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,769 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,769 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,770 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00150
2025-08-14 11:24:38,770 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00151
2025-08-14 11:24:38,775 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,775 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,776 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00152
2025-08-14 11:24:38,779 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,779 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,780 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00153
2025-08-14 11:24:38,791 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,792 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,792 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,792 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,794 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00154
2025-08-14 11:24:38,804 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,804 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,805 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00155
2025-08-14 11:24:38,805 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00156
2025-08-14 11:24:38,808 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,808 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,809 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,809 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00157
2025-08-14 11:24:38,809 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,811 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00158
2025-08-14 11:24:38,820 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,821 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,822 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00159
2025-08-14 11:24:38,836 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,836 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,837 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00160
2025-08-14 11:24:38,847 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,847 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,856 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,856 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,858 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,858 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,859 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00161
2025-08-14 11:24:38,859 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00162
2025-08-14 11:24:38,860 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00163
2025-08-14 11:24:38,860 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,860 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,866 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,867 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,868 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00164
2025-08-14 11:24:38,868 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00165
2025-08-14 11:24:38,878 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,878 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,886 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,886 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,887 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,887 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,889 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00166
2025-08-14 11:24:38,889 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00167
2025-08-14 11:24:38,889 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00168
2025-08-14 11:24:38,903 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,903 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,904 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00169
2025-08-14 11:24:38,911 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,911 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,916 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,916 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,917 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00170
2025-08-14 11:24:38,917 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00171
2025-08-14 11:24:38,921 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,921 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,922 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00172
2025-08-14 11:24:38,931 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,931 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,940 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,940 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,940 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,940 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,943 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00173
2025-08-14 11:24:38,943 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00174
2025-08-14 11:24:38,943 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00175
2025-08-14 11:24:38,944 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,944 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,945 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00176
2025-08-14 11:24:38,964 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,964 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,965 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00177
2025-08-14 11:24:38,972 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,972 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,973 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00178
2025-08-14 11:24:38,986 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,986 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,987 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,987 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00179
2025-08-14 11:24:38,988 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:38,988 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,989 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:38,990 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00180
2025-08-14 11:24:39,001 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,001 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,005 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,005 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,013 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,013 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,017 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,017 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,018 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00181
2025-08-14 11:24:39,018 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00182
2025-08-14 11:24:39,018 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00183
2025-08-14 11:24:39,018 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00184
2025-08-14 11:24:39,026 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,026 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,027 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00185
2025-08-14 11:24:39,027 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00186
2025-08-14 11:24:39,041 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,042 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,042 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,042 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,044 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00187
2025-08-14 11:24:39,044 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00188
2025-08-14 11:24:39,053 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,053 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,055 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,055 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,071 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,071 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,074 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,074 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,074 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,074 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,077 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00189
2025-08-14 11:24:39,077 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00190
2025-08-14 11:24:39,077 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00191
2025-08-14 11:24:39,077 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00192
2025-08-14 11:24:39,077 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00193
2025-08-14 11:24:39,081 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,081 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,082 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00194
2025-08-14 11:24:39,089 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,089 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,090 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00195
2025-08-14 11:24:39,112 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,112 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,114 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00196
2025-08-14 11:24:39,119 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,120 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,120 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,120 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,122 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00197
2025-08-14 11:24:39,123 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,123 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,127 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,127 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,128 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00198
2025-08-14 11:24:39,128 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00199
2025-08-14 11:24:39,128 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00200
2025-08-14 11:24:39,142 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,142 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,148 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,148 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,149 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,149 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,151 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00201
2025-08-14 11:24:39,151 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,151 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00202
2025-08-14 11:24:39,151 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,153 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00203
2025-08-14 11:24:39,153 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00204
2025-08-14 11:24:39,165 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,165 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,166 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00205
2025-08-14 11:24:39,189 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,189 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,195 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,195 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,197 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00206
2025-08-14 11:24:39,200 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,201 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,202 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,202 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,210 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,210 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,211 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00207
2025-08-14 11:24:39,212 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00208
2025-08-14 11:24:39,212 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00209
2025-08-14 11:24:39,212 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00210
2025-08-14 11:24:39,216 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,216 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,216 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,216 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,219 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00211
2025-08-14 11:24:39,219 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00212
2025-08-14 11:24:39,223 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,223 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,224 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00213
2025-08-14 11:24:39,234 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,234 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,235 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00214
2025-08-14 11:24:39,237 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,237 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,238 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00215
2025-08-14 11:24:39,254 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,254 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,255 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00216
2025-08-14 11:24:39,265 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,266 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,280 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,280 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,281 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00217
2025-08-14 11:24:39,284 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,284 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,286 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,286 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,291 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,291 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,293 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,293 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,294 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00218
2025-08-14 11:24:39,294 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00219
2025-08-14 11:24:39,294 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00220
2025-08-14 11:24:39,294 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00221
2025-08-14 11:24:39,294 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00222
2025-08-14 11:24:39,299 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,299 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,300 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00223
2025-08-14 11:24:39,308 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,308 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,319 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,319 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,320 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00224
2025-08-14 11:24:39,321 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00225
2025-08-14 11:24:39,324 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,324 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,325 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00226
2025-08-14 11:24:39,329 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,329 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,330 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00227
2025-08-14 11:24:39,354 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,354 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,363 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,363 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,363 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,364 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,366 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,367 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,368 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,368 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,369 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,369 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00228
2025-08-14 11:24:39,370 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00229
2025-08-14 11:24:39,370 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00230
2025-08-14 11:24:39,370 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00231
2025-08-14 11:24:39,370 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,371 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00232
2025-08-14 11:24:39,372 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00233
2025-08-14 11:24:39,378 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,378 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,379 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00234
2025-08-14 11:24:39,392 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,392 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,393 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,393 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,421 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,421 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,436 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,436 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,441 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,441 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,442 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,442 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,448 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,449 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,449 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,449 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,451 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00235
2025-08-14 11:24:39,451 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00236
2025-08-14 11:24:39,451 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00237
2025-08-14 11:24:39,451 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00238
2025-08-14 11:24:39,451 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00239
2025-08-14 11:24:39,451 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00240
2025-08-14 11:24:39,455 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,455 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,456 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00241
2025-08-14 11:24:39,456 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00242
2025-08-14 11:24:39,460 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,460 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,462 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00243
2025-08-14 11:24:39,462 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00244
2025-08-14 11:24:39,463 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,463 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,464 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00245
2025-08-14 11:24:39,465 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,465 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,466 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00246
2025-08-14 11:24:39,489 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,489 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,490 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00247
2025-08-14 11:24:39,504 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,504 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,505 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00248
2025-08-14 11:24:39,518 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,518 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,520 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,520 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,526 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,526 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,529 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,529 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,532 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,532 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,535 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,535 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,545 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,545 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,546 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00249
2025-08-14 11:24:39,547 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,547 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00250
2025-08-14 11:24:39,547 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,547 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00251
2025-08-14 11:24:39,548 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00252
2025-08-14 11:24:39,548 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00253
2025-08-14 11:24:39,548 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00254
2025-08-14 11:24:39,548 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00255
2025-08-14 11:24:39,548 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00256
2025-08-14 11:24:39,556 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,556 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,557 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00257
2025-08-14 11:24:39,571 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,571 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,572 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00258
2025-08-14 11:24:39,590 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,591 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,592 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00259
2025-08-14 11:24:39,594 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,594 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,596 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,596 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,597 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00260
2025-08-14 11:24:39,606 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,606 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,609 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,609 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,610 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,610 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00261
2025-08-14 11:24:39,610 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,611 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00262
2025-08-14 11:24:39,612 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00263
2025-08-14 11:24:39,612 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00264
2025-08-14 11:24:39,623 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,623 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,626 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,626 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,627 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00265
2025-08-14 11:24:39,632 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,632 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,633 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00266
2025-08-14 11:24:39,633 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00267
2025-08-14 11:24:39,642 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,642 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,643 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00268
2025-08-14 11:24:39,662 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,662 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,663 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,663 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,669 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,669 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,670 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00269
2025-08-14 11:24:39,670 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00270
2025-08-14 11:24:39,670 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00271
2025-08-14 11:24:39,675 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,675 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,677 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,677 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,678 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00272
2025-08-14 11:24:39,689 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,689 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,698 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,698 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,700 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,700 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,701 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00273
2025-08-14 11:24:39,701 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00274
2025-08-14 11:24:39,701 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00275
2025-08-14 11:24:39,701 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00276
2025-08-14 11:24:39,714 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,714 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,725 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,725 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,732 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,733 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,733 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,733 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,735 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00277
2025-08-14 11:24:39,735 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00278
2025-08-14 11:24:39,735 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00279
2025-08-14 11:24:39,735 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00280
2025-08-14 11:24:39,741 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,741 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,743 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,743 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,744 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00281
2025-08-14 11:24:39,747 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,747 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,748 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00282
2025-08-14 11:24:39,748 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00283
2025-08-14 11:24:39,756 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,756 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,757 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00284
2025-08-14 11:24:39,770 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,770 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,771 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00285
2025-08-14 11:24:39,775 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,775 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,776 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00286
2025-08-14 11:24:39,792 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,792 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,794 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,794 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,795 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00287
2025-08-14 11:24:39,795 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00288
2025-08-14 11:24:39,806 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,806 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,812 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,812 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,817 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,817 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,818 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00289
2025-08-14 11:24:39,818 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,818 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00290
2025-08-14 11:24:39,819 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,819 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00291
2025-08-14 11:24:39,820 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00292
2025-08-14 11:24:39,821 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,821 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,844 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,844 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,854 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,854 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,864 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,864 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,868 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,868 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,877 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,877 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,885 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,885 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,886 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,887 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,894 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,894 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,910 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,910 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,923 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,923 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,930 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,930 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,935 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,935 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,941 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,941 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,954 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,954 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,957 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,957 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,966 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,966 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,989 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,989 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,992 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,992 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:39,998 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:39,998 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,000 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,000 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,004 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,004 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,021 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,021 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,032 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,032 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,035 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,035 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,041 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,041 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,069 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,069 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,071 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,071 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,072 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,073 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,074 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,074 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,076 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,076 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,077 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00293
2025-08-14 11:24:40,077 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00294
2025-08-14 11:24:40,077 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00295
2025-08-14 11:24:40,077 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00296
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00297
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00298
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00299
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00300
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00301
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00302
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00303
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00304
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00305
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00306
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00307
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00308
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00309
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00310
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00311
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00312
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00313
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00314
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00315
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00316
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00317
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00318
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00319
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00320
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00321
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00322
2025-08-14 11:24:40,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00323
2025-08-14 11:24:40,082 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,082 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,083 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00324
2025-08-14 11:24:40,096 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,096 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,097 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00325
2025-08-14 11:24:40,111 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,111 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,112 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00326
2025-08-14 11:24:40,126 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,127 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,127 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,127 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,129 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00327
2025-08-14 11:24:40,129 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00328
2025-08-14 11:24:40,139 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,139 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,140 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00329
2025-08-14 11:24:40,145 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,145 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,147 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00330
2025-08-14 11:24:40,152 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,152 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,154 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,154 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,160 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,160 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,161 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00331
2025-08-14 11:24:40,161 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00332
2025-08-14 11:24:40,161 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00333
2025-08-14 11:24:40,167 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,167 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,168 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00334
2025-08-14 11:24:40,182 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,182 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,183 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00335
2025-08-14 11:24:40,184 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,184 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,185 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00336
2025-08-14 11:24:40,205 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,205 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,214 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,215 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,215 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,215 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,217 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,218 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00337
2025-08-14 11:24:40,218 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,219 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00338
2025-08-14 11:24:40,220 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00339
2025-08-14 11:24:40,220 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00340
2025-08-14 11:24:40,226 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,226 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,232 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,232 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,238 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,238 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,239 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00341
2025-08-14 11:24:40,239 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00342
2025-08-14 11:24:40,254 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,254 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,263 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,263 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,264 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00343
2025-08-14 11:24:40,265 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00344
2025-08-14 11:24:40,270 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,270 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,272 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,272 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,273 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00345
2025-08-14 11:24:40,273 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00346
2025-08-14 11:24:40,273 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00347
2025-08-14 11:24:40,285 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,285 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,291 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,292 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,295 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,295 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,303 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,303 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,304 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00348
2025-08-14 11:24:40,305 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00349
2025-08-14 11:24:40,312 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,312 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,313 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00350
2025-08-14 11:24:40,313 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00351
2025-08-14 11:24:40,313 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00352
2025-08-14 11:24:40,328 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,329 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,329 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,329 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,330 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00353
2025-08-14 11:24:40,332 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00354
2025-08-14 11:24:40,337 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,337 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,351 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,351 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,352 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00355
2025-08-14 11:24:40,352 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00356
2025-08-14 11:24:40,356 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,356 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,357 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00357
2025-08-14 11:24:40,359 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,359 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,360 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00358
2025-08-14 11:24:40,362 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,362 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,365 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,365 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,366 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00359
2025-08-14 11:24:40,366 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00360
2025-08-14 11:24:40,391 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,391 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,392 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00361
2025-08-14 11:24:40,404 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,404 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,410 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,411 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,412 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,412 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00362
2025-08-14 11:24:40,412 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,420 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,420 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,421 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00363
2025-08-14 11:24:40,421 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00364
2025-08-14 11:24:40,421 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00365
2025-08-14 11:24:40,427 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,427 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,428 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,429 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00366
2025-08-14 11:24:40,427 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,431 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,431 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,432 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,432 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00367
2025-08-14 11:24:40,433 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,434 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,433 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00368
2025-08-14 11:24:40,433 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,435 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00369
2025-08-14 11:24:40,436 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00370
2025-08-14 11:24:40,479 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,479 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,481 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,481 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,482 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00371
2025-08-14 11:24:40,486 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,486 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,489 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,489 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,496 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,496 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,499 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,499 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,501 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,501 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,503 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,503 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,504 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00372
2025-08-14 11:24:40,504 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00373
2025-08-14 11:24:40,504 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00374
2025-08-14 11:24:40,504 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00375
2025-08-14 11:24:40,509 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,509 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,510 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00376
2025-08-14 11:24:40,511 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,511 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,512 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00377
2025-08-14 11:24:40,512 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00378
2025-08-14 11:24:40,512 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00379
2025-08-14 11:24:40,512 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00380
2025-08-14 11:24:40,544 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,544 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,545 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00381
2025-08-14 11:24:40,562 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,562 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,563 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,564 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,564 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,564 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,565 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,567 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,568 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00382
2025-08-14 11:24:40,568 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00383
2025-08-14 11:24:40,569 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00384
2025-08-14 11:24:40,569 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,570 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,570 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,570 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,570 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00385
2025-08-14 11:24:40,572 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00386
2025-08-14 11:24:40,572 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00387
2025-08-14 11:24:40,579 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,580 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,581 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,581 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,583 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,583 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00388
2025-08-14 11:24:40,583 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,584 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00389
2025-08-14 11:24:40,585 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00390
2025-08-14 11:24:40,607 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,607 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,608 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00391
2025-08-14 11:24:40,629 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,629 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,630 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,631 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,632 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00392
2025-08-14 11:24:40,632 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00393
2025-08-14 11:24:40,635 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,635 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,639 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,639 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,648 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,648 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,649 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,649 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,651 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00394
2025-08-14 11:24:40,651 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00395
2025-08-14 11:24:40,651 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00396
2025-08-14 11:24:40,651 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00397
2025-08-14 11:24:40,660 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,661 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,661 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,662 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,666 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,666 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,668 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00398
2025-08-14 11:24:40,668 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00399
2025-08-14 11:24:40,668 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00400
2025-08-14 11:24:40,671 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,671 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,672 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00401
2025-08-14 11:24:40,697 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,697 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,698 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00402
2025-08-14 11:24:40,700 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,700 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,703 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,703 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,704 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00403
2025-08-14 11:24:40,704 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00404
2025-08-14 11:24:40,708 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,708 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,709 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00405
2025-08-14 11:24:40,730 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,730 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,731 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00406
2025-08-14 11:24:40,735 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,735 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,740 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,741 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,741 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,741 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,747 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,747 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,748 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00407
2025-08-14 11:24:40,748 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00408
2025-08-14 11:24:40,749 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00409
2025-08-14 11:24:40,753 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,753 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,754 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00410
2025-08-14 11:24:40,754 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00411
2025-08-14 11:24:40,773 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,773 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,774 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00412
2025-08-14 11:24:40,778 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,778 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,782 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,783 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,784 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00413
2025-08-14 11:24:40,784 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00414
2025-08-14 11:24:40,800 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,800 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,806 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,806 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,820 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,821 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,821 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,821 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,830 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,830 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,837 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,837 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,837 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,837 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,846 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,847 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,848 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,848 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,849 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00415
2025-08-14 11:24:40,849 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00416
2025-08-14 11:24:40,849 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00417
2025-08-14 11:24:40,849 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00418
2025-08-14 11:24:40,849 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00419
2025-08-14 11:24:40,850 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00420
2025-08-14 11:24:40,850 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00421
2025-08-14 11:24:40,850 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00422
2025-08-14 11:24:40,850 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00423
2025-08-14 11:24:40,852 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,853 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,854 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00424
2025-08-14 11:24:40,870 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,870 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,871 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00425
2025-08-14 11:24:40,893 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,893 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,894 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,894 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,895 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00426
2025-08-14 11:24:40,895 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00427
2025-08-14 11:24:40,901 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,901 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,902 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00428
2025-08-14 11:24:40,903 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,903 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,914 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,914 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,915 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00429
2025-08-14 11:24:40,915 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00430
2025-08-14 11:24:40,921 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,921 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,923 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,923 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,924 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00431
2025-08-14 11:24:40,924 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00432
2025-08-14 11:24:40,927 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,927 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,934 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,935 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,961 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,961 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,969 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,969 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,979 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,979 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,979 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,980 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,988 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,988 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,989 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00433
2025-08-14 11:24:40,990 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,990 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00434
2025-08-14 11:24:40,990 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,990 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00435
2025-08-14 11:24:40,992 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,992 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00436
2025-08-14 11:24:40,992 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:40,992 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00437
2025-08-14 11:24:40,994 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00438
2025-08-14 11:24:40,994 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00439
2025-08-14 11:24:40,994 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00440
2025-08-14 11:24:40,994 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00441
2025-08-14 11:24:40,994 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:40,994 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,006 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,006 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,007 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00442
2025-08-14 11:24:41,007 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00443
2025-08-14 11:24:41,010 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,010 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,011 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00444
2025-08-14 11:24:41,043 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,043 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,044 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,044 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,045 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00445
2025-08-14 11:24:41,048 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,048 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,049 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00446
2025-08-14 11:24:41,050 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00447
2025-08-14 11:24:41,059 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,060 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,060 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,060 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,074 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,074 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,076 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,076 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,078 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,078 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,089 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,089 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,092 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,092 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,093 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00448
2025-08-14 11:24:41,093 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00449
2025-08-14 11:24:41,093 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00450
2025-08-14 11:24:41,093 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00451
2025-08-14 11:24:41,093 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00452
2025-08-14 11:24:41,093 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00453
2025-08-14 11:24:41,093 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00454
2025-08-14 11:24:41,109 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,109 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,110 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00455
2025-08-14 11:24:41,117 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,118 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,119 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00456
2025-08-14 11:24:41,129 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,129 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,131 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00457
2025-08-14 11:24:41,141 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,141 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,150 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,150 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,159 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,159 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,166 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,166 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,168 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,168 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,174 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,174 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,186 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,186 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,195 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,195 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,204 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,204 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,214 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,214 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,228 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,228 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,229 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,229 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,235 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,235 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,242 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,242 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,262 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,262 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,265 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,265 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,270 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,270 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,284 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,284 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,286 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,286 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,303 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,303 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,305 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,305 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,316 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,316 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,324 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,325 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,332 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,333 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,333 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,333 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,335 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,336 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,337 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00458
2025-08-14 11:24:41,337 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00459
2025-08-14 11:24:41,337 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00460
2025-08-14 11:24:41,337 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00461
2025-08-14 11:24:41,337 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00462
2025-08-14 11:24:41,337 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00463
2025-08-14 11:24:41,337 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00464
2025-08-14 11:24:41,337 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00465
2025-08-14 11:24:41,337 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00466
2025-08-14 11:24:41,337 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00467
2025-08-14 11:24:41,337 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00468
2025-08-14 11:24:41,337 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00469
2025-08-14 11:24:41,337 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00470
2025-08-14 11:24:41,337 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00471
2025-08-14 11:24:41,338 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00472
2025-08-14 11:24:41,338 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00473
2025-08-14 11:24:41,338 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00474
2025-08-14 11:24:41,338 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00475
2025-08-14 11:24:41,338 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00476
2025-08-14 11:24:41,338 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00477
2025-08-14 11:24:41,338 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00478
2025-08-14 11:24:41,338 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00479
2025-08-14 11:24:41,338 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00480
2025-08-14 11:24:41,338 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00481
2025-08-14 11:24:41,338 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00482
2025-08-14 11:24:41,338 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00483
2025-08-14 11:24:41,352 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,352 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,355 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,355 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,357 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00484
2025-08-14 11:24:41,357 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00485
2025-08-14 11:24:41,370 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,370 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,371 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00486
2025-08-14 11:24:41,375 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,375 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,376 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,376 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,377 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00487
2025-08-14 11:24:41,378 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00488
2025-08-14 11:24:41,388 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,388 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,397 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,398 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,399 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00489
2025-08-14 11:24:41,399 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00490
2025-08-14 11:24:41,403 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,403 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,412 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,412 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,415 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,415 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,416 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00491
2025-08-14 11:24:41,416 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00492
2025-08-14 11:24:41,416 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00493
2025-08-14 11:24:41,421 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,421 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,422 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00494
2025-08-14 11:24:41,440 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,440 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,441 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00495
2025-08-14 11:24:41,442 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,442 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,443 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00496
2025-08-14 11:24:41,446 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,446 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,447 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00497
2025-08-14 11:24:41,447 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,448 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,449 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00498
2025-08-14 11:24:41,453 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,453 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,454 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00499
2025-08-14 11:24:41,468 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,468 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,476 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,476 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,477 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00500
2025-08-14 11:24:41,478 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00501
2025-08-14 11:24:41,481 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,481 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,482 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00502
2025-08-14 11:24:41,483 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,484 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,485 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00503
2025-08-14 11:24:41,485 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,485 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,486 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00504
2025-08-14 11:24:41,514 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,514 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,518 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,518 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,521 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,521 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,523 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,523 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,524 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00505
2025-08-14 11:24:41,524 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00506
2025-08-14 11:24:41,525 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00507
2025-08-14 11:24:41,528 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,528 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,529 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00508
2025-08-14 11:24:41,530 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00509
2025-08-14 11:24:41,537 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,537 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,538 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00510
2025-08-14 11:24:41,550 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,550 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,552 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,553 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,554 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,554 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00511
2025-08-14 11:24:41,554 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,555 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00512
2025-08-14 11:24:41,556 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,556 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,557 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00513
2025-08-14 11:24:41,558 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00514
2025-08-14 11:24:41,595 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,595 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,597 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,597 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,598 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,599 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,608 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,608 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,610 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,610 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,611 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,611 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00515
2025-08-14 11:24:41,612 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,612 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00516
2025-08-14 11:24:41,613 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00517
2025-08-14 11:24:41,613 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00518
2025-08-14 11:24:41,613 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00519
2025-08-14 11:24:41,613 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00520
2025-08-14 11:24:41,625 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,625 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,625 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,626 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,628 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,629 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,630 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00521
2025-08-14 11:24:41,630 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00522
2025-08-14 11:24:41,630 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00523
2025-08-14 11:24:41,637 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,637 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,638 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00524
2025-08-14 11:24:41,666 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,667 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,670 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,670 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,671 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00525
2025-08-14 11:24:41,672 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,672 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,673 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00526
2025-08-14 11:24:41,673 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00527
2025-08-14 11:24:41,676 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,676 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,678 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00528
2025-08-14 11:24:41,689 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,690 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,690 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,690 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,691 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00529
2025-08-14 11:24:41,699 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,699 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,701 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,701 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,701 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,702 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,703 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00530
2025-08-14 11:24:41,704 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00531
2025-08-14 11:24:41,704 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00532
2025-08-14 11:24:41,704 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00533
2025-08-14 11:24:41,713 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,713 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,714 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00534
2025-08-14 11:24:41,737 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,737 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,738 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00535
2025-08-14 11:24:41,740 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,740 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,744 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,745 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,749 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,749 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,750 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00536
2025-08-14 11:24:41,751 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00537
2025-08-14 11:24:41,751 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00538
2025-08-14 11:24:41,758 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,758 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,758 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,758 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,759 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00539
2025-08-14 11:24:41,761 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00540
2025-08-14 11:24:41,772 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,772 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,777 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,777 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,778 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00541
2025-08-14 11:24:41,781 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,781 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,785 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,785 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,786 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00542
2025-08-14 11:24:41,786 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00543
2025-08-14 11:24:41,786 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00544
2025-08-14 11:24:41,803 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,804 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,805 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00545
2025-08-14 11:24:41,807 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,807 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,808 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00546
2025-08-14 11:24:41,819 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,819 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,820 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00547
2025-08-14 11:24:41,824 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,824 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,825 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00548
2025-08-14 11:24:41,839 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,839 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,857 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,858 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,858 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,858 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,860 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,861 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,871 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,871 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,876 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,876 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,877 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,878 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,888 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,888 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,903 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,903 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,904 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,905 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,911 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,911 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,912 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00549
2025-08-14 11:24:41,912 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00550
2025-08-14 11:24:41,912 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00551
2025-08-14 11:24:41,912 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00552
2025-08-14 11:24:41,912 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00553
2025-08-14 11:24:41,912 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00554
2025-08-14 11:24:41,912 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00555
2025-08-14 11:24:41,912 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00556
2025-08-14 11:24:41,912 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00557
2025-08-14 11:24:41,912 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00558
2025-08-14 11:24:41,912 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00559
2025-08-14 11:24:41,926 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,927 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,935 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,935 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,936 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00560
2025-08-14 11:24:41,936 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00561
2025-08-14 11:24:41,938 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,938 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,939 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00562
2025-08-14 11:24:41,942 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,943 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,946 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,946 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,956 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,956 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,957 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00563
2025-08-14 11:24:41,957 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00564
2025-08-14 11:24:41,957 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00565
2025-08-14 11:24:41,961 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,961 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,962 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00566
2025-08-14 11:24:41,972 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,972 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,973 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00567
2025-08-14 11:24:41,990 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,990 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,991 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00568
2025-08-14 11:24:41,996 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:41,996 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:41,998 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00569
2025-08-14 11:24:42,006 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,006 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,009 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,009 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,011 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,011 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,013 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,013 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,029 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,029 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,031 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,031 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,032 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00570
2025-08-14 11:24:42,033 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00571
2025-08-14 11:24:42,033 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00572
2025-08-14 11:24:42,033 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00573
2025-08-14 11:24:42,033 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00574
2025-08-14 11:24:42,040 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,040 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,041 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00575
2025-08-14 11:24:42,041 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00576
2025-08-14 11:24:42,054 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,054 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,055 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00577
2025-08-14 11:24:42,060 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,060 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,065 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,065 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,066 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00578
2025-08-14 11:24:42,066 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00579
2025-08-14 11:24:42,077 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,077 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,085 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,086 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,086 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,086 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,087 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,086 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,090 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00580
2025-08-14 11:24:42,090 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00581
2025-08-14 11:24:42,090 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00582
2025-08-14 11:24:42,090 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00583
2025-08-14 11:24:42,100 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,100 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,101 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00584
2025-08-14 11:24:42,112 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,112 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,113 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00585
2025-08-14 11:24:42,123 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,124 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,125 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,125 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,126 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00586
2025-08-14 11:24:42,127 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00587
2025-08-14 11:24:42,127 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,127 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,128 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00588
2025-08-14 11:24:42,144 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,144 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,149 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,150 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,151 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00589
2025-08-14 11:24:42,151 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00590
2025-08-14 11:24:42,156 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,156 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,157 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00591
2025-08-14 11:24:42,172 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,172 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,174 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,174 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,178 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,178 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,179 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00592
2025-08-14 11:24:42,179 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00593
2025-08-14 11:24:42,180 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,180 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00594
2025-08-14 11:24:42,180 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,181 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00595
2025-08-14 11:24:42,192 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,192 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,193 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00596
2025-08-14 11:24:42,195 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,196 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,215 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,216 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,217 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00597
2025-08-14 11:24:42,217 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00598
2025-08-14 11:24:42,225 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,226 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,235 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,235 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,236 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00599
2025-08-14 11:24:42,236 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00600
2025-08-14 11:24:42,246 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,246 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,247 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,247 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,247 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,247 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,248 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00601
2025-08-14 11:24:42,249 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,252 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00602
2025-08-14 11:24:42,252 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,255 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,255 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,256 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00603
2025-08-14 11:24:42,256 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00604
2025-08-14 11:24:42,257 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00605
2025-08-14 11:24:42,260 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,260 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,288 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,288 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,289 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00606
2025-08-14 11:24:42,290 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00607
2025-08-14 11:24:42,306 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,306 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,310 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,310 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,315 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,315 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,316 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00608
2025-08-14 11:24:42,316 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00609
2025-08-14 11:24:42,316 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00610
2025-08-14 11:24:42,317 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,317 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,321 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,322 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,326 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,327 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,327 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,327 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,338 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,338 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,347 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,347 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,348 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00611
2025-08-14 11:24:42,348 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00612
2025-08-14 11:24:42,348 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00613
2025-08-14 11:24:42,348 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00614
2025-08-14 11:24:42,348 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00615
2025-08-14 11:24:42,348 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00616
2025-08-14 11:24:42,354 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,354 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,355 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00617
2025-08-14 11:24:42,383 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,383 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,385 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,385 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,394 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,394 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,395 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00618
2025-08-14 11:24:42,395 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00619
2025-08-14 11:24:42,398 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,398 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,410 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,410 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,411 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00620
2025-08-14 11:24:42,411 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00621
2025-08-14 11:24:42,413 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,413 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,415 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,415 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,421 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,421 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,443 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,443 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,455 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,455 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,469 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,469 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,473 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,473 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,476 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,476 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,485 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,485 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,486 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00622
2025-08-14 11:24:42,486 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00623
2025-08-14 11:24:42,486 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00624
2025-08-14 11:24:42,486 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00625
2025-08-14 11:24:42,486 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00626
2025-08-14 11:24:42,486 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00627
2025-08-14 11:24:42,486 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00628
2025-08-14 11:24:42,486 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00629
2025-08-14 11:24:42,486 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00630
2025-08-14 11:24:42,486 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00631
2025-08-14 11:24:42,496 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,496 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,498 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,498 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00632
2025-08-14 11:24:42,498 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,499 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,500 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,501 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00633
2025-08-14 11:24:42,513 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,513 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,514 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00634
2025-08-14 11:24:42,514 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00635
2025-08-14 11:24:42,523 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,523 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,525 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,525 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,526 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00636
2025-08-14 11:24:42,526 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00637
2025-08-14 11:24:42,545 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,545 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,546 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,546 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,548 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00638
2025-08-14 11:24:42,551 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,551 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,551 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,551 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,554 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00639
2025-08-14 11:24:42,554 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00640
2025-08-14 11:24:42,554 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00641
2025-08-14 11:24:42,568 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,568 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,574 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,574 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,583 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,584 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,585 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00642
2025-08-14 11:24:42,585 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00643
2025-08-14 11:24:42,585 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00644
2025-08-14 11:24:42,586 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,586 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,587 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00645
2025-08-14 11:24:42,588 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,588 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,589 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00646
2025-08-14 11:24:42,595 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,595 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,596 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00647
2025-08-14 11:24:42,612 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,612 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,619 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,619 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,620 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00648
2025-08-14 11:24:42,620 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00649
2025-08-14 11:24:42,634 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,634 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,643 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,643 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,644 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00650
2025-08-14 11:24:42,644 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00651
2025-08-14 11:24:42,651 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,652 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,652 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,652 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,667 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,667 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,674 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,674 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,675 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,675 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,679 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,679 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,692 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,692 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,698 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,698 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,699 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00652
2025-08-14 11:24:42,700 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00653
2025-08-14 11:24:42,700 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00654
2025-08-14 11:24:42,700 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00655
2025-08-14 11:24:42,700 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00656
2025-08-14 11:24:42,700 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00657
2025-08-14 11:24:42,700 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00658
2025-08-14 11:24:42,700 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00659
2025-08-14 11:24:42,712 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,712 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,713 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00660
2025-08-14 11:24:42,717 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,717 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,718 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00661
2025-08-14 11:24:42,727 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,727 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,733 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,733 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,735 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,735 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,736 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00662
2025-08-14 11:24:42,736 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00663
2025-08-14 11:24:42,736 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00664
2025-08-14 11:24:42,746 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,746 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,747 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00665
2025-08-14 11:24:42,759 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,760 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,761 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00666
2025-08-14 11:24:42,763 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,763 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,765 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,765 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,766 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00667
2025-08-14 11:24:42,766 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00668
2025-08-14 11:24:42,769 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,769 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,770 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00669
2025-08-14 11:24:42,786 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,787 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,788 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00670
2025-08-14 11:24:42,790 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,790 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,791 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00671
2025-08-14 11:24:42,801 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,801 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,804 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,804 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,805 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00672
2025-08-14 11:24:42,809 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,809 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,810 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00673
2025-08-14 11:24:42,811 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00674
2025-08-14 11:24:42,817 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,817 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,818 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00675
2025-08-14 11:24:42,832 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,832 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,840 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,841 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,841 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,841 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,848 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,848 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,849 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00676
2025-08-14 11:24:42,849 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00677
2025-08-14 11:24:42,849 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00678
2025-08-14 11:24:42,849 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00679
2025-08-14 11:24:42,854 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,854 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,855 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00680
2025-08-14 11:24:42,862 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,862 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,863 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00681
2025-08-14 11:24:42,865 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,865 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,866 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00682
2025-08-14 11:24:42,873 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,873 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,885 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,885 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,886 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00683
2025-08-14 11:24:42,886 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00684
2025-08-14 11:24:42,905 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,905 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,906 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,906 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,909 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,909 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,910 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00685
2025-08-14 11:24:42,910 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00686
2025-08-14 11:24:42,910 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00687
2025-08-14 11:24:42,926 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,926 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,927 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,927 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00688
2025-08-14 11:24:42,927 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,931 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,931 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,933 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,933 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00689
2025-08-14 11:24:42,933 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,933 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00690
2025-08-14 11:24:42,940 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,940 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,941 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00691
2025-08-14 11:24:42,941 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00692
2025-08-14 11:24:42,946 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,946 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,947 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00693
2025-08-14 11:24:42,963 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,963 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,964 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00694
2025-08-14 11:24:42,977 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,977 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,978 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00695
2025-08-14 11:24:42,981 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,981 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,982 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00696
2025-08-14 11:24:42,993 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,993 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,995 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,995 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,996 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,996 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00697
2025-08-14 11:24:42,996 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:42,996 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00698
2025-08-14 11:24:42,998 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:42,998 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00699
2025-08-14 11:24:42,998 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,016 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,017 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,019 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,019 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,021 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00700
2025-08-14 11:24:43,021 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00701
2025-08-14 11:24:43,022 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,022 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,024 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00702
2025-08-14 11:24:43,024 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00703
2025-08-14 11:24:43,035 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,035 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,036 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00704
2025-08-14 11:24:43,058 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,058 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,059 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,060 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,061 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00705
2025-08-14 11:24:43,061 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00706
2025-08-14 11:24:43,068 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,068 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,070 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,071 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,072 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00707
2025-08-14 11:24:43,072 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00708
2025-08-14 11:24:43,077 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,077 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,078 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00709
2025-08-14 11:24:43,082 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,082 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,091 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,091 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,093 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00710
2025-08-14 11:24:43,093 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00711
2025-08-14 11:24:43,107 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,108 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,109 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00712
2025-08-14 11:24:43,120 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,120 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,140 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,140 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,142 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,142 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,143 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,143 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,145 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,146 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,146 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,146 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,148 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,149 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,161 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,161 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,163 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,163 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00713
2025-08-14 11:24:43,163 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,163 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00714
2025-08-14 11:24:43,164 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00715
2025-08-14 11:24:43,164 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00716
2025-08-14 11:24:43,165 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00717
2025-08-14 11:24:43,165 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00718
2025-08-14 11:24:43,165 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00719
2025-08-14 11:24:43,165 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00720
2025-08-14 11:24:43,165 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00721
2025-08-14 11:24:43,190 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,190 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,192 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00722
2025-08-14 11:24:43,202 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,202 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,204 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00723
2025-08-14 11:24:43,207 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,207 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,208 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00724
2025-08-14 11:24:43,213 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,213 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,214 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00725
2025-08-14 11:24:43,214 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,215 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,215 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,216 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,218 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00726
2025-08-14 11:24:43,220 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,220 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,221 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00727
2025-08-14 11:24:43,221 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00728
2025-08-14 11:24:43,227 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,227 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,229 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,229 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,230 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00729
2025-08-14 11:24:43,240 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,240 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,241 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00730
2025-08-14 11:24:43,241 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00731
2025-08-14 11:24:43,278 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,278 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,281 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,282 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,283 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,283 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,283 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,283 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,283 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,285 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00732
2025-08-14 11:24:43,285 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,287 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00733
2025-08-14 11:24:43,289 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00734
2025-08-14 11:24:43,292 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,292 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,293 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,294 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,294 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,295 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00735
2025-08-14 11:24:43,296 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,296 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00736
2025-08-14 11:24:43,297 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00737
2025-08-14 11:24:43,297 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00738
2025-08-14 11:24:43,297 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00739
2025-08-14 11:24:43,323 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,323 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,338 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,338 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,339 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00740
2025-08-14 11:24:43,339 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00741
2025-08-14 11:24:43,349 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,349 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,353 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,353 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,355 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,355 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,357 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,357 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,360 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,360 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,361 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00742
2025-08-14 11:24:43,361 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00743
2025-08-14 11:24:43,361 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00744
2025-08-14 11:24:43,365 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,366 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,368 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,368 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,385 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,385 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,386 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00745
2025-08-14 11:24:43,386 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00746
2025-08-14 11:24:43,386 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00747
2025-08-14 11:24:43,386 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00748
2025-08-14 11:24:43,386 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00749
2025-08-14 11:24:43,400 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,400 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,401 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00750
2025-08-14 11:24:43,420 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,420 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,422 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,422 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,425 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,426 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,426 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,426 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,428 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,429 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,430 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00751
2025-08-14 11:24:43,430 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00752
2025-08-14 11:24:43,430 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00753
2025-08-14 11:24:43,430 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00754
2025-08-14 11:24:43,430 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00755
2025-08-14 11:24:43,440 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,440 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,441 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,441 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,463 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,463 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,464 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00756
2025-08-14 11:24:43,464 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00757
2025-08-14 11:24:43,464 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00758
2025-08-14 11:24:43,475 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,475 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,491 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,491 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,493 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,493 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,495 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,496 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,497 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,498 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,498 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,498 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,500 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,501 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00759
2025-08-14 11:24:43,501 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,501 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00760
2025-08-14 11:24:43,502 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00761
2025-08-14 11:24:43,503 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00762
2025-08-14 11:24:43,503 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00763
2025-08-14 11:24:43,503 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00764
2025-08-14 11:24:43,503 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00765
2025-08-14 11:24:43,510 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,510 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,511 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00766
2025-08-14 11:24:43,519 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,519 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,520 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00767
2025-08-14 11:24:43,539 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,539 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,540 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00768
2025-08-14 11:24:43,552 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,552 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,554 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,554 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,555 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00769
2025-08-14 11:24:43,555 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00770
2025-08-14 11:24:43,562 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,562 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,567 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,567 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,569 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,569 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,581 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,581 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,585 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,585 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,603 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,603 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,614 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,614 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,616 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,616 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,630 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,631 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,631 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,631 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,633 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,635 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,635 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,635 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,637 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00771
2025-08-14 11:24:43,638 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00772
2025-08-14 11:24:43,638 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00773
2025-08-14 11:24:43,638 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00774
2025-08-14 11:24:43,638 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00775
2025-08-14 11:24:43,638 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00776
2025-08-14 11:24:43,638 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00777
2025-08-14 11:24:43,638 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00778
2025-08-14 11:24:43,638 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00779
2025-08-14 11:24:43,638 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00780
2025-08-14 11:24:43,638 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00781
2025-08-14 11:24:43,654 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,654 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,669 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,669 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,685 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,685 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,687 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,687 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,695 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,695 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,697 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,697 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,698 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,699 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00782
2025-08-14 11:24:43,699 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,699 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00783
2025-08-14 11:24:43,700 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00784
2025-08-14 11:24:43,700 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00785
2025-08-14 11:24:43,700 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00786
2025-08-14 11:24:43,700 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00787
2025-08-14 11:24:43,700 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00788
2025-08-14 11:24:43,708 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,708 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,709 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,709 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,711 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,712 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,713 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00789
2025-08-14 11:24:43,713 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00790
2025-08-14 11:24:43,713 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00791
2025-08-14 11:24:43,713 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00792
2025-08-14 11:24:43,728 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,728 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,729 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00793
2025-08-14 11:24:43,751 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,751 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,753 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,753 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,754 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00794
2025-08-14 11:24:43,758 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,758 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,764 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,764 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,770 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,770 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,772 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00795
2025-08-14 11:24:43,772 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00796
2025-08-14 11:24:43,784 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,784 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,786 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,786 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,791 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,791 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,792 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00797
2025-08-14 11:24:43,792 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00798
2025-08-14 11:24:43,792 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00799
2025-08-14 11:24:43,792 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00800
2025-08-14 11:24:43,792 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00801
2025-08-14 11:24:43,800 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,800 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,802 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00802
2025-08-14 11:24:43,808 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,808 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,809 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00803
2025-08-14 11:24:43,818 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,818 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,819 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00804
2025-08-14 11:24:43,827 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,827 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,839 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,839 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,840 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,840 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,845 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,845 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,846 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00805
2025-08-14 11:24:43,846 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00806
2025-08-14 11:24:43,846 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00807
2025-08-14 11:24:43,846 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00808
2025-08-14 11:24:43,853 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,853 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,854 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00809
2025-08-14 11:24:43,856 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,856 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,857 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00810
2025-08-14 11:24:43,867 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,867 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,868 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00811
2025-08-14 11:24:43,876 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,877 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,878 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00812
2025-08-14 11:24:43,894 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,895 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,895 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,895 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,897 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,898 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,899 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00813
2025-08-14 11:24:43,899 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00814
2025-08-14 11:24:43,899 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00815
2025-08-14 11:24:43,908 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,908 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,909 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00816
2025-08-14 11:24:43,923 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,923 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,926 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,926 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,927 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00817
2025-08-14 11:24:43,937 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,937 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,943 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,943 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,944 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00818
2025-08-14 11:24:43,944 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00819
2025-08-14 11:24:43,944 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00820
2025-08-14 11:24:43,948 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,948 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,949 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,949 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,951 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00821
2025-08-14 11:24:43,951 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00822
2025-08-14 11:24:43,962 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,962 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,963 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,963 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,965 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00823
2025-08-14 11:24:43,965 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00824
2025-08-14 11:24:43,970 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,970 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,971 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00825
2025-08-14 11:24:43,978 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,978 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,979 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00826
2025-08-14 11:24:43,989 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,989 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,990 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00827
2025-08-14 11:24:43,996 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:43,996 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:43,997 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00828
2025-08-14 11:24:44,008 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,008 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,009 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00829
2025-08-14 11:24:44,022 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,022 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,024 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,025 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,027 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,027 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,029 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,030 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,030 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,030 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,031 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00830
2025-08-14 11:24:44,033 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00831
2025-08-14 11:24:44,033 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00832
2025-08-14 11:24:44,033 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00833
2025-08-14 11:24:44,033 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00834
2025-08-14 11:24:44,047 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,047 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,048 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00835
2025-08-14 11:24:44,050 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,050 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,051 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00836
2025-08-14 11:24:44,076 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,076 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,077 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,077 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,079 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,079 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00837
2025-08-14 11:24:44,079 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,079 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00838
2025-08-14 11:24:44,081 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00839
2025-08-14 11:24:44,092 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,092 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,103 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,103 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,105 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,106 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,106 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,106 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,108 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00840
2025-08-14 11:24:44,108 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00841
2025-08-14 11:24:44,108 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00842
2025-08-14 11:24:44,108 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00843
2025-08-14 11:24:44,120 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,120 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,123 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,123 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,125 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00844
2025-08-14 11:24:44,125 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00845
2025-08-14 11:24:44,148 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,148 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,150 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,150 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,151 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,151 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,151 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,153 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00846
2025-08-14 11:24:44,153 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,154 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00847
2025-08-14 11:24:44,156 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00848
2025-08-14 11:24:44,156 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00849
2025-08-14 11:24:44,162 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,162 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,163 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00850
2025-08-14 11:24:44,166 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,166 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,167 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00851
2025-08-14 11:24:44,184 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,184 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,186 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,186 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,187 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00852
2025-08-14 11:24:44,187 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00853
2025-08-14 11:24:44,196 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,197 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,198 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00854
2025-08-14 11:24:44,208 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,208 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,209 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00855
2025-08-14 11:24:44,214 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,214 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,215 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00856
2025-08-14 11:24:44,222 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,223 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,223 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,223 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,224 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00857
2025-08-14 11:24:44,229 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,229 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,231 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,231 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,232 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00858
2025-08-14 11:24:44,232 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00859
2025-08-14 11:24:44,234 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,234 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,235 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00860
2025-08-14 11:24:44,236 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00861
2025-08-14 11:24:44,260 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,260 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,261 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00862
2025-08-14 11:24:44,274 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,274 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,275 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00863
2025-08-14 11:24:44,277 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,277 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,278 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00864
2025-08-14 11:24:44,282 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,282 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,288 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,288 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,290 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,290 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,292 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00865
2025-08-14 11:24:44,292 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00866
2025-08-14 11:24:44,292 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00867
2025-08-14 11:24:44,293 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,293 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,294 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00868
2025-08-14 11:24:44,298 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,298 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,299 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00869
2025-08-14 11:24:44,300 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,300 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,301 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00870
2025-08-14 11:24:44,309 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,310 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,311 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00871
2025-08-14 11:24:44,336 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,336 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,337 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00872
2025-08-14 11:24:44,347 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,348 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,349 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,349 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,353 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,353 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,354 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00873
2025-08-14 11:24:44,354 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00874
2025-08-14 11:24:44,354 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00875
2025-08-14 11:24:44,355 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,355 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,356 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00876
2025-08-14 11:24:44,363 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,363 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,366 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,366 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,374 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,374 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,381 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,382 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,382 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,382 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,383 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00877
2025-08-14 11:24:44,385 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00878
2025-08-14 11:24:44,385 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00879
2025-08-14 11:24:44,385 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00880
2025-08-14 11:24:44,385 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00881
2025-08-14 11:24:44,421 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,421 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,425 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,425 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,426 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00882
2025-08-14 11:24:44,426 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00883
2025-08-14 11:24:44,427 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,427 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,427 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,428 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,429 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00884
2025-08-14 11:24:44,430 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,431 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,432 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00885
2025-08-14 11:24:44,434 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,434 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,435 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00886
2025-08-14 11:24:44,435 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00887
2025-08-14 11:24:44,436 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,436 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,437 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00888
2025-08-14 11:24:44,445 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,445 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,446 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00889
2025-08-14 11:24:44,457 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,458 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,459 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00890
2025-08-14 11:24:44,466 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,466 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,467 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00891
2025-08-14 11:24:44,491 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,491 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,493 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00892
2025-08-14 11:24:44,493 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,493 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,499 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,499 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,501 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,501 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,502 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00893
2025-08-14 11:24:44,502 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00894
2025-08-14 11:24:44,507 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,507 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,509 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,509 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,510 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00895
2025-08-14 11:24:44,521 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,521 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,523 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,524 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,526 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,526 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,527 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00896
2025-08-14 11:24:44,527 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00897
2025-08-14 11:24:44,527 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00898
2025-08-14 11:24:44,527 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00899
2025-08-14 11:24:44,527 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00900
2025-08-14 11:24:44,559 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,559 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,561 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,561 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,570 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,570 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,575 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,575 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,590 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,590 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,592 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,592 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,594 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,594 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,599 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,599 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,600 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,600 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,601 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00901
2025-08-14 11:24:44,602 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00902
2025-08-14 11:24:44,602 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00903
2025-08-14 11:24:44,602 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00904
2025-08-14 11:24:44,602 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00905
2025-08-14 11:24:44,602 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00906
2025-08-14 11:24:44,602 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00907
2025-08-14 11:24:44,628 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,628 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,635 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,635 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,638 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,638 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,657 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,658 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,659 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00908
2025-08-14 11:24:44,659 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00909
2025-08-14 11:24:44,659 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00910
2025-08-14 11:24:44,659 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00911
2025-08-14 11:24:44,659 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00912
2025-08-14 11:24:44,659 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00913
2025-08-14 11:24:44,659 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,660 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,664 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,664 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,664 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,664 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,666 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00914
2025-08-14 11:24:44,667 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,667 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00915
2025-08-14 11:24:44,667 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,669 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00916
2025-08-14 11:24:44,669 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00917
2025-08-14 11:24:44,683 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,683 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,684 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00918
2025-08-14 11:24:44,689 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,690 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,691 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00919
2025-08-14 11:24:44,697 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,697 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,698 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00920
2025-08-14 11:24:44,702 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,703 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,717 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,717 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,718 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00921
2025-08-14 11:24:44,718 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00922
2025-08-14 11:24:44,728 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,729 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,730 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00923
2025-08-14 11:24:44,734 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,735 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,735 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,735 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,738 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00924
2025-08-14 11:24:44,738 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,738 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,739 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00925
2025-08-14 11:24:44,750 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,750 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,751 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00926
2025-08-14 11:24:44,751 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00927
2025-08-14 11:24:44,764 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,764 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,775 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,775 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,779 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,779 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,782 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,782 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,784 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,784 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,785 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00928
2025-08-14 11:24:44,785 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00929
2025-08-14 11:24:44,785 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00930
2025-08-14 11:24:44,785 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00931
2025-08-14 11:24:44,785 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00932
2025-08-14 11:24:44,801 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,801 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,802 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00933
2025-08-14 11:24:44,809 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,809 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,811 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,811 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,812 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00934
2025-08-14 11:24:44,812 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00935
2025-08-14 11:24:44,828 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,828 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,831 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,831 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,837 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,837 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,838 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00936
2025-08-14 11:24:44,838 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00937
2025-08-14 11:24:44,839 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00938
2025-08-14 11:24:44,843 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,843 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,857 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,857 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,864 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,864 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,865 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00939
2025-08-14 11:24:44,865 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00940
2025-08-14 11:24:44,865 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00941
2025-08-14 11:24:44,871 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,871 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,875 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,875 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,881 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,881 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,883 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00942
2025-08-14 11:24:44,883 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00943
2025-08-14 11:24:44,895 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,895 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,896 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00944
2025-08-14 11:24:44,896 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00945
2025-08-14 11:24:44,907 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,907 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,908 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,908 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,924 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,924 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,927 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,927 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,928 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00946
2025-08-14 11:24:44,928 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00947
2025-08-14 11:24:44,937 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,937 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,938 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00948
2025-08-14 11:24:44,938 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00949
2025-08-14 11:24:44,938 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00950
2025-08-14 11:24:44,940 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,940 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,943 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,943 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,954 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,954 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,955 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00951
2025-08-14 11:24:44,955 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00952
2025-08-14 11:24:44,956 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00953
2025-08-14 11:24:44,965 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,965 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,978 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,978 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,980 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,980 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00954
2025-08-14 11:24:44,980 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,980 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,981 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00955
2025-08-14 11:24:44,981 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,982 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00956
2025-08-14 11:24:44,983 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00957
2025-08-14 11:24:44,986 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:44,986 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:44,987 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00958
2025-08-14 11:24:45,004 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,004 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,005 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00959
2025-08-14 11:24:45,010 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,010 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,020 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,020 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,022 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,022 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,023 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00960
2025-08-14 11:24:45,023 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00961
2025-08-14 11:24:45,023 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00962
2025-08-14 11:24:45,039 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,039 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,042 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,042 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,043 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00963
2025-08-14 11:24:45,043 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00964
2025-08-14 11:24:45,047 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,047 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,053 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,053 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,061 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,061 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,062 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00965
2025-08-14 11:24:45,062 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00966
2025-08-14 11:24:45,062 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00967
2025-08-14 11:24:45,063 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,063 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,064 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00968
2025-08-14 11:24:45,083 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,083 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,084 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00969
2025-08-14 11:24:45,084 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,085 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,086 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00970
2025-08-14 11:24:45,097 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,097 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,098 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00971
2025-08-14 11:24:45,099 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,099 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,100 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00972
2025-08-14 11:24:45,116 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,116 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,117 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00973
2025-08-14 11:24:45,126 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,126 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,127 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00974
2025-08-14 11:24:45,132 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,132 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:24:45,133 - LLMsInterface - INFO - Got response from gpt-5-mini-2025-08-07 at index BenchmarkTest00975
2025-08-14 11:24:45,180 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported value: 'temperature' does not support 0.0 with this model. Only the default (1) value is supported.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_value'}}
2025-08-14 11:24:45,180 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 11:25:46,282 - VuLLMBench - INFO - Experiment exp11 started...
2025-08-14 11:25:46,300 - Controller - INFO - Loaded 2740 examples from the owasp dataset.
2025-08-14 11:25:46,939 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:46,939 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:46,960 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:46,961 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:46,961 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:46,961 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:46,963 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:46,963 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:46,968 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:46,968 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:46,968 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:46,968 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:46,970 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:46,971 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:46,973 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:46,973 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:46,987 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:46,987 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:47,016 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:47,017 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:48,983 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:48,983 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:49,000 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:49,000 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:49,004 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:49,004 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:49,007 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:49,007 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:49,012 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:49,012 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:49,014 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:49,015 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:49,018 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:49,018 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:49,026 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:49,026 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:49,031 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:49,031 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:49,058 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:49,058 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:51,028 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:51,028 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:51,041 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:51,041 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:51,043 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:51,043 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:51,049 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:51,049 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:51,055 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:51,055 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:51,062 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:51,062 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:51,070 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:51,071 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:51,071 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:51,071 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:51,074 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:51,074 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:51,100 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:51,100 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:53,073 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:53,074 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:53,083 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:53,083 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:53,085 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:53,085 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:53,087 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:53,087 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:53,097 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:53,097 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:53,115 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:53,115 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:53,116 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:53,116 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:53,118 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:53,118 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:53,118 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:53,118 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:53,142 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:53,142 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:55,123 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:55,123 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:55,123 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:55,123 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:55,125 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:55,125 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:55,131 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:55,131 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:55,140 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:55,140 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:55,160 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:55,160 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:55,164 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:55,164 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:55,171 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:55,171 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:55,185 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:55,185 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:55,263 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:55,263 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:57,168 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:57,168 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:57,168 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:57,168 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:57,170 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:57,171 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:57,171 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:57,172 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:57,183 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:57,183 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:57,208 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:57,208 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:57,214 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:57,215 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:57,216 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:57,216 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:57,227 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:57,227 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:57,307 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:57,307 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:59,210 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:59,210 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:59,214 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:59,214 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:59,216 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:59,216 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:59,217 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:59,218 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:59,226 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:59,226 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:59,259 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:59,259 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:59,259 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:59,259 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:59,263 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:59,263 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:59,271 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:59,271 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 11:25:59,351 - LLMsInterface - ERROR - Error invoking model: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
2025-08-14 11:25:59,351 - LLMsInterface - INFO - Retrying after 2 seconds...
2025-08-14 14:57:04,822 - VuLLMBench - INFO - Experiment exp11 started...
2025-08-14 14:57:04,839 - Controller - INFO - Loaded 2740 examples from the owasp dataset.
2025-08-14 14:57:05,569 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,569 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,571 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,573 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,573 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,574 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,574 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,574 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,574 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,579 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,579 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,579 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,613 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,613 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,618 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,619 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,619 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,620 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,620 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,620 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,620 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,622 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,622 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,623 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,623 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,628 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,625 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,628 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00001
2025-08-14 14:57:05,627 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,628 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,630 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,630 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00002
2025-08-14 14:57:05,633 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00003
2025-08-14 14:57:05,638 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,638 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,639 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00004
2025-08-14 14:57:05,639 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00005
2025-08-14 14:57:05,639 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00006
2025-08-14 14:57:05,639 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00007
2025-08-14 14:57:05,639 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00008
2025-08-14 14:57:05,639 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00009
2025-08-14 14:57:05,639 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00010
2025-08-14 14:57:05,639 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00011
2025-08-14 14:57:05,639 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00012
2025-08-14 14:57:05,639 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00013
2025-08-14 14:57:05,639 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00014
2025-08-14 14:57:05,639 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00015
2025-08-14 14:57:05,639 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00016
2025-08-14 14:57:05,657 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,657 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,658 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00017
2025-08-14 14:57:05,668 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,668 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,671 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,672 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,672 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,672 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,675 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,675 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,675 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,676 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,677 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,677 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,679 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00018
2025-08-14 14:57:05,680 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00019
2025-08-14 14:57:05,682 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,682 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,683 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00020
2025-08-14 14:57:05,683 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00021
2025-08-14 14:57:05,684 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00022
2025-08-14 14:57:05,684 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00023
2025-08-14 14:57:05,684 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00024
2025-08-14 14:57:05,688 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,688 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,689 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00025
2025-08-14 14:57:05,695 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,695 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,696 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00026
2025-08-14 14:57:05,700 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,700 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,701 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00027
2025-08-14 14:57:05,716 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,716 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,717 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,717 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,718 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00028
2025-08-14 14:57:05,719 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,720 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,721 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00029
2025-08-14 14:57:05,721 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00030
2025-08-14 14:57:05,722 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,722 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,722 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,722 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,730 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,731 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,732 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00031
2025-08-14 14:57:05,732 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00032
2025-08-14 14:57:05,732 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00033
2025-08-14 14:57:05,737 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,737 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00034
2025-08-14 14:57:05,743 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,743 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,744 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,744 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00035
2025-08-14 14:57:05,744 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,753 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,753 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,754 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00036
2025-08-14 14:57:05,754 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00037
2025-08-14 14:57:05,761 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,761 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,762 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,762 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,763 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00038
2025-08-14 14:57:05,764 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,765 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00039
2025-08-14 14:57:05,765 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,767 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,767 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00040
2025-08-14 14:57:05,767 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,767 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,769 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,770 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00041
2025-08-14 14:57:05,770 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00042
2025-08-14 14:57:05,786 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,786 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,787 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00043
2025-08-14 14:57:05,792 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,792 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,793 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00044
2025-08-14 14:57:05,794 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,795 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,798 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,798 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,799 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00045
2025-08-14 14:57:05,799 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00046
2025-08-14 14:57:05,806 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,806 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,807 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,808 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,809 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,810 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,811 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,811 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,812 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00047
2025-08-14 14:57:05,813 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,813 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00048
2025-08-14 14:57:05,813 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,814 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,814 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00049
2025-08-14 14:57:05,814 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,815 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00050
2025-08-14 14:57:05,816 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00051
2025-08-14 14:57:05,816 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00052
2025-08-14 14:57:05,836 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,836 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,840 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,840 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,841 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00053
2025-08-14 14:57:05,846 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,846 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,847 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00054
2025-08-14 14:57:05,848 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00055
2025-08-14 14:57:05,850 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,850 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,854 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,854 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,855 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,855 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,855 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,855 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,858 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,860 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00056
2025-08-14 14:57:05,860 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,860 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00057
2025-08-14 14:57:05,861 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,862 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00058
2025-08-14 14:57:05,862 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,862 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00059
2025-08-14 14:57:05,875 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,875 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00060
2025-08-14 14:57:05,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00061
2025-08-14 14:57:05,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00062
2025-08-14 14:57:05,878 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,878 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,879 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00063
2025-08-14 14:57:05,894 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,895 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,895 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,896 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,897 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00064
2025-08-14 14:57:05,900 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,900 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,901 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,902 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,902 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,902 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,903 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,903 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,904 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00065
2025-08-14 14:57:05,906 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00066
2025-08-14 14:57:05,906 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00067
2025-08-14 14:57:05,907 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00068
2025-08-14 14:57:05,907 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00069
2025-08-14 14:57:05,913 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,913 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,916 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,916 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,917 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00070
2025-08-14 14:57:05,917 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00071
2025-08-14 14:57:05,920 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,921 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,933 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,933 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,934 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00072
2025-08-14 14:57:05,934 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00073
2025-08-14 14:57:05,943 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,943 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,946 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,946 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,948 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,948 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,948 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,950 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,950 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,950 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,953 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00074
2025-08-14 14:57:05,953 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00075
2025-08-14 14:57:05,953 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00076
2025-08-14 14:57:05,958 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,958 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,959 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,959 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,960 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00077
2025-08-14 14:57:05,960 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00078
2025-08-14 14:57:05,960 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00079
2025-08-14 14:57:05,960 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00080
2025-08-14 14:57:05,962 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,962 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,971 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,971 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,972 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00081
2025-08-14 14:57:05,972 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00082
2025-08-14 14:57:05,988 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,988 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,990 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,991 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,991 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,991 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,993 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,994 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00083
2025-08-14 14:57:05,994 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:05,994 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00084
2025-08-14 14:57:05,996 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:05,996 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00085
2025-08-14 14:57:05,996 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00086
2025-08-14 14:57:05,996 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,001 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,002 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,005 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,005 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,005 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,005 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,008 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00087
2025-08-14 14:57:06,008 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00088
2025-08-14 14:57:06,008 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00089
2025-08-14 14:57:06,016 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,016 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,017 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00090
2025-08-14 14:57:06,017 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00091
2025-08-14 14:57:06,026 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,026 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,027 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00092
2025-08-14 14:57:06,032 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,032 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,033 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00093
2025-08-14 14:57:06,035 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,035 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,036 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00094
2025-08-14 14:57:06,037 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,037 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,044 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,044 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,048 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,049 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,049 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,049 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,052 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,052 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00095
2025-08-14 14:57:06,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00096
2025-08-14 14:57:06,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00097
2025-08-14 14:57:06,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00098
2025-08-14 14:57:06,060 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,060 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,061 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00099
2025-08-14 14:57:06,061 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00100
2025-08-14 14:57:06,071 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,071 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,072 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00101
2025-08-14 14:57:06,076 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,076 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,080 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,080 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,081 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,082 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,082 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,082 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,084 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00102
2025-08-14 14:57:06,084 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00103
2025-08-14 14:57:06,084 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00104
2025-08-14 14:57:06,085 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00105
2025-08-14 14:57:06,087 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,087 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00106
2025-08-14 14:57:06,091 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,091 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,092 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00107
2025-08-14 14:57:06,094 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,094 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,096 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00108
2025-08-14 14:57:06,111 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,111 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,112 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00109
2025-08-14 14:57:06,114 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,114 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,116 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00110
2025-08-14 14:57:06,121 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,121 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,124 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,124 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,126 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,126 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,127 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,127 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,128 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00111
2025-08-14 14:57:06,129 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00112
2025-08-14 14:57:06,129 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00113
2025-08-14 14:57:06,129 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00114
2025-08-14 14:57:06,131 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,131 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,134 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,134 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,139 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,139 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,139 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,139 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,142 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00115
2025-08-14 14:57:06,142 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00116
2025-08-14 14:57:06,142 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00117
2025-08-14 14:57:06,142 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00118
2025-08-14 14:57:06,165 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,165 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,169 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,169 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,169 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,169 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,171 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00119
2025-08-14 14:57:06,171 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,172 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,173 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00120
2025-08-14 14:57:06,173 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,173 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,173 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00121
2025-08-14 14:57:06,176 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00122
2025-08-14 14:57:06,176 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,176 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,182 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,182 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,183 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00123
2025-08-14 14:57:06,183 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00124
2025-08-14 14:57:06,183 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,183 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,192 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,192 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,194 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00125
2025-08-14 14:57:06,194 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00126
2025-08-14 14:57:06,194 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00127
2025-08-14 14:57:06,196 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,196 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,197 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00128
2025-08-14 14:57:06,210 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,210 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,211 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00129
2025-08-14 14:57:06,216 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,216 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,218 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,218 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,219 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,219 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,224 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,224 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00130
2025-08-14 14:57:06,226 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00131
2025-08-14 14:57:06,226 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00132
2025-08-14 14:57:06,228 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,228 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,233 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,233 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,234 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00133
2025-08-14 14:57:06,234 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00134
2025-08-14 14:57:06,235 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,236 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,237 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,237 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,238 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00135
2025-08-14 14:57:06,238 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00136
2025-08-14 14:57:06,238 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00137
2025-08-14 14:57:06,252 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,252 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,253 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00138
2025-08-14 14:57:06,254 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,254 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,255 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00139
2025-08-14 14:57:06,261 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,261 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,262 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00140
2025-08-14 14:57:06,263 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,263 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,263 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,263 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,266 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00141
2025-08-14 14:57:06,266 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00142
2025-08-14 14:57:06,272 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,272 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,279 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,279 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,279 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,279 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,281 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00143
2025-08-14 14:57:06,282 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00144
2025-08-14 14:57:06,291 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,291 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,293 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,293 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00145
2025-08-14 14:57:06,293 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,293 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00146
2025-08-14 14:57:06,294 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00147
2025-08-14 14:57:06,299 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,299 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,305 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,306 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,306 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,306 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,308 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,309 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,309 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,310 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,312 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00148
2025-08-14 14:57:06,312 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00149
2025-08-14 14:57:06,312 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00150
2025-08-14 14:57:06,312 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00151
2025-08-14 14:57:06,312 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00152
2025-08-14 14:57:06,316 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,316 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,317 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00153
2025-08-14 14:57:06,324 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,324 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,334 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,334 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,335 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00154
2025-08-14 14:57:06,335 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00155
2025-08-14 14:57:06,343 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,343 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,348 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,348 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,350 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,350 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,351 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00156
2025-08-14 14:57:06,352 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,352 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00157
2025-08-14 14:57:06,352 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,352 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00158
2025-08-14 14:57:06,354 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,354 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,362 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,362 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,363 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,363 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,366 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,366 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00159
2025-08-14 14:57:06,366 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,366 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00160
2025-08-14 14:57:06,368 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,368 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00161
2025-08-14 14:57:06,368 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,368 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00162
2025-08-14 14:57:06,369 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00163
2025-08-14 14:57:06,369 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00164
2025-08-14 14:57:06,388 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,389 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,388 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,390 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,391 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00165
2025-08-14 14:57:06,391 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00166
2025-08-14 14:57:06,398 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,398 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,399 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,399 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,404 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,404 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,406 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,406 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00167
2025-08-14 14:57:06,406 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,408 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,408 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,409 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,410 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,411 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00168
2025-08-14 14:57:06,411 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00169
2025-08-14 14:57:06,411 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00170
2025-08-14 14:57:06,411 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00171
2025-08-14 14:57:06,411 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00172
2025-08-14 14:57:06,414 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,414 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,422 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,422 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,423 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00173
2025-08-14 14:57:06,423 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00174
2025-08-14 14:57:06,441 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,441 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,443 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,444 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,444 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,444 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,445 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00175
2025-08-14 14:57:06,448 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,448 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,452 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,452 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,458 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,458 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,460 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,460 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,468 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,468 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,477 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,477 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,484 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,484 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,490 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,490 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,491 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,491 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,494 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,494 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00176
2025-08-14 14:57:06,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00177
2025-08-14 14:57:06,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00178
2025-08-14 14:57:06,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00179
2025-08-14 14:57:06,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00180
2025-08-14 14:57:06,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00181
2025-08-14 14:57:06,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00182
2025-08-14 14:57:06,496 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00183
2025-08-14 14:57:06,496 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00184
2025-08-14 14:57:06,496 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00185
2025-08-14 14:57:06,496 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,496 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,499 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,499 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,500 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00186
2025-08-14 14:57:06,500 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00187
2025-08-14 14:57:06,500 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00188
2025-08-14 14:57:06,500 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00189
2025-08-14 14:57:06,514 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,514 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,526 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,526 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,527 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,527 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,528 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,530 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00190
2025-08-14 14:57:06,530 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,530 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00191
2025-08-14 14:57:06,531 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00192
2025-08-14 14:57:06,533 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,533 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,534 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,534 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00193
2025-08-14 14:57:06,535 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,535 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,535 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00194
2025-08-14 14:57:06,535 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,538 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00195
2025-08-14 14:57:06,538 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00196
2025-08-14 14:57:06,539 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,539 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,540 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,540 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00197
2025-08-14 14:57:06,540 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,542 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00198
2025-08-14 14:57:06,554 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,554 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,555 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00199
2025-08-14 14:57:06,569 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,569 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,571 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,571 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00200
2025-08-14 14:57:06,571 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00201
2025-08-14 14:57:06,574 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,574 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,577 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,577 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,582 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,582 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,584 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,584 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,587 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,587 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,588 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,589 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,589 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,589 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,591 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00202
2025-08-14 14:57:06,592 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00203
2025-08-14 14:57:06,592 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00204
2025-08-14 14:57:06,592 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00205
2025-08-14 14:57:06,592 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00206
2025-08-14 14:57:06,592 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00207
2025-08-14 14:57:06,592 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00208
2025-08-14 14:57:06,608 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,609 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,610 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00209
2025-08-14 14:57:06,615 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,615 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,618 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,618 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,620 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,620 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,625 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,625 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,627 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,627 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,628 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,628 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00210
2025-08-14 14:57:06,629 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,629 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00211
2025-08-14 14:57:06,630 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00212
2025-08-14 14:57:06,630 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00213
2025-08-14 14:57:06,630 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00214
2025-08-14 14:57:06,630 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00215
2025-08-14 14:57:06,631 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,631 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,632 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00216
2025-08-14 14:57:06,645 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,646 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,647 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,647 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,648 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00217
2025-08-14 14:57:06,649 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00218
2025-08-14 14:57:06,658 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,658 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,661 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,661 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,663 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,663 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,664 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,664 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,666 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00219
2025-08-14 14:57:06,666 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00220
2025-08-14 14:57:06,666 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00221
2025-08-14 14:57:06,666 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00222
2025-08-14 14:57:06,671 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,671 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,673 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,673 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,675 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,675 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,681 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,681 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,682 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00223
2025-08-14 14:57:06,682 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00224
2025-08-14 14:57:06,682 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00225
2025-08-14 14:57:06,682 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00226
2025-08-14 14:57:06,701 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,701 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,702 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00227
2025-08-14 14:57:06,702 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,703 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,705 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,705 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,705 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,706 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,706 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,707 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,710 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00228
2025-08-14 14:57:06,710 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00229
2025-08-14 14:57:06,710 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00230
2025-08-14 14:57:06,710 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00231
2025-08-14 14:57:06,715 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,715 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,717 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,717 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,719 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,719 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,720 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00232
2025-08-14 14:57:06,720 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00233
2025-08-14 14:57:06,721 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,721 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00234
2025-08-14 14:57:06,721 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,722 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00235
2025-08-14 14:57:06,736 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,736 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00236
2025-08-14 14:57:06,748 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,748 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,748 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,748 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,753 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,753 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,757 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,757 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00237
2025-08-14 14:57:06,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00238
2025-08-14 14:57:06,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00239
2025-08-14 14:57:06,759 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,759 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,761 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,761 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,767 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,767 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,773 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,773 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,777 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,777 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,778 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00240
2025-08-14 14:57:06,779 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00241
2025-08-14 14:57:06,779 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00242
2025-08-14 14:57:06,779 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00243
2025-08-14 14:57:06,779 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00244
2025-08-14 14:57:06,779 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00245
2025-08-14 14:57:06,790 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,790 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,792 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,792 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00246
2025-08-14 14:57:06,793 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,793 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,793 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,794 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00247
2025-08-14 14:57:06,796 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,796 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00248
2025-08-14 14:57:06,797 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,798 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00249
2025-08-14 14:57:06,803 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,803 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,805 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,805 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,812 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,813 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,813 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,813 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,814 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00250
2025-08-14 14:57:06,815 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00251
2025-08-14 14:57:06,815 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00252
2025-08-14 14:57:06,815 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00253
2025-08-14 14:57:06,828 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,828 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,829 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00254
2025-08-14 14:57:06,836 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,836 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,838 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00255
2025-08-14 14:57:06,838 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,838 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,840 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,840 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,845 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,845 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,845 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,846 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,848 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00256
2025-08-14 14:57:06,848 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,848 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00257
2025-08-14 14:57:06,849 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00258
2025-08-14 14:57:06,849 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00259
2025-08-14 14:57:06,848 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,850 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,850 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00260
2025-08-14 14:57:06,850 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,852 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00261
2025-08-14 14:57:06,865 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,865 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00262
2025-08-14 14:57:06,869 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,869 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00263
2025-08-14 14:57:06,882 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,882 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,883 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,883 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,885 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00264
2025-08-14 14:57:06,885 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,885 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,888 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,888 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,894 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,895 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,896 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,896 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,896 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,897 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00265
2025-08-14 14:57:06,896 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,898 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00266
2025-08-14 14:57:06,900 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00267
2025-08-14 14:57:06,900 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00268
2025-08-14 14:57:06,901 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,901 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,902 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00269
2025-08-14 14:57:06,902 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00270
2025-08-14 14:57:06,902 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00271
2025-08-14 14:57:06,909 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,909 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,910 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00272
2025-08-14 14:57:06,925 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,926 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,926 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,927 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00273
2025-08-14 14:57:06,926 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,928 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,929 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00274
2025-08-14 14:57:06,929 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,932 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,932 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,941 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,942 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,942 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,942 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,942 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,943 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,945 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00275
2025-08-14 14:57:06,946 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00276
2025-08-14 14:57:06,946 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00277
2025-08-14 14:57:06,946 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00278
2025-08-14 14:57:06,946 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00279
2025-08-14 14:57:06,953 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,953 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,956 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,956 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,960 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,960 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,961 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00280
2025-08-14 14:57:06,961 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00281
2025-08-14 14:57:06,961 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00282
2025-08-14 14:57:06,972 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,972 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,972 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,973 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,975 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00283
2025-08-14 14:57:06,979 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,979 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,982 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,983 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,984 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00284
2025-08-14 14:57:06,984 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00285
2025-08-14 14:57:06,984 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00286
2025-08-14 14:57:06,988 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,988 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,990 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,990 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,997 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,998 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:06,998 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:06,998 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,000 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00287
2025-08-14 14:57:07,001 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00288
2025-08-14 14:57:07,001 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00289
2025-08-14 14:57:07,001 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00290
2025-08-14 14:57:07,011 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,011 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,012 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00291
2025-08-14 14:57:07,016 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,016 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,018 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,018 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,021 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,021 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,033 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,033 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,034 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,034 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,038 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,038 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,044 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,044 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,053 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,053 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,064 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,064 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,067 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,067 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,074 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,074 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,081 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,081 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,087 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,087 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00292
2025-08-14 14:57:07,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00293
2025-08-14 14:57:07,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00294
2025-08-14 14:57:07,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00295
2025-08-14 14:57:07,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00296
2025-08-14 14:57:07,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00297
2025-08-14 14:57:07,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00298
2025-08-14 14:57:07,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00299
2025-08-14 14:57:07,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00300
2025-08-14 14:57:07,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00301
2025-08-14 14:57:07,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00302
2025-08-14 14:57:07,089 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,090 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,094 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,094 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,096 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,096 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,109 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,109 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,115 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,115 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,117 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,117 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,120 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,120 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,121 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00303
2025-08-14 14:57:07,121 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00304
2025-08-14 14:57:07,121 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00305
2025-08-14 14:57:07,121 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00306
2025-08-14 14:57:07,121 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00307
2025-08-14 14:57:07,121 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00308
2025-08-14 14:57:07,121 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00309
2025-08-14 14:57:07,121 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00310
2025-08-14 14:57:07,122 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,122 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,123 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00311
2025-08-14 14:57:07,123 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00312
2025-08-14 14:57:07,126 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,126 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,127 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00313
2025-08-14 14:57:07,134 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,134 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,144 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,144 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,146 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,146 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,147 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00314
2025-08-14 14:57:07,147 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00315
2025-08-14 14:57:07,149 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,149 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,150 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00316
2025-08-14 14:57:07,151 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00317
2025-08-14 14:57:07,154 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,154 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,155 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00318
2025-08-14 14:57:07,160 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,160 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,163 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,163 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,170 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,170 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,171 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00319
2025-08-14 14:57:07,171 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00320
2025-08-14 14:57:07,171 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00321
2025-08-14 14:57:07,172 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,172 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,177 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,177 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,178 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00322
2025-08-14 14:57:07,178 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00323
2025-08-14 14:57:07,185 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,186 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,187 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00324
2025-08-14 14:57:07,188 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,188 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,189 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00325
2025-08-14 14:57:07,197 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,197 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,203 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,204 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,204 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,204 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,206 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,207 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,207 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00326
2025-08-14 14:57:07,208 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,208 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,209 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00327
2025-08-14 14:57:07,210 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00328
2025-08-14 14:57:07,210 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00329
2025-08-14 14:57:07,210 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00330
2025-08-14 14:57:07,216 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,216 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,225 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,225 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,226 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00331
2025-08-14 14:57:07,226 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00332
2025-08-14 14:57:07,230 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,230 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,231 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,232 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,232 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,232 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,234 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00333
2025-08-14 14:57:07,234 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00334
2025-08-14 14:57:07,234 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00335
2025-08-14 14:57:07,241 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,241 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,242 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00336
2025-08-14 14:57:07,247 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,247 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,248 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00337
2025-08-14 14:57:07,251 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,251 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,261 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,261 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,264 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,265 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,265 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,265 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,266 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00338
2025-08-14 14:57:07,267 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00339
2025-08-14 14:57:07,267 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00340
2025-08-14 14:57:07,267 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00341
2025-08-14 14:57:07,273 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,274 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,278 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,278 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,281 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,281 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,282 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00342
2025-08-14 14:57:07,282 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00343
2025-08-14 14:57:07,283 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,283 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,286 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,287 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,288 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00344
2025-08-14 14:57:07,288 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00345
2025-08-14 14:57:07,288 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00346
2025-08-14 14:57:07,290 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,290 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,291 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00347
2025-08-14 14:57:07,305 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,305 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,309 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,309 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,310 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00348
2025-08-14 14:57:07,310 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00349
2025-08-14 14:57:07,318 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,318 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,322 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,322 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,324 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,324 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,326 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,326 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,326 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,327 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,328 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00350
2025-08-14 14:57:07,329 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00351
2025-08-14 14:57:07,329 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00352
2025-08-14 14:57:07,329 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00353
2025-08-14 14:57:07,334 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,334 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,335 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,335 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,336 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00354
2025-08-14 14:57:07,337 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00355
2025-08-14 14:57:07,341 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,341 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,342 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00356
2025-08-14 14:57:07,342 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00357
2025-08-14 14:57:07,349 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,350 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,351 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00358
2025-08-14 14:57:07,353 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,353 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,354 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00359
2025-08-14 14:57:07,362 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,362 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,363 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00360
2025-08-14 14:57:07,368 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,369 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,371 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,371 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,377 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,377 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,378 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,379 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,380 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00361
2025-08-14 14:57:07,380 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00362
2025-08-14 14:57:07,380 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00363
2025-08-14 14:57:07,386 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,386 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,387 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00364
2025-08-14 14:57:07,387 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00365
2025-08-14 14:57:07,390 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,390 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,391 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00366
2025-08-14 14:57:07,396 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,396 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,396 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,396 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,397 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00367
2025-08-14 14:57:07,398 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,399 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,400 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00368
2025-08-14 14:57:07,400 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00369
2025-08-14 14:57:07,406 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,407 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,408 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00370
2025-08-14 14:57:07,417 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,417 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,419 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,419 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,420 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00371
2025-08-14 14:57:07,420 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00372
2025-08-14 14:57:07,422 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,422 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,423 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00373
2025-08-14 14:57:07,434 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,434 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,435 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00374
2025-08-14 14:57:07,443 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,444 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,444 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,444 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,446 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,447 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,447 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,449 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,450 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00375
2025-08-14 14:57:07,450 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00376
2025-08-14 14:57:07,453 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,453 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,453 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,453 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,454 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00377
2025-08-14 14:57:07,456 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00378
2025-08-14 14:57:07,456 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00379
2025-08-14 14:57:07,456 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00380
2025-08-14 14:57:07,461 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,461 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,463 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,463 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00381
2025-08-14 14:57:07,463 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,464 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00382
2025-08-14 14:57:07,465 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,465 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,466 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00383
2025-08-14 14:57:07,488 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,488 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,490 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,490 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,491 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00384
2025-08-14 14:57:07,491 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00385
2025-08-14 14:57:07,492 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,492 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,499 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,499 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,502 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,502 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,503 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00386
2025-08-14 14:57:07,505 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,506 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,506 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,506 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,506 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,507 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,509 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,510 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,511 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00387
2025-08-14 14:57:07,512 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00388
2025-08-14 14:57:07,512 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,512 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00389
2025-08-14 14:57:07,511 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,513 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00390
2025-08-14 14:57:07,514 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00391
2025-08-14 14:57:07,514 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00392
2025-08-14 14:57:07,514 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00393
2025-08-14 14:57:07,533 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,533 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,534 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00394
2025-08-14 14:57:07,535 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,535 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,544 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,544 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,545 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,546 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,547 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00395
2025-08-14 14:57:07,547 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00396
2025-08-14 14:57:07,547 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00397
2025-08-14 14:57:07,549 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,549 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,555 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,555 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,557 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,557 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,558 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,558 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00398
2025-08-14 14:57:07,560 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00399
2025-08-14 14:57:07,565 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,565 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,566 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,566 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00400
2025-08-14 14:57:07,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00401
2025-08-14 14:57:07,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00402
2025-08-14 14:57:07,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00403
2025-08-14 14:57:07,577 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,577 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,579 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,579 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00404
2025-08-14 14:57:07,579 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,580 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00405
2025-08-14 14:57:07,589 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,589 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00406
2025-08-14 14:57:07,592 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,592 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,598 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,598 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,601 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,601 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,603 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,603 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00407
2025-08-14 14:57:07,603 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00408
2025-08-14 14:57:07,605 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00409
2025-08-14 14:57:07,612 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,612 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,613 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00410
2025-08-14 14:57:07,614 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00411
2025-08-14 14:57:07,620 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,620 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,621 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00412
2025-08-14 14:57:07,623 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,623 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,625 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,625 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,626 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00413
2025-08-14 14:57:07,630 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,630 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,631 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00414
2025-08-14 14:57:07,631 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00415
2025-08-14 14:57:07,633 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,633 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00416
2025-08-14 14:57:07,642 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,642 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,648 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,648 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,657 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,657 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,666 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,666 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,669 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,669 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,675 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,675 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,676 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,676 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,676 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,676 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,679 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,680 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00417
2025-08-14 14:57:07,680 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,680 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00418
2025-08-14 14:57:07,681 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00419
2025-08-14 14:57:07,681 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00420
2025-08-14 14:57:07,682 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00421
2025-08-14 14:57:07,682 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00422
2025-08-14 14:57:07,682 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00423
2025-08-14 14:57:07,682 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,682 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,683 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00424
2025-08-14 14:57:07,684 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00425
2025-08-14 14:57:07,684 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00426
2025-08-14 14:57:07,685 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,685 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,686 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00427
2025-08-14 14:57:07,692 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,692 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,694 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00428
2025-08-14 14:57:07,710 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,710 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,712 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,712 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,713 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00429
2025-08-14 14:57:07,713 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00430
2025-08-14 14:57:07,724 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,724 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,724 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,725 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00431
2025-08-14 14:57:07,726 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,726 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,727 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,729 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,729 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,730 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,730 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,731 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00432
2025-08-14 14:57:07,733 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,733 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,734 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00433
2025-08-14 14:57:07,734 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00434
2025-08-14 14:57:07,734 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00435
2025-08-14 14:57:07,736 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,736 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,740 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,740 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,741 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00436
2025-08-14 14:57:07,741 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00437
2025-08-14 14:57:07,742 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00438
2025-08-14 14:57:07,754 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,754 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,755 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00439
2025-08-14 14:57:07,767 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,768 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,769 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00440
2025-08-14 14:57:07,771 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,771 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,772 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,773 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,774 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,774 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,779 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,779 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,780 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00441
2025-08-14 14:57:07,781 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,781 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00442
2025-08-14 14:57:07,781 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,781 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00443
2025-08-14 14:57:07,782 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00444
2025-08-14 14:57:07,789 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,789 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,797 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,798 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,798 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,798 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,798 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,799 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00445
2025-08-14 14:57:07,801 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,801 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00446
2025-08-14 14:57:07,802 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00447
2025-08-14 14:57:07,802 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00448
2025-08-14 14:57:07,802 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00449
2025-08-14 14:57:07,816 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,816 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,817 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,818 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,820 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,820 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,825 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,825 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,834 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,834 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,841 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,841 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,844 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,844 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,844 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,845 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,857 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,857 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,860 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,860 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,862 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,862 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,864 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,864 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,867 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,867 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00450
2025-08-14 14:57:07,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00451
2025-08-14 14:57:07,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00452
2025-08-14 14:57:07,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00453
2025-08-14 14:57:07,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00454
2025-08-14 14:57:07,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00455
2025-08-14 14:57:07,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00456
2025-08-14 14:57:07,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00457
2025-08-14 14:57:07,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00458
2025-08-14 14:57:07,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00459
2025-08-14 14:57:07,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00460
2025-08-14 14:57:07,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00461
2025-08-14 14:57:07,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00462
2025-08-14 14:57:07,870 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,870 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00463
2025-08-14 14:57:07,885 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,885 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,889 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,889 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,890 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,890 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00464
2025-08-14 14:57:07,891 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,891 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00465
2025-08-14 14:57:07,904 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,904 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,906 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,906 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,907 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,907 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,908 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00466
2025-08-14 14:57:07,909 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00467
2025-08-14 14:57:07,910 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,910 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,914 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,914 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,916 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,916 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,917 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00468
2025-08-14 14:57:07,917 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00469
2025-08-14 14:57:07,917 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00470
2025-08-14 14:57:07,917 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00471
2025-08-14 14:57:07,923 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,923 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,924 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00472
2025-08-14 14:57:07,924 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00473
2025-08-14 14:57:07,928 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,928 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,929 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00474
2025-08-14 14:57:07,934 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,934 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,943 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,943 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,944 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00475
2025-08-14 14:57:07,944 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00476
2025-08-14 14:57:07,948 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,949 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,950 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00477
2025-08-14 14:57:07,952 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,952 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,954 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,954 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,958 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,958 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,962 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,962 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,963 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00478
2025-08-14 14:57:07,963 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00479
2025-08-14 14:57:07,963 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00480
2025-08-14 14:57:07,964 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00481
2025-08-14 14:57:07,971 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,971 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,974 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,974 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,975 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00482
2025-08-14 14:57:07,977 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,977 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,979 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,979 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,980 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00483
2025-08-14 14:57:07,980 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00484
2025-08-14 14:57:07,980 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00485
2025-08-14 14:57:07,993 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,993 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,996 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,996 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:07,997 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:07,997 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,002 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,003 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,004 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,004 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,005 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00486
2025-08-14 14:57:08,005 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00487
2025-08-14 14:57:08,006 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00488
2025-08-14 14:57:08,006 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00489
2025-08-14 14:57:08,006 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00490
2025-08-14 14:57:08,014 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,014 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,017 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,017 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,018 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00491
2025-08-14 14:57:08,018 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00492
2025-08-14 14:57:08,020 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,020 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,032 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,032 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,033 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00493
2025-08-14 14:57:08,033 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00494
2025-08-14 14:57:08,035 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,035 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,036 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00495
2025-08-14 14:57:08,038 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,038 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,039 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00496
2025-08-14 14:57:08,039 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,039 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,041 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00497
2025-08-14 14:57:08,042 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,042 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,043 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00498
2025-08-14 14:57:08,047 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,048 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,049 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00499
2025-08-14 14:57:08,058 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,058 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,059 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,060 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,061 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00500
2025-08-14 14:57:08,061 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00501
2025-08-14 14:57:08,063 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,063 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,072 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,072 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00502
2025-08-14 14:57:08,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00503
2025-08-14 14:57:08,082 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,082 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,083 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,084 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,087 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,087 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,091 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,091 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,091 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,092 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,093 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,093 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,096 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00504
2025-08-14 14:57:08,096 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00505
2025-08-14 14:57:08,096 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00506
2025-08-14 14:57:08,096 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00507
2025-08-14 14:57:08,096 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00508
2025-08-14 14:57:08,096 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00509
2025-08-14 14:57:08,102 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,102 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,103 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00510
2025-08-14 14:57:08,107 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,107 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,115 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,115 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,116 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00511
2025-08-14 14:57:08,117 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00512
2025-08-14 14:57:08,123 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,123 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,128 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,128 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,128 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,128 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,129 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00513
2025-08-14 14:57:08,131 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00514
2025-08-14 14:57:08,131 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00515
2025-08-14 14:57:08,132 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,132 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,133 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00516
2025-08-14 14:57:08,141 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,142 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,146 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,146 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,150 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,150 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,151 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,152 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,153 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,153 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00517
2025-08-14 14:57:08,153 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,153 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00518
2025-08-14 14:57:08,155 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00519
2025-08-14 14:57:08,155 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00520
2025-08-14 14:57:08,155 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00521
2025-08-14 14:57:08,165 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,165 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,170 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,170 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,171 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00522
2025-08-14 14:57:08,171 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00523
2025-08-14 14:57:08,174 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,174 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,175 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00524
2025-08-14 14:57:08,183 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,183 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,185 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,185 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,186 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00525
2025-08-14 14:57:08,186 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00526
2025-08-14 14:57:08,187 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,187 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,188 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00527
2025-08-14 14:57:08,189 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,189 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,190 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00528
2025-08-14 14:57:08,199 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,199 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,205 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,205 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,206 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00529
2025-08-14 14:57:08,207 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,207 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,209 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,209 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,211 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00530
2025-08-14 14:57:08,211 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00531
2025-08-14 14:57:08,211 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00532
2025-08-14 14:57:08,218 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,218 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,227 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,227 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,229 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,229 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00533
2025-08-14 14:57:08,229 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,229 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00534
2025-08-14 14:57:08,230 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00535
2025-08-14 14:57:08,231 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,231 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,236 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,236 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,240 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,240 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,241 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00536
2025-08-14 14:57:08,241 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00537
2025-08-14 14:57:08,241 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00538
2025-08-14 14:57:08,243 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,243 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,244 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00539
2025-08-14 14:57:08,252 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,252 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,260 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,261 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,262 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00540
2025-08-14 14:57:08,262 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00541
2025-08-14 14:57:08,262 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,262 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,268 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,268 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,269 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00542
2025-08-14 14:57:08,269 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00543
2025-08-14 14:57:08,273 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,273 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,275 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,275 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,282 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,282 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,283 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00544
2025-08-14 14:57:08,283 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00545
2025-08-14 14:57:08,283 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00546
2025-08-14 14:57:08,286 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,286 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,294 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,294 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,295 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,296 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,307 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,307 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,317 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,317 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,318 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,318 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,319 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,321 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,325 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,325 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,326 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,326 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00547
2025-08-14 14:57:08,326 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,327 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00548
2025-08-14 14:57:08,328 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00549
2025-08-14 14:57:08,328 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00550
2025-08-14 14:57:08,328 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00551
2025-08-14 14:57:08,328 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00552
2025-08-14 14:57:08,328 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00553
2025-08-14 14:57:08,328 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00554
2025-08-14 14:57:08,328 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00555
2025-08-14 14:57:08,332 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,332 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,337 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,337 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,338 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,338 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,339 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00556
2025-08-14 14:57:08,340 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00557
2025-08-14 14:57:08,340 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00558
2025-08-14 14:57:08,351 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,352 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,352 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,352 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,353 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00559
2025-08-14 14:57:08,354 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00560
2025-08-14 14:57:08,362 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,362 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,364 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,364 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00561
2025-08-14 14:57:08,364 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,365 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00562
2025-08-14 14:57:08,375 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,376 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,377 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,377 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,378 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00563
2025-08-14 14:57:08,381 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,381 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,384 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,384 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,392 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,392 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,400 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,400 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,400 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,400 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,402 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00564
2025-08-14 14:57:08,403 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00565
2025-08-14 14:57:08,403 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00566
2025-08-14 14:57:08,403 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00567
2025-08-14 14:57:08,403 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00568
2025-08-14 14:57:08,403 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00569
2025-08-14 14:57:08,407 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,407 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,408 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,409 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,409 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,409 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,410 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00570
2025-08-14 14:57:08,412 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00571
2025-08-14 14:57:08,412 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00572
2025-08-14 14:57:08,419 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,419 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,420 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00573
2025-08-14 14:57:08,423 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,423 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,432 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,433 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,434 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00574
2025-08-14 14:57:08,434 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00575
2025-08-14 14:57:08,445 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,445 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,445 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,446 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,447 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,449 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,451 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,451 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,454 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,454 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,455 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,455 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,455 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00576
2025-08-14 14:57:08,457 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00577
2025-08-14 14:57:08,457 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00578
2025-08-14 14:57:08,457 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00579
2025-08-14 14:57:08,457 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00580
2025-08-14 14:57:08,464 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,464 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,465 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00581
2025-08-14 14:57:08,466 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00582
2025-08-14 14:57:08,468 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,468 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,469 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00583
2025-08-14 14:57:08,471 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,471 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,473 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00584
2025-08-14 14:57:08,488 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,488 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,489 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00585
2025-08-14 14:57:08,490 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,490 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,491 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00586
2025-08-14 14:57:08,492 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,492 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,495 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,495 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,499 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,500 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,503 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,503 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,504 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00587
2025-08-14 14:57:08,504 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00588
2025-08-14 14:57:08,504 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00589
2025-08-14 14:57:08,511 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,511 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,513 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00590
2025-08-14 14:57:08,513 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00591
2025-08-14 14:57:08,513 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,513 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,515 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,515 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,521 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,521 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,522 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00592
2025-08-14 14:57:08,522 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00593
2025-08-14 14:57:08,522 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00594
2025-08-14 14:57:08,534 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,534 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,536 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,536 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,539 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,539 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,544 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,545 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,545 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,545 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,547 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00595
2025-08-14 14:57:08,547 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00596
2025-08-14 14:57:08,547 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00597
2025-08-14 14:57:08,547 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00598
2025-08-14 14:57:08,547 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00599
2025-08-14 14:57:08,555 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,555 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,558 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,558 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,565 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,565 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,566 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00600
2025-08-14 14:57:08,569 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,570 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,571 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00601
2025-08-14 14:57:08,571 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00602
2025-08-14 14:57:08,571 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00603
2025-08-14 14:57:08,576 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,576 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,577 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00604
2025-08-14 14:57:08,579 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,579 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,580 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,580 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,580 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00605
2025-08-14 14:57:08,581 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00606
2025-08-14 14:57:08,584 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,584 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,585 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00607
2025-08-14 14:57:08,589 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,589 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00608
2025-08-14 14:57:08,601 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,602 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,603 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,604 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00609
2025-08-14 14:57:08,604 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,604 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,605 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00610
2025-08-14 14:57:08,607 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00611
2025-08-14 14:57:08,622 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,622 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,623 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00612
2025-08-14 14:57:08,624 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,625 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,625 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,625 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,628 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,628 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,629 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00613
2025-08-14 14:57:08,630 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,630 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,632 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,632 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,633 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00614
2025-08-14 14:57:08,633 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00615
2025-08-14 14:57:08,633 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00616
2025-08-14 14:57:08,634 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00617
2025-08-14 14:57:08,635 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00618
2025-08-14 14:57:08,646 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,646 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,649 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,649 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,657 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,657 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,658 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00619
2025-08-14 14:57:08,659 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00620
2025-08-14 14:57:08,659 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00621
2025-08-14 14:57:08,670 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,670 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,672 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,672 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,674 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,675 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,676 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,676 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,678 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00622
2025-08-14 14:57:08,678 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00623
2025-08-14 14:57:08,678 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00624
2025-08-14 14:57:08,678 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,678 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,686 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,686 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,688 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,688 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,689 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00625
2025-08-14 14:57:08,689 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00626
2025-08-14 14:57:08,689 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00627
2025-08-14 14:57:08,689 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00628
2025-08-14 14:57:08,692 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,693 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,694 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,695 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,696 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00629
2025-08-14 14:57:08,696 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00630
2025-08-14 14:57:08,713 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,713 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,714 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00631
2025-08-14 14:57:08,716 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,716 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,717 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,718 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,719 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,719 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00632
2025-08-14 14:57:08,719 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,720 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00633
2025-08-14 14:57:08,721 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00634
2025-08-14 14:57:08,722 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,722 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,731 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,731 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,732 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00635
2025-08-14 14:57:08,732 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00636
2025-08-14 14:57:08,736 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,736 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,738 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,738 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,741 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,741 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,742 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00637
2025-08-14 14:57:08,746 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,747 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,748 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00638
2025-08-14 14:57:08,748 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00639
2025-08-14 14:57:08,748 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00640
2025-08-14 14:57:08,759 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,759 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,762 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,762 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,764 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,764 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,766 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,766 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,771 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,771 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,772 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00641
2025-08-14 14:57:08,772 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00642
2025-08-14 14:57:08,773 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00643
2025-08-14 14:57:08,773 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00644
2025-08-14 14:57:08,773 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00645
2025-08-14 14:57:08,778 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,778 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,781 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,782 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,786 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,786 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,787 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00646
2025-08-14 14:57:08,787 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00647
2025-08-14 14:57:08,787 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00648
2025-08-14 14:57:08,796 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,796 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,796 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00649
2025-08-14 14:57:08,802 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,802 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,805 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,805 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,806 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00650
2025-08-14 14:57:08,807 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,807 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00651
2025-08-14 14:57:08,807 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,808 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00652
2025-08-14 14:57:08,809 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,809 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00653
2025-08-14 14:57:08,810 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,811 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,812 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00654
2025-08-14 14:57:08,820 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,820 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,825 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,825 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,827 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,827 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,828 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00655
2025-08-14 14:57:08,828 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00656
2025-08-14 14:57:08,828 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00657
2025-08-14 14:57:08,840 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,841 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,842 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00658
2025-08-14 14:57:08,846 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,846 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,851 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,851 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,855 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,855 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,857 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,858 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,862 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,862 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,864 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,864 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,868 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,868 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,882 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,882 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,889 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,889 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,895 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,896 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,896 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,896 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,899 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,899 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,902 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,902 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,904 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,904 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,911 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,911 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,918 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,918 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,919 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00659
2025-08-14 14:57:08,919 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00660
2025-08-14 14:57:08,919 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00661
2025-08-14 14:57:08,919 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00662
2025-08-14 14:57:08,919 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00663
2025-08-14 14:57:08,919 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00664
2025-08-14 14:57:08,920 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00665
2025-08-14 14:57:08,920 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00666
2025-08-14 14:57:08,920 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00667
2025-08-14 14:57:08,920 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00668
2025-08-14 14:57:08,920 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00669
2025-08-14 14:57:08,920 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00670
2025-08-14 14:57:08,920 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00671
2025-08-14 14:57:08,920 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00672
2025-08-14 14:57:08,920 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00673
2025-08-14 14:57:08,922 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,922 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,923 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00674
2025-08-14 14:57:08,923 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00675
2025-08-14 14:57:08,933 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,933 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,938 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,938 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,940 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00676
2025-08-14 14:57:08,940 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00677
2025-08-14 14:57:08,941 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,941 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,944 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,944 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,946 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,946 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,948 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,948 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,951 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,951 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,952 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00678
2025-08-14 14:57:08,952 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00679
2025-08-14 14:57:08,953 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00680
2025-08-14 14:57:08,953 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00681
2025-08-14 14:57:08,953 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00682
2025-08-14 14:57:08,955 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,955 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,956 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00683
2025-08-14 14:57:08,973 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,973 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00684
2025-08-14 14:57:08,977 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,977 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,980 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,980 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,981 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00685
2025-08-14 14:57:08,981 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00686
2025-08-14 14:57:08,985 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,985 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,988 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,988 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,990 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,990 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,991 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,991 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,994 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:08,994 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:08,995 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00687
2025-08-14 14:57:08,995 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00688
2025-08-14 14:57:08,995 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00689
2025-08-14 14:57:08,995 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00690
2025-08-14 14:57:08,995 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00691
2025-08-14 14:57:09,002 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,002 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,006 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,006 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,007 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00692
2025-08-14 14:57:09,007 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00693
2025-08-14 14:57:09,024 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,024 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,029 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,030 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,030 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,030 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,031 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00694
2025-08-14 14:57:09,033 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,033 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00695
2025-08-14 14:57:09,033 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,034 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,033 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,038 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,039 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,039 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,039 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,040 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00696
2025-08-14 14:57:09,042 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00697
2025-08-14 14:57:09,042 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00698
2025-08-14 14:57:09,042 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00699
2025-08-14 14:57:09,042 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00700
2025-08-14 14:57:09,046 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,046 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,049 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,049 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,050 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00701
2025-08-14 14:57:09,050 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00702
2025-08-14 14:57:09,061 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,061 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,062 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00703
2025-08-14 14:57:09,068 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,068 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,069 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00704
2025-08-14 14:57:09,074 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,074 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,075 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00705
2025-08-14 14:57:09,076 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,076 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,085 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,085 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,086 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,087 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,087 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,087 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00706
2025-08-14 14:57:09,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00707
2025-08-14 14:57:09,090 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00708
2025-08-14 14:57:09,093 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,093 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,097 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,097 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00709
2025-08-14 14:57:09,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00710
2025-08-14 14:57:09,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00711
2025-08-14 14:57:09,109 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,109 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,110 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00712
2025-08-14 14:57:09,112 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,112 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,116 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,116 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,117 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00713
2025-08-14 14:57:09,117 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00714
2025-08-14 14:57:09,118 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,118 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,121 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,121 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,122 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00715
2025-08-14 14:57:09,122 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00716
2025-08-14 14:57:09,133 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,133 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,134 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00717
2025-08-14 14:57:09,135 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,135 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,137 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,137 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,142 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,142 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,143 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00718
2025-08-14 14:57:09,143 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00719
2025-08-14 14:57:09,143 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00720
2025-08-14 14:57:09,155 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,155 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,155 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,155 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,158 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00721
2025-08-14 14:57:09,165 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,165 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,166 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00722
2025-08-14 14:57:09,166 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,166 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00723
2025-08-14 14:57:09,167 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,168 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,168 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,171 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,171 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,172 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00724
2025-08-14 14:57:09,172 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00725
2025-08-14 14:57:09,172 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00726
2025-08-14 14:57:09,177 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,177 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,179 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,179 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00727
2025-08-14 14:57:09,180 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,181 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00728
2025-08-14 14:57:09,181 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,181 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,182 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00729
2025-08-14 14:57:09,197 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,197 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,198 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00730
2025-08-14 14:57:09,199 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,199 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,200 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00731
2025-08-14 14:57:09,210 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,211 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,212 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,212 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,214 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,215 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,216 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00732
2025-08-14 14:57:09,220 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,220 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,221 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00733
2025-08-14 14:57:09,222 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,222 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00734
2025-08-14 14:57:09,222 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,222 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00735
2025-08-14 14:57:09,224 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,224 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,226 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,226 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,226 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,226 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,229 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00736
2025-08-14 14:57:09,229 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00737
2025-08-14 14:57:09,229 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00738
2025-08-14 14:57:09,229 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00739
2025-08-14 14:57:09,242 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,243 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,251 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,251 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,253 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,253 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00740
2025-08-14 14:57:09,253 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,253 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00741
2025-08-14 14:57:09,255 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00742
2025-08-14 14:57:09,257 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,257 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,258 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00743
2025-08-14 14:57:09,266 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,266 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,269 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,269 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,271 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,271 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,273 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,273 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,274 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00744
2025-08-14 14:57:09,276 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,276 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,277 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00745
2025-08-14 14:57:09,277 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00746
2025-08-14 14:57:09,277 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00747
2025-08-14 14:57:09,281 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,281 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,282 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00748
2025-08-14 14:57:09,282 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00749
2025-08-14 14:57:09,286 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,286 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,287 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00750
2025-08-14 14:57:09,296 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,296 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,303 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,303 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,306 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,306 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00751
2025-08-14 14:57:09,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00752
2025-08-14 14:57:09,308 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00753
2025-08-14 14:57:09,310 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,310 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,311 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00754
2025-08-14 14:57:09,313 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,313 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,314 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00755
2025-08-14 14:57:09,315 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,315 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,316 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00756
2025-08-14 14:57:09,330 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,330 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,332 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,332 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,333 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,332 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,335 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00757
2025-08-14 14:57:09,335 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00758
2025-08-14 14:57:09,337 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,337 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,347 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,347 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,357 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,357 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,359 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,359 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,360 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,361 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,362 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,362 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,374 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,374 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,380 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,380 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,386 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,386 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,387 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00759
2025-08-14 14:57:09,387 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00760
2025-08-14 14:57:09,387 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00761
2025-08-14 14:57:09,387 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00762
2025-08-14 14:57:09,387 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00763
2025-08-14 14:57:09,388 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00764
2025-08-14 14:57:09,388 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00765
2025-08-14 14:57:09,388 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00766
2025-08-14 14:57:09,388 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00767
2025-08-14 14:57:09,389 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,389 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,391 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,391 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,392 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00768
2025-08-14 14:57:09,393 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,393 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00769
2025-08-14 14:57:09,393 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00770
2025-08-14 14:57:09,393 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,394 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00771
2025-08-14 14:57:09,401 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,401 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,403 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,403 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00772
2025-08-14 14:57:09,403 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,404 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00773
2025-08-14 14:57:09,405 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,405 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,406 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00774
2025-08-14 14:57:09,418 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,418 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,422 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,422 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,438 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,438 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,440 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,441 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,445 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,446 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,446 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,446 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,446 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,446 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,447 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,450 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,450 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,450 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00775
2025-08-14 14:57:09,452 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,452 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,452 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,452 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00776
2025-08-14 14:57:09,456 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00777
2025-08-14 14:57:09,456 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00778
2025-08-14 14:57:09,456 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00779
2025-08-14 14:57:09,456 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00780
2025-08-14 14:57:09,456 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00781
2025-08-14 14:57:09,456 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00782
2025-08-14 14:57:09,456 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00783
2025-08-14 14:57:09,456 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00784
2025-08-14 14:57:09,461 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,461 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,462 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00785
2025-08-14 14:57:09,464 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,464 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,465 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00786
2025-08-14 14:57:09,482 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,482 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,483 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00787
2025-08-14 14:57:09,492 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,492 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,495 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,495 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,495 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,497 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,497 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,497 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,500 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00788
2025-08-14 14:57:09,502 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,502 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,503 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00789
2025-08-14 14:57:09,503 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00790
2025-08-14 14:57:09,503 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00791
2025-08-14 14:57:09,504 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,504 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,506 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,506 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,510 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,510 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,511 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,511 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,513 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00792
2025-08-14 14:57:09,513 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00793
2025-08-14 14:57:09,513 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00794
2025-08-14 14:57:09,513 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00795
2025-08-14 14:57:09,513 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00796
2025-08-14 14:57:09,536 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,537 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,537 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,537 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,539 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00797
2025-08-14 14:57:09,539 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00798
2025-08-14 14:57:09,542 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,542 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,542 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,542 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,548 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,548 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,550 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,550 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,551 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00799
2025-08-14 14:57:09,551 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00800
2025-08-14 14:57:09,551 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00801
2025-08-14 14:57:09,552 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,552 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,557 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,557 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,558 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00802
2025-08-14 14:57:09,558 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00803
2025-08-14 14:57:09,558 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00804
2025-08-14 14:57:09,565 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,565 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,566 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00805
2025-08-14 14:57:09,572 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,572 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00806
2025-08-14 14:57:09,581 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,582 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,582 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,582 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,583 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00807
2025-08-14 14:57:09,585 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00808
2025-08-14 14:57:09,587 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,587 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,589 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,589 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00809
2025-08-14 14:57:09,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00810
2025-08-14 14:57:09,591 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,591 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,592 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00811
2025-08-14 14:57:09,595 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,596 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,605 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,605 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,606 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00812
2025-08-14 14:57:09,606 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00813
2025-08-14 14:57:09,612 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,612 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,613 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00814
2025-08-14 14:57:09,622 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,622 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,623 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00815
2025-08-14 14:57:09,627 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,627 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,627 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,628 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,630 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,630 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,632 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00816
2025-08-14 14:57:09,632 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00817
2025-08-14 14:57:09,632 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00818
2025-08-14 14:57:09,633 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,633 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,634 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,635 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,638 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,639 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,639 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,639 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,640 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00819
2025-08-14 14:57:09,641 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00820
2025-08-14 14:57:09,642 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00821
2025-08-14 14:57:09,642 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00822
2025-08-14 14:57:09,660 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,661 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,662 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00823
2025-08-14 14:57:09,667 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,667 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00824
2025-08-14 14:57:09,672 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,672 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,674 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,674 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,677 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,677 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,677 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,678 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,679 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00825
2025-08-14 14:57:09,680 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00826
2025-08-14 14:57:09,682 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,682 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,683 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00827
2025-08-14 14:57:09,684 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,684 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,684 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,684 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,689 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,689 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,690 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00828
2025-08-14 14:57:09,690 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00829
2025-08-14 14:57:09,690 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00830
2025-08-14 14:57:09,690 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00831
2025-08-14 14:57:09,691 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00832
2025-08-14 14:57:09,715 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,715 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,716 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00833
2025-08-14 14:57:09,717 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,717 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,718 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,717 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,722 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,722 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,723 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,723 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,724 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00834
2025-08-14 14:57:09,725 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00835
2025-08-14 14:57:09,725 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00836
2025-08-14 14:57:09,725 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00837
2025-08-14 14:57:09,727 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,728 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,729 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,730 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,730 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,730 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,734 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,734 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,735 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00838
2025-08-14 14:57:09,735 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00839
2025-08-14 14:57:09,735 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00840
2025-08-14 14:57:09,735 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00841
2025-08-14 14:57:09,747 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,747 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,748 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00842
2025-08-14 14:57:09,759 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,760 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,763 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,763 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,765 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,765 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,770 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,770 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,771 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00843
2025-08-14 14:57:09,772 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00844
2025-08-14 14:57:09,772 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00845
2025-08-14 14:57:09,772 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00846
2025-08-14 14:57:09,772 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,772 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,775 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,775 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,778 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,778 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,779 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00847
2025-08-14 14:57:09,780 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00848
2025-08-14 14:57:09,783 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,783 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,784 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00849
2025-08-14 14:57:09,784 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00850
2025-08-14 14:57:09,790 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,790 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,792 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00851
2025-08-14 14:57:09,803 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,803 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,807 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,807 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,809 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,809 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,811 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,811 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,812 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00852
2025-08-14 14:57:09,812 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00853
2025-08-14 14:57:09,812 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00854
2025-08-14 14:57:09,812 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00855
2025-08-14 14:57:09,816 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,817 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,825 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,825 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,825 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,825 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,828 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00856
2025-08-14 14:57:09,828 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,828 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00857
2025-08-14 14:57:09,829 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,829 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00858
2025-08-14 14:57:09,833 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,833 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,834 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00859
2025-08-14 14:57:09,834 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00860
2025-08-14 14:57:09,844 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,844 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,846 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,846 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,847 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00861
2025-08-14 14:57:09,847 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00862
2025-08-14 14:57:09,852 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,852 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,853 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00863
2025-08-14 14:57:09,854 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,854 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,855 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00864
2025-08-14 14:57:09,866 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,866 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,869 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,869 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00865
2025-08-14 14:57:09,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00866
2025-08-14 14:57:09,871 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,871 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,875 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,875 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,882 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,882 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00867
2025-08-14 14:57:09,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00868
2025-08-14 14:57:09,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00869
2025-08-14 14:57:09,886 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,886 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,888 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,888 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,889 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00870
2025-08-14 14:57:09,889 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00871
2025-08-14 14:57:09,897 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,897 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,898 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,898 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,902 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,902 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,903 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00872
2025-08-14 14:57:09,903 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00873
2025-08-14 14:57:09,903 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00874
2025-08-14 14:57:09,910 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,910 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,911 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00875
2025-08-14 14:57:09,918 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,918 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,920 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,920 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,928 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,928 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,933 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,933 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,934 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00876
2025-08-14 14:57:09,934 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00877
2025-08-14 14:57:09,934 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00878
2025-08-14 14:57:09,940 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,940 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,941 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00879
2025-08-14 14:57:09,941 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00880
2025-08-14 14:57:09,942 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,942 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,943 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,944 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,944 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,944 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,945 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00881
2025-08-14 14:57:09,946 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00882
2025-08-14 14:57:09,946 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00883
2025-08-14 14:57:09,954 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,954 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,957 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,957 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,958 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00884
2025-08-14 14:57:09,958 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00885
2025-08-14 14:57:09,962 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,962 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,963 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00886
2025-08-14 14:57:09,964 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,964 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,965 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00887
2025-08-14 14:57:09,975 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,975 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,976 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00888
2025-08-14 14:57:09,989 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,990 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,990 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,990 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,991 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,993 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,994 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00889
2025-08-14 14:57:09,994 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,995 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:09,996 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00890
2025-08-14 14:57:09,996 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00891
2025-08-14 14:57:09,996 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00892
2025-08-14 14:57:09,999 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:09,999 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,001 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,001 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,003 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00893
2025-08-14 14:57:10,003 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00894
2025-08-14 14:57:10,008 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,008 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,012 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,012 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,013 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,013 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,015 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00895
2025-08-14 14:57:10,015 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00896
2025-08-14 14:57:10,015 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00897
2025-08-14 14:57:10,017 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,017 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,018 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00898
2025-08-14 14:57:10,034 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,034 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,035 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00899
2025-08-14 14:57:10,037 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,037 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,043 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,043 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,049 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,049 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,056 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,056 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,057 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,057 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,059 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,059 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,064 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,064 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,064 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,064 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,065 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00900
2025-08-14 14:57:10,067 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00901
2025-08-14 14:57:10,067 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00902
2025-08-14 14:57:10,067 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00903
2025-08-14 14:57:10,067 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00904
2025-08-14 14:57:10,067 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00905
2025-08-14 14:57:10,067 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00906
2025-08-14 14:57:10,069 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,069 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,070 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00907
2025-08-14 14:57:10,070 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00908
2025-08-14 14:57:10,079 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,079 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,080 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00909
2025-08-14 14:57:10,084 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,084 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,085 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00910
2025-08-14 14:57:10,088 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,088 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00911
2025-08-14 14:57:10,101 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,101 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,103 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,103 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,105 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,105 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,106 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00912
2025-08-14 14:57:10,106 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00913
2025-08-14 14:57:10,112 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,112 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,113 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00914
2025-08-14 14:57:10,113 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00915
2025-08-14 14:57:10,123 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,123 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,124 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,125 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,126 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,126 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,126 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,126 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,129 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00916
2025-08-14 14:57:10,130 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00917
2025-08-14 14:57:10,130 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00918
2025-08-14 14:57:10,130 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00919
2025-08-14 14:57:10,133 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,133 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,136 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,136 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00920
2025-08-14 14:57:10,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00921
2025-08-14 14:57:10,145 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,145 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,147 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,147 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,148 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00922
2025-08-14 14:57:10,148 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00923
2025-08-14 14:57:10,163 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,163 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,164 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00924
2025-08-14 14:57:10,167 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,167 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,168 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00925
2025-08-14 14:57:10,169 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,169 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,169 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00926
2025-08-14 14:57:10,171 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,171 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,172 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00927
2025-08-14 14:57:10,178 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,178 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,181 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,181 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,184 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,184 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,186 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,186 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,187 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,187 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,187 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00928
2025-08-14 14:57:10,189 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00929
2025-08-14 14:57:10,189 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00930
2025-08-14 14:57:10,189 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00931
2025-08-14 14:57:10,189 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00932
2025-08-14 14:57:10,191 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,191 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,192 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00933
2025-08-14 14:57:10,213 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,213 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,218 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,218 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,219 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00934
2025-08-14 14:57:10,220 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,220 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,222 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,222 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,224 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,224 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00935
2025-08-14 14:57:10,225 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00936
2025-08-14 14:57:10,226 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,226 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00937
2025-08-14 14:57:10,227 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00938
2025-08-14 14:57:10,227 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00939
2025-08-14 14:57:10,235 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,235 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,240 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,240 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,241 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00940
2025-08-14 14:57:10,242 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,243 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,246 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,246 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,247 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00941
2025-08-14 14:57:10,247 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00942
2025-08-14 14:57:10,248 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00943
2025-08-14 14:57:10,257 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,257 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,259 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00944
2025-08-14 14:57:10,264 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,264 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,266 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,267 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,269 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,269 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,273 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,273 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,274 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00945
2025-08-14 14:57:10,274 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00946
2025-08-14 14:57:10,274 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00947
2025-08-14 14:57:10,279 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,279 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,279 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,279 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,280 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00948
2025-08-14 14:57:10,282 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00949
2025-08-14 14:57:10,282 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00950
2025-08-14 14:57:10,284 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,284 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,295 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,295 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,296 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00951
2025-08-14 14:57:10,296 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00952
2025-08-14 14:57:10,302 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,302 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,305 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,305 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,306 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00953
2025-08-14 14:57:10,306 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00954
2025-08-14 14:57:10,308 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,308 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,309 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00955
2025-08-14 14:57:10,311 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,311 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,312 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,312 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00956
2025-08-14 14:57:10,313 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,314 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00957
2025-08-14 14:57:10,325 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,325 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,327 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,327 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,329 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,329 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,330 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00958
2025-08-14 14:57:10,336 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,336 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,337 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00959
2025-08-14 14:57:10,337 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00960
2025-08-14 14:57:10,338 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00961
2025-08-14 14:57:10,347 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,347 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,351 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,351 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,351 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,351 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,353 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00962
2025-08-14 14:57:10,354 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00963
2025-08-14 14:57:10,355 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,355 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,357 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,357 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,363 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,363 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,364 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00964
2025-08-14 14:57:10,364 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00965
2025-08-14 14:57:10,364 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00966
2025-08-14 14:57:10,364 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00967
2025-08-14 14:57:10,369 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,369 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,373 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,373 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,374 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00968
2025-08-14 14:57:10,374 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00969
2025-08-14 14:57:10,384 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,384 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,385 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00970
2025-08-14 14:57:10,391 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,391 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,391 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,392 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,394 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00971
2025-08-14 14:57:10,394 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00972
2025-08-14 14:57:10,395 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,395 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,396 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00973
2025-08-14 14:57:10,399 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,400 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,401 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,401 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,408 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,408 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,409 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00974
2025-08-14 14:57:10,409 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00975
2025-08-14 14:57:10,409 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00976
2025-08-14 14:57:10,411 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,411 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,421 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,421 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,422 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00977
2025-08-14 14:57:10,422 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00978
2025-08-14 14:57:10,430 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,430 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,431 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00979
2025-08-14 14:57:10,436 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,436 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,438 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,438 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,439 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,440 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,441 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00980
2025-08-14 14:57:10,441 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00981
2025-08-14 14:57:10,444 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,445 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,445 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,445 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,448 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,448 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,449 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00982
2025-08-14 14:57:10,449 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00983
2025-08-14 14:57:10,449 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00984
2025-08-14 14:57:10,449 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00985
2025-08-14 14:57:10,454 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,454 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,463 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,463 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,464 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00986
2025-08-14 14:57:10,464 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00987
2025-08-14 14:57:10,479 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,479 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,479 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,479 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,481 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,482 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00988
2025-08-14 14:57:10,482 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,483 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00989
2025-08-14 14:57:10,484 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00990
2025-08-14 14:57:10,489 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,489 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,489 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,490 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,496 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,496 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,497 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,497 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,503 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,503 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,518 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,518 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,527 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,527 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,530 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,530 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,534 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,534 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,534 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,535 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00991
2025-08-14 14:57:10,537 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,538 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,538 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00992
2025-08-14 14:57:10,538 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,538 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,538 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00993
2025-08-14 14:57:10,541 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,541 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00994
2025-08-14 14:57:10,541 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,541 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00995
2025-08-14 14:57:10,543 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00996
2025-08-14 14:57:10,543 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00997
2025-08-14 14:57:10,543 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00998
2025-08-14 14:57:10,543 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00999
2025-08-14 14:57:10,543 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01000
2025-08-14 14:57:10,543 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01001
2025-08-14 14:57:10,543 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01002
2025-08-14 14:57:10,543 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01003
2025-08-14 14:57:10,552 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,552 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,553 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01004
2025-08-14 14:57:10,558 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,558 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01005
2025-08-14 14:57:10,571 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,571 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,575 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,575 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,576 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01006
2025-08-14 14:57:10,576 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01007
2025-08-14 14:57:10,579 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,579 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,582 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,583 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,584 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,584 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,586 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,586 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,588 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,588 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,589 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01008
2025-08-14 14:57:10,589 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01009
2025-08-14 14:57:10,589 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01010
2025-08-14 14:57:10,589 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01011
2025-08-14 14:57:10,598 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,598 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,599 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01012
2025-08-14 14:57:10,599 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01013
2025-08-14 14:57:10,609 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,609 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,610 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01014
2025-08-14 14:57:10,614 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,614 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,615 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01015
2025-08-14 14:57:10,615 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,615 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,617 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01016
2025-08-14 14:57:10,630 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,630 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,631 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01017
2025-08-14 14:57:10,632 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,633 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,633 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,634 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,633 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,633 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,635 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,636 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,638 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,638 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,640 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01018
2025-08-14 14:57:10,641 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01019
2025-08-14 14:57:10,641 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01020
2025-08-14 14:57:10,641 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01021
2025-08-14 14:57:10,641 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01022
2025-08-14 14:57:10,656 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,656 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,657 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01023
2025-08-14 14:57:10,662 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,662 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,667 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,667 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01024
2025-08-14 14:57:10,670 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,670 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,671 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01025
2025-08-14 14:57:10,671 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01026
2025-08-14 14:57:10,678 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,679 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,679 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,679 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,683 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,683 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,686 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,687 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,687 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,687 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,687 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,687 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,688 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01027
2025-08-14 14:57:10,691 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01028
2025-08-14 14:57:10,691 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01029
2025-08-14 14:57:10,691 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01030
2025-08-14 14:57:10,691 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01031
2025-08-14 14:57:10,691 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01032
2025-08-14 14:57:10,714 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,714 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,715 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01033
2025-08-14 14:57:10,721 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,721 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,723 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,723 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,724 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,725 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,726 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,726 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,730 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,730 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,734 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,734 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,739 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,739 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,745 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,745 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,756 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,756 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01034
2025-08-14 14:57:10,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01035
2025-08-14 14:57:10,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01036
2025-08-14 14:57:10,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01037
2025-08-14 14:57:10,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01038
2025-08-14 14:57:10,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01039
2025-08-14 14:57:10,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01040
2025-08-14 14:57:10,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01041
2025-08-14 14:57:10,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01042
2025-08-14 14:57:10,764 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,764 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,769 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,770 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,770 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,770 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,773 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,773 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,774 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01043
2025-08-14 14:57:10,774 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,775 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01044
2025-08-14 14:57:10,775 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,778 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,778 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,779 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01045
2025-08-14 14:57:10,779 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01046
2025-08-14 14:57:10,779 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01047
2025-08-14 14:57:10,779 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01048
2025-08-14 14:57:10,785 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,785 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,788 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,788 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,790 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01049
2025-08-14 14:57:10,790 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01050
2025-08-14 14:57:10,801 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,801 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,804 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,804 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,805 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01051
2025-08-14 14:57:10,805 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01052
2025-08-14 14:57:10,807 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,807 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,808 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01053
2025-08-14 14:57:10,814 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,815 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,815 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,815 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,816 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01054
2025-08-14 14:57:10,818 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01055
2025-08-14 14:57:10,818 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,818 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,830 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,831 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,832 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,832 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,833 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01056
2025-08-14 14:57:10,834 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,834 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01057
2025-08-14 14:57:10,834 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,835 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01058
2025-08-14 14:57:10,835 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01059
2025-08-14 14:57:10,843 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,844 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,845 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01060
2025-08-14 14:57:10,845 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,845 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,846 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01061
2025-08-14 14:57:10,850 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,850 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,859 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,859 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,859 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,859 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,861 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,862 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,863 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,863 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,864 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01062
2025-08-14 14:57:10,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01063
2025-08-14 14:57:10,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01064
2025-08-14 14:57:10,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01065
2025-08-14 14:57:10,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01066
2025-08-14 14:57:10,876 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,876 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,877 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01067
2025-08-14 14:57:10,889 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,889 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,890 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,891 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,891 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,891 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,893 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,893 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01068
2025-08-14 14:57:10,894 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,894 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01069
2025-08-14 14:57:10,898 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,898 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01070
2025-08-14 14:57:10,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01071
2025-08-14 14:57:10,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01072
2025-08-14 14:57:10,904 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,904 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,905 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01073
2025-08-14 14:57:10,905 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,906 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,907 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,907 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01074
2025-08-14 14:57:10,907 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,908 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01075
2025-08-14 14:57:10,920 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,921 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,921 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,921 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,922 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01076
2025-08-14 14:57:10,923 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01077
2025-08-14 14:57:10,936 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,936 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,937 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,937 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,948 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,948 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,949 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,949 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,949 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,949 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,951 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,951 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01078
2025-08-14 14:57:10,953 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,954 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,954 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01079
2025-08-14 14:57:10,954 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,956 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,956 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01080
2025-08-14 14:57:10,957 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,958 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01081
2025-08-14 14:57:10,958 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01082
2025-08-14 14:57:10,959 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01083
2025-08-14 14:57:10,959 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01084
2025-08-14 14:57:10,959 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01085
2025-08-14 14:57:10,970 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,970 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,971 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01086
2025-08-14 14:57:10,978 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,978 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,979 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01087
2025-08-14 14:57:10,980 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,980 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,981 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,981 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:10,983 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01088
2025-08-14 14:57:10,983 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01089
2025-08-14 14:57:10,998 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:10,998 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,002 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,002 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,005 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,005 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,006 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01090
2025-08-14 14:57:11,006 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01091
2025-08-14 14:57:11,009 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,009 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,010 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01092
2025-08-14 14:57:11,010 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01093
2025-08-14 14:57:11,014 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,014 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,015 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01094
2025-08-14 14:57:11,015 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,016 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,019 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,019 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,020 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01095
2025-08-14 14:57:11,021 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01096
2025-08-14 14:57:11,022 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,022 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,026 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,026 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,033 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,033 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,034 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01097
2025-08-14 14:57:11,035 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01098
2025-08-14 14:57:11,035 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01099
2025-08-14 14:57:11,046 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,046 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,058 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,058 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,059 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01100
2025-08-14 14:57:11,059 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01101
2025-08-14 14:57:11,060 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,060 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,062 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,062 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,063 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,063 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01102
2025-08-14 14:57:11,063 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,065 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,065 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,067 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,067 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,068 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01103
2025-08-14 14:57:11,070 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,070 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,089 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,089 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,091 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,091 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,097 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,097 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01104
2025-08-14 14:57:11,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01105
2025-08-14 14:57:11,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01106
2025-08-14 14:57:11,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01107
2025-08-14 14:57:11,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01108
2025-08-14 14:57:11,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01109
2025-08-14 14:57:11,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01110
2025-08-14 14:57:11,103 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,103 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,104 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01111
2025-08-14 14:57:11,105 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,105 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,106 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01112
2025-08-14 14:57:11,107 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,107 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,108 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,108 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,115 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,116 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,117 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,117 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,118 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01113
2025-08-14 14:57:11,118 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01114
2025-08-14 14:57:11,119 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01115
2025-08-14 14:57:11,123 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,123 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,124 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01116
2025-08-14 14:57:11,124 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01117
2025-08-14 14:57:11,135 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,135 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,145 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,145 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,146 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01118
2025-08-14 14:57:11,146 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01119
2025-08-14 14:57:11,146 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,147 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,149 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,149 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,150 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,150 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,154 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,154 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,155 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,155 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,157 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01120
2025-08-14 14:57:11,157 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01121
2025-08-14 14:57:11,157 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01122
2025-08-14 14:57:11,157 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01123
2025-08-14 14:57:11,157 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01124
2025-08-14 14:57:11,160 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,161 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,162 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01125
2025-08-14 14:57:11,173 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,173 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,174 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01126
2025-08-14 14:57:11,178 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,178 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,179 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01127
2025-08-14 14:57:11,180 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,180 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,181 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01128
2025-08-14 14:57:11,190 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,190 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,193 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,193 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,195 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,195 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,197 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,197 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,200 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,200 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,201 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01129
2025-08-14 14:57:11,201 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01130
2025-08-14 14:57:11,201 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01131
2025-08-14 14:57:11,201 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01132
2025-08-14 14:57:11,201 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01133
2025-08-14 14:57:11,211 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,211 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,213 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,213 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,214 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01134
2025-08-14 14:57:11,214 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01135
2025-08-14 14:57:11,224 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,224 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,232 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,232 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,233 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01136
2025-08-14 14:57:11,233 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,234 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,234 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,234 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01137
2025-08-14 14:57:11,237 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,237 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01138
2025-08-14 14:57:11,237 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,238 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,238 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01139
2025-08-14 14:57:11,239 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,240 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01140
2025-08-14 14:57:11,241 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,241 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01141
2025-08-14 14:57:11,241 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,242 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01142
2025-08-14 14:57:11,255 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,255 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,256 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,256 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,258 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01143
2025-08-14 14:57:11,258 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01144
2025-08-14 14:57:11,271 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,271 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,272 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01145
2025-08-14 14:57:11,279 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,279 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,280 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,280 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,284 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,284 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,287 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,287 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,289 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,290 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,290 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,290 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,304 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,304 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,313 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,313 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,321 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,322 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,323 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,323 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,325 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,325 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,326 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01146
2025-08-14 14:57:11,327 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01147
2025-08-14 14:57:11,327 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01148
2025-08-14 14:57:11,327 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01149
2025-08-14 14:57:11,327 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01150
2025-08-14 14:57:11,327 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01151
2025-08-14 14:57:11,327 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01152
2025-08-14 14:57:11,327 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01153
2025-08-14 14:57:11,327 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01154
2025-08-14 14:57:11,327 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,327 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,329 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,329 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,330 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01155
2025-08-14 14:57:11,330 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01156
2025-08-14 14:57:11,330 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01157
2025-08-14 14:57:11,330 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01158
2025-08-14 14:57:11,342 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,342 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,343 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01159
2025-08-14 14:57:11,344 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,344 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,346 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01160
2025-08-14 14:57:11,348 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,348 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,365 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,365 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,366 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,366 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,368 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,369 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,370 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,370 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,372 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,372 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,383 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,383 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,384 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01161
2025-08-14 14:57:11,384 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01162
2025-08-14 14:57:11,384 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01163
2025-08-14 14:57:11,384 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01164
2025-08-14 14:57:11,384 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01165
2025-08-14 14:57:11,384 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01166
2025-08-14 14:57:11,384 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01167
2025-08-14 14:57:11,387 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,387 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,388 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01168
2025-08-14 14:57:11,392 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,392 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,397 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,397 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,398 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01169
2025-08-14 14:57:11,399 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,399 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,400 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01170
2025-08-14 14:57:11,400 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01171
2025-08-14 14:57:11,408 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,408 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,409 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01172
2025-08-14 14:57:11,410 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,410 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,411 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01173
2025-08-14 14:57:11,415 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,415 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,417 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,417 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,426 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,426 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,427 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01174
2025-08-14 14:57:11,427 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01175
2025-08-14 14:57:11,427 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01176
2025-08-14 14:57:11,429 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,429 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,430 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01177
2025-08-14 14:57:11,436 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,436 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,445 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,445 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,446 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01178
2025-08-14 14:57:11,446 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01179
2025-08-14 14:57:11,450 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,450 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,452 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,452 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,453 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,453 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01180
2025-08-14 14:57:11,453 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,455 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,455 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,456 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01181
2025-08-14 14:57:11,456 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01182
2025-08-14 14:57:11,456 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01183
2025-08-14 14:57:11,459 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,459 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,461 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,461 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01184
2025-08-14 14:57:11,461 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,462 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01185
2025-08-14 14:57:11,475 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,475 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,480 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,481 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,481 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,481 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,482 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01186
2025-08-14 14:57:11,484 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01187
2025-08-14 14:57:11,484 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01188
2025-08-14 14:57:11,493 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,493 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,498 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,498 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,503 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,503 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,503 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,504 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,504 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,505 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01189
2025-08-14 14:57:11,505 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,507 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01190
2025-08-14 14:57:11,508 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,508 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,509 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01191
2025-08-14 14:57:11,510 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01192
2025-08-14 14:57:11,511 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,511 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,512 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01193
2025-08-14 14:57:11,512 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01194
2025-08-14 14:57:11,512 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01195
2025-08-14 14:57:11,519 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,519 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,520 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01196
2025-08-14 14:57:11,525 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,525 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,526 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01197
2025-08-14 14:57:11,535 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,535 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,538 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,538 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,539 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01198
2025-08-14 14:57:11,539 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01199
2025-08-14 14:57:11,542 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,542 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,543 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01200
2025-08-14 14:57:11,549 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,549 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,550 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,550 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01201
2025-08-14 14:57:11,550 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,563 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,563 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,564 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,564 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,564 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,564 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,567 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,567 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01202
2025-08-14 14:57:11,568 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01203
2025-08-14 14:57:11,570 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,570 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01204
2025-08-14 14:57:11,570 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,570 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01205
2025-08-14 14:57:11,571 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01206
2025-08-14 14:57:11,571 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01207
2025-08-14 14:57:11,577 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,577 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,578 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01208
2025-08-14 14:57:11,585 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,585 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,593 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,594 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,594 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,594 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,594 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,594 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,598 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01209
2025-08-14 14:57:11,599 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01210
2025-08-14 14:57:11,599 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01211
2025-08-14 14:57:11,599 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01212
2025-08-14 14:57:11,613 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,613 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,615 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,615 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,620 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,620 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,622 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,623 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,623 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,623 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,623 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,624 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,626 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01213
2025-08-14 14:57:11,628 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,628 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01214
2025-08-14 14:57:11,628 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,628 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01215
2025-08-14 14:57:11,629 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01216
2025-08-14 14:57:11,629 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01217
2025-08-14 14:57:11,629 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01218
2025-08-14 14:57:11,629 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01219
2025-08-14 14:57:11,638 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,638 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,639 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01220
2025-08-14 14:57:11,640 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,640 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,641 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01221
2025-08-14 14:57:11,653 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,653 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,654 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01222
2025-08-14 14:57:11,657 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,657 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,658 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01223
2025-08-14 14:57:11,659 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,659 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,660 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01224
2025-08-14 14:57:11,661 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,662 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,663 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01225
2025-08-14 14:57:11,676 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,676 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,679 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,679 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,681 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,681 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01226
2025-08-14 14:57:11,681 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,682 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01227
2025-08-14 14:57:11,683 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,683 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,684 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,685 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,685 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,685 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,687 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01228
2025-08-14 14:57:11,687 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01229
2025-08-14 14:57:11,688 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01230
2025-08-14 14:57:11,688 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01231
2025-08-14 14:57:11,703 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,704 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,704 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,704 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,704 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,705 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,708 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,709 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,710 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01232
2025-08-14 14:57:11,710 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01233
2025-08-14 14:57:11,710 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01234
2025-08-14 14:57:11,710 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01235
2025-08-14 14:57:11,718 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,719 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,720 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01236
2025-08-14 14:57:11,727 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,727 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,731 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,731 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,734 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,734 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,735 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01237
2025-08-14 14:57:11,736 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,736 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01238
2025-08-14 14:57:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01239
2025-08-14 14:57:11,743 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,743 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,745 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01240
2025-08-14 14:57:11,745 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01241
2025-08-14 14:57:11,746 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,747 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,748 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01242
2025-08-14 14:57:11,751 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,751 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,753 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,753 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,754 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01243
2025-08-14 14:57:11,754 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01244
2025-08-14 14:57:11,762 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,762 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,764 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,764 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,765 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01245
2025-08-14 14:57:11,765 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01246
2025-08-14 14:57:11,771 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,771 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,773 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01247
2025-08-14 14:57:11,774 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,775 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,776 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01248
2025-08-14 14:57:11,789 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,789 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,790 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,791 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01249
2025-08-14 14:57:11,791 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,791 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,791 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,792 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01250
2025-08-14 14:57:11,796 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,796 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,797 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,798 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,801 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,801 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,802 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01251
2025-08-14 14:57:11,802 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01252
2025-08-14 14:57:11,802 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01253
2025-08-14 14:57:11,802 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01254
2025-08-14 14:57:11,805 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,805 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,806 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01255
2025-08-14 14:57:11,816 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,816 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,818 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,818 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,819 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,819 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,820 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01256
2025-08-14 14:57:11,821 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01257
2025-08-14 14:57:11,821 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01258
2025-08-14 14:57:11,836 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,836 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,841 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,841 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,845 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,845 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,847 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,847 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,848 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,849 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,849 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01259
2025-08-14 14:57:11,849 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,849 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,850 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01260
2025-08-14 14:57:11,852 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01261
2025-08-14 14:57:11,852 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01262
2025-08-14 14:57:11,852 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01263
2025-08-14 14:57:11,859 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,860 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,861 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,862 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,862 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,862 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,864 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01264
2025-08-14 14:57:11,864 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01265
2025-08-14 14:57:11,864 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01266
2025-08-14 14:57:11,864 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01267
2025-08-14 14:57:11,875 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,875 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01268
2025-08-14 14:57:11,878 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,878 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,880 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01269
2025-08-14 14:57:11,885 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,885 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,886 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01270
2025-08-14 14:57:11,896 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,896 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,897 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,898 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,900 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,900 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,901 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01271
2025-08-14 14:57:11,901 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01272
2025-08-14 14:57:11,904 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,904 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,905 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,905 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,907 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01273
2025-08-14 14:57:11,907 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01274
2025-08-14 14:57:11,907 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01275
2025-08-14 14:57:11,920 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,920 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01276
2025-08-14 14:57:11,923 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,923 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,925 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,925 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,926 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01277
2025-08-14 14:57:11,933 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,933 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,934 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,935 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,936 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01278
2025-08-14 14:57:11,936 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01279
2025-08-14 14:57:11,936 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01280
2025-08-14 14:57:11,940 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,940 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,941 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01281
2025-08-14 14:57:11,945 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,945 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,946 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01282
2025-08-14 14:57:11,950 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,950 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,959 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,960 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,960 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,961 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01283
2025-08-14 14:57:11,961 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,962 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01284
2025-08-14 14:57:11,963 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01285
2025-08-14 14:57:11,965 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,965 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,968 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,969 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,977 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,977 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,979 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,979 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,980 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01286
2025-08-14 14:57:11,980 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01287
2025-08-14 14:57:11,980 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01288
2025-08-14 14:57:11,980 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01289
2025-08-14 14:57:11,983 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,983 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,989 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,989 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,990 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,990 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,992 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01290
2025-08-14 14:57:11,992 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01291
2025-08-14 14:57:11,992 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01292
2025-08-14 14:57:11,996 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:11,996 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:11,997 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01293
2025-08-14 14:57:12,008 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,008 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,015 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,015 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,015 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,016 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,017 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,018 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01294
2025-08-14 14:57:12,019 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,020 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01295
2025-08-14 14:57:12,020 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01296
2025-08-14 14:57:12,020 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01297
2025-08-14 14:57:12,021 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,022 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,023 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01298
2025-08-14 14:57:12,027 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,027 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,036 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,036 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,037 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,037 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,038 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01299
2025-08-14 14:57:12,038 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01300
2025-08-14 14:57:12,038 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01301
2025-08-14 14:57:12,040 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,040 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,046 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,046 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,047 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01302
2025-08-14 14:57:12,047 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01303
2025-08-14 14:57:12,060 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,060 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,062 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,062 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01304
2025-08-14 14:57:12,062 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,066 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,066 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,070 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,070 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,072 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,072 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,073 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,074 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,075 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01305
2025-08-14 14:57:12,075 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01306
2025-08-14 14:57:12,075 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01307
2025-08-14 14:57:12,075 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01308
2025-08-14 14:57:12,075 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01309
2025-08-14 14:57:12,081 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,081 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,082 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01310
2025-08-14 14:57:12,085 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,085 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,096 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,096 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,097 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01311
2025-08-14 14:57:12,097 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01312
2025-08-14 14:57:12,103 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,103 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,107 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,107 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,108 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,108 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01313
2025-08-14 14:57:12,109 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,109 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01314
2025-08-14 14:57:12,110 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,110 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01315
2025-08-14 14:57:12,111 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,112 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01316
2025-08-14 14:57:12,115 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,115 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,116 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01317
2025-08-14 14:57:12,127 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,127 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,128 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01318
2025-08-14 14:57:12,129 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,129 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,130 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,130 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,130 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,130 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,133 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01319
2025-08-14 14:57:12,134 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01320
2025-08-14 14:57:12,134 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01321
2025-08-14 14:57:12,145 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,145 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,153 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,153 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,154 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,154 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,155 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,157 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01322
2025-08-14 14:57:12,157 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,157 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01323
2025-08-14 14:57:12,158 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,158 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,162 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,162 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,163 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01324
2025-08-14 14:57:12,163 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01325
2025-08-14 14:57:12,163 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01326
2025-08-14 14:57:12,163 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01327
2025-08-14 14:57:12,176 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,176 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,177 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,178 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,181 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,182 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,183 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01328
2025-08-14 14:57:12,185 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,185 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,186 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01329
2025-08-14 14:57:12,186 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01330
2025-08-14 14:57:12,186 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01331
2025-08-14 14:57:12,187 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,187 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,188 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01332
2025-08-14 14:57:12,200 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,200 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,200 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,200 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,202 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,203 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,217 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,217 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,220 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,220 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,222 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,222 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01333
2025-08-14 14:57:12,222 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,222 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01334
2025-08-14 14:57:12,223 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01335
2025-08-14 14:57:12,223 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01336
2025-08-14 14:57:12,223 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01337
2025-08-14 14:57:12,223 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01338
2025-08-14 14:57:12,227 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,227 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,228 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01339
2025-08-14 14:57:12,230 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,230 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,236 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,236 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,237 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01340
2025-08-14 14:57:12,240 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,240 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,241 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01341
2025-08-14 14:57:12,241 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01342
2025-08-14 14:57:12,245 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,245 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,246 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01343
2025-08-14 14:57:12,247 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,247 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,248 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,248 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,249 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01344
2025-08-14 14:57:12,250 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01345
2025-08-14 14:57:12,267 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,267 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,271 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,271 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,273 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,273 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,273 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,273 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,274 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01346
2025-08-14 14:57:12,279 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,279 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,280 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01347
2025-08-14 14:57:12,280 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01348
2025-08-14 14:57:12,280 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01349
2025-08-14 14:57:12,280 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01350
2025-08-14 14:57:12,289 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,289 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,291 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,291 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,292 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,292 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,293 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01351
2025-08-14 14:57:12,294 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,294 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,295 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,295 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,297 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01352
2025-08-14 14:57:12,297 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01353
2025-08-14 14:57:12,297 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01354
2025-08-14 14:57:12,297 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01355
2025-08-14 14:57:12,311 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,311 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,312 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01356
2025-08-14 14:57:12,315 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,315 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,320 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,320 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,321 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01357
2025-08-14 14:57:12,321 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01358
2025-08-14 14:57:12,331 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,331 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,332 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01359
2025-08-14 14:57:12,334 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,334 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,334 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,334 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,337 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,337 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,339 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01360
2025-08-14 14:57:12,339 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,339 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01361
2025-08-14 14:57:12,339 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,339 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01362
2025-08-14 14:57:12,347 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,347 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,348 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01363
2025-08-14 14:57:12,356 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,356 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,357 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,357 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,368 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,368 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,379 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,380 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,380 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,380 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,382 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,383 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,384 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,384 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,384 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01364
2025-08-14 14:57:12,385 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01365
2025-08-14 14:57:12,386 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01366
2025-08-14 14:57:12,386 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01367
2025-08-14 14:57:12,386 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01368
2025-08-14 14:57:12,387 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,387 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,388 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01369
2025-08-14 14:57:12,388 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01370
2025-08-14 14:57:12,388 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01371
2025-08-14 14:57:12,395 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,396 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,397 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01372
2025-08-14 14:57:12,397 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01373
2025-08-14 14:57:12,400 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,400 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,402 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,402 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,403 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01374
2025-08-14 14:57:12,403 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01375
2025-08-14 14:57:12,418 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,418 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,424 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,424 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,424 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,424 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,427 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,427 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,437 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,438 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,444 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,444 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,445 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,445 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,452 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,452 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,454 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,454 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01376
2025-08-14 14:57:12,454 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,454 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01377
2025-08-14 14:57:12,455 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01378
2025-08-14 14:57:12,455 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01379
2025-08-14 14:57:12,455 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01380
2025-08-14 14:57:12,455 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01381
2025-08-14 14:57:12,455 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01382
2025-08-14 14:57:12,455 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01383
2025-08-14 14:57:12,455 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01384
2025-08-14 14:57:12,457 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,457 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,458 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01385
2025-08-14 14:57:12,463 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,463 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,464 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01386
2025-08-14 14:57:12,469 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,469 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,469 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,469 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,470 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01387
2025-08-14 14:57:12,472 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,472 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01388
2025-08-14 14:57:12,472 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,474 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01389
2025-08-14 14:57:12,490 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,490 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,492 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,492 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,493 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01390
2025-08-14 14:57:12,493 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01391
2025-08-14 14:57:12,495 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,495 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,502 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,502 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,503 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01392
2025-08-14 14:57:12,503 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01393
2025-08-14 14:57:12,510 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,510 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,512 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,513 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,513 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,513 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,514 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,515 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,516 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,516 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01394
2025-08-14 14:57:12,516 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,517 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,517 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,517 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01395
2025-08-14 14:57:12,520 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01396
2025-08-14 14:57:12,521 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01397
2025-08-14 14:57:12,521 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01398
2025-08-14 14:57:12,521 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01399
2025-08-14 14:57:12,534 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,535 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,536 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01400
2025-08-14 14:57:12,537 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,537 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,547 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,547 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,548 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01401
2025-08-14 14:57:12,548 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01402
2025-08-14 14:57:12,554 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,554 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,559 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,559 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,561 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,561 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,561 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,561 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,563 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,563 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01403
2025-08-14 14:57:12,564 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,565 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01404
2025-08-14 14:57:12,567 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,567 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01405
2025-08-14 14:57:12,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01406
2025-08-14 14:57:12,569 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01407
2025-08-14 14:57:12,577 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,577 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,578 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01408
2025-08-14 14:57:12,578 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01409
2025-08-14 14:57:12,579 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,579 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,579 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,579 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,581 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01410
2025-08-14 14:57:12,582 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01411
2025-08-14 14:57:12,598 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,598 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,603 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,603 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,604 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,605 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,605 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,605 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01412
2025-08-14 14:57:12,605 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,607 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,607 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01413
2025-08-14 14:57:12,608 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,608 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01414
2025-08-14 14:57:12,609 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01415
2025-08-14 14:57:12,609 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01416
2025-08-14 14:57:12,621 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,622 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,622 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,622 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,622 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,622 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,624 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01417
2025-08-14 14:57:12,626 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,626 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01418
2025-08-14 14:57:12,627 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,635 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,635 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,636 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01419
2025-08-14 14:57:12,636 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01420
2025-08-14 14:57:12,636 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01421
2025-08-14 14:57:12,642 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,642 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01422
2025-08-14 14:57:12,649 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,649 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,651 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,651 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,652 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,652 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,664 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,664 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,670 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,670 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,672 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,672 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01423
2025-08-14 14:57:12,672 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,672 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01424
2025-08-14 14:57:12,673 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01425
2025-08-14 14:57:12,673 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01426
2025-08-14 14:57:12,673 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01427
2025-08-14 14:57:12,678 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,678 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,679 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01428
2025-08-14 14:57:12,680 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,680 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,681 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01429
2025-08-14 14:57:12,681 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01430
2025-08-14 14:57:12,690 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,690 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,693 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,693 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,693 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,694 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,694 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,695 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01431
2025-08-14 14:57:12,697 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,697 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,697 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01432
2025-08-14 14:57:12,697 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,698 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01433
2025-08-14 14:57:12,700 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01434
2025-08-14 14:57:12,700 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01435
2025-08-14 14:57:12,706 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,706 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,708 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01436
2025-08-14 14:57:12,717 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,717 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,725 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,725 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,726 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01437
2025-08-14 14:57:12,726 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01438
2025-08-14 14:57:12,733 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,733 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,733 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01439
2025-08-14 14:57:12,734 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,735 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,737 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,737 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,739 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,740 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,740 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,740 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01440
2025-08-14 14:57:12,740 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,741 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01441
2025-08-14 14:57:12,743 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,743 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01442
2025-08-14 14:57:12,743 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,743 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01443
2025-08-14 14:57:12,748 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,748 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,755 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,755 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,756 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01444
2025-08-14 14:57:12,756 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01445
2025-08-14 14:57:12,756 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01446
2025-08-14 14:57:12,761 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,761 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,762 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01447
2025-08-14 14:57:12,779 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,779 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,780 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,780 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,782 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01448
2025-08-14 14:57:12,785 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,785 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,785 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,785 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,789 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,789 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,791 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,791 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01449
2025-08-14 14:57:12,791 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,791 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01450
2025-08-14 14:57:12,793 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,793 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,794 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01451
2025-08-14 14:57:12,794 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01452
2025-08-14 14:57:12,794 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01453
2025-08-14 14:57:12,805 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,805 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,808 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,808 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,809 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01454
2025-08-14 14:57:12,809 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01455
2025-08-14 14:57:12,813 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,813 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,814 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01456
2025-08-14 14:57:12,814 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01457
2025-08-14 14:57:12,823 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,823 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,824 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01458
2025-08-14 14:57:12,830 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,830 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,830 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,830 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,834 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,834 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,835 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,835 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,836 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01459
2025-08-14 14:57:12,837 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01460
2025-08-14 14:57:12,837 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01461
2025-08-14 14:57:12,844 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,844 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,845 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01462
2025-08-14 14:57:12,845 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01463
2025-08-14 14:57:12,848 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,849 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,850 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,850 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01464
2025-08-14 14:57:12,850 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,851 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01465
2025-08-14 14:57:12,857 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,857 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,859 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01466
2025-08-14 14:57:12,867 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,867 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,875 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,875 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,876 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,876 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,876 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,876 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,890 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,890 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,896 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,896 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,899 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,899 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,901 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,901 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,909 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,909 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,915 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,915 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,918 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,918 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,920 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,920 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01467
2025-08-14 14:57:12,920 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,920 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01468
2025-08-14 14:57:12,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01469
2025-08-14 14:57:12,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01470
2025-08-14 14:57:12,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01471
2025-08-14 14:57:12,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01472
2025-08-14 14:57:12,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01473
2025-08-14 14:57:12,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01474
2025-08-14 14:57:12,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01475
2025-08-14 14:57:12,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01476
2025-08-14 14:57:12,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01477
2025-08-14 14:57:12,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01478
2025-08-14 14:57:12,922 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,922 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,924 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,924 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,925 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01479
2025-08-14 14:57:12,925 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01480
2025-08-14 14:57:12,940 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,941 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,945 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,945 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,946 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01481
2025-08-14 14:57:12,946 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01482
2025-08-14 14:57:12,955 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,956 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,957 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01483
2025-08-14 14:57:12,959 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,960 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,961 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01484
2025-08-14 14:57:12,962 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,962 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,964 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,964 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,964 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,965 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,966 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01485
2025-08-14 14:57:12,966 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,966 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,968 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01486
2025-08-14 14:57:12,969 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,969 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,976 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,976 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,977 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01487
2025-08-14 14:57:12,978 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01488
2025-08-14 14:57:12,978 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01489
2025-08-14 14:57:12,978 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01490
2025-08-14 14:57:12,985 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:12,985 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:12,986 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01491
2025-08-14 14:57:13,000 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,000 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,001 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01492
2025-08-14 14:57:13,004 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,005 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,005 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,005 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,010 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,010 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,011 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01493
2025-08-14 14:57:13,011 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01494
2025-08-14 14:57:13,011 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01495
2025-08-14 14:57:13,014 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,014 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,018 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,018 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,023 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,023 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,030 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,030 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,034 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,035 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,035 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,035 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,037 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01496
2025-08-14 14:57:13,037 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01497
2025-08-14 14:57:13,037 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01498
2025-08-14 14:57:13,037 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01499
2025-08-14 14:57:13,037 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01500
2025-08-14 14:57:13,037 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01501
2025-08-14 14:57:13,048 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,048 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,054 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,055 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,056 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01502
2025-08-14 14:57:13,056 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01503
2025-08-14 14:57:13,058 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,058 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,062 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,062 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,065 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,065 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,068 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,068 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,069 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01504
2025-08-14 14:57:13,069 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01505
2025-08-14 14:57:13,070 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01506
2025-08-14 14:57:13,070 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01507
2025-08-14 14:57:13,074 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,074 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,078 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,078 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,080 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01508
2025-08-14 14:57:13,080 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01509
2025-08-14 14:57:13,089 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,089 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,091 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,091 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01510
2025-08-14 14:57:13,091 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,094 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,094 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,095 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01511
2025-08-14 14:57:13,095 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01512
2025-08-14 14:57:13,103 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,103 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,106 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,106 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,109 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,110 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,111 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01513
2025-08-14 14:57:13,111 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01514
2025-08-14 14:57:13,111 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01515
2025-08-14 14:57:13,111 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,111 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,119 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,119 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,120 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,120 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,121 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01516
2025-08-14 14:57:13,122 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01517
2025-08-14 14:57:13,122 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01518
2025-08-14 14:57:13,134 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,134 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,135 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01519
2025-08-14 14:57:13,135 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,135 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,138 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,138 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,139 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01520
2025-08-14 14:57:13,139 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01521
2025-08-14 14:57:13,147 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,147 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,150 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,150 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,151 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,152 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,153 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01522
2025-08-14 14:57:13,153 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01523
2025-08-14 14:57:13,153 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01524
2025-08-14 14:57:13,154 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,154 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,163 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,163 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,164 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,165 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,166 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01525
2025-08-14 14:57:13,166 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01526
2025-08-14 14:57:13,166 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01527
2025-08-14 14:57:13,177 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,177 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,179 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,179 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,180 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01528
2025-08-14 14:57:13,184 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,184 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,189 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,189 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,190 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01529
2025-08-14 14:57:13,190 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01530
2025-08-14 14:57:13,190 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01531
2025-08-14 14:57:13,191 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,191 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,192 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01532
2025-08-14 14:57:13,197 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,197 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,199 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,199 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,200 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01533
2025-08-14 14:57:13,207 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,207 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,209 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,209 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,210 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01534
2025-08-14 14:57:13,211 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01535
2025-08-14 14:57:13,211 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01536
2025-08-14 14:57:13,219 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,220 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,220 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,220 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,221 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01537
2025-08-14 14:57:13,222 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01538
2025-08-14 14:57:13,230 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,230 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,233 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,234 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01539
2025-08-14 14:57:13,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01540
2025-08-14 14:57:13,236 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,236 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,241 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,241 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,244 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,244 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,245 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01541
2025-08-14 14:57:13,245 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01542
2025-08-14 14:57:13,245 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01543
2025-08-14 14:57:13,249 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,249 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,250 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01544
2025-08-14 14:57:13,251 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,252 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,253 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01545
2025-08-14 14:57:13,263 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,263 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,267 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,267 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,268 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01546
2025-08-14 14:57:13,274 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,274 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,275 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,275 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,277 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01547
2025-08-14 14:57:13,277 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01548
2025-08-14 14:57:13,277 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01549
2025-08-14 14:57:13,280 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,281 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,284 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,284 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,288 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,288 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,289 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01550
2025-08-14 14:57:13,289 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01551
2025-08-14 14:57:13,289 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01552
2025-08-14 14:57:13,296 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,296 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,299 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,299 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,301 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,301 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01553
2025-08-14 14:57:13,301 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,302 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01554
2025-08-14 14:57:13,302 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01555
2025-08-14 14:57:13,306 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,306 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01556
2025-08-14 14:57:13,317 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,317 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,325 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,325 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,330 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,330 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,332 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,332 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,336 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,336 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,337 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01557
2025-08-14 14:57:13,338 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01558
2025-08-14 14:57:13,338 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01559
2025-08-14 14:57:13,338 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01560
2025-08-14 14:57:13,338 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01561
2025-08-14 14:57:13,340 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,340 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,344 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,344 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,345 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01562
2025-08-14 14:57:13,345 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01563
2025-08-14 14:57:13,348 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,349 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,349 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,349 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,356 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,356 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,357 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01564
2025-08-14 14:57:13,357 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01565
2025-08-14 14:57:13,357 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01566
2025-08-14 14:57:13,360 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,360 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,361 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01567
2025-08-14 14:57:13,369 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,369 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,370 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01568
2025-08-14 14:57:13,373 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,373 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,375 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01569
2025-08-14 14:57:13,384 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,385 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,387 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,387 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,388 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01570
2025-08-14 14:57:13,391 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,391 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,394 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,394 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,395 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,395 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,396 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01571
2025-08-14 14:57:13,397 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01572
2025-08-14 14:57:13,400 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,400 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,401 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01573
2025-08-14 14:57:13,401 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01574
2025-08-14 14:57:13,401 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01575
2025-08-14 14:57:13,403 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,403 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,411 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,411 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,412 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01576
2025-08-14 14:57:13,413 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01577
2025-08-14 14:57:13,413 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,413 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,414 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01578
2025-08-14 14:57:13,417 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,417 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,418 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01579
2025-08-14 14:57:13,432 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,432 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,434 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,434 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01580
2025-08-14 14:57:13,434 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,439 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,439 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,442 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,442 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,443 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01581
2025-08-14 14:57:13,443 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01582
2025-08-14 14:57:13,443 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01583
2025-08-14 14:57:13,446 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,446 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,454 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,454 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,455 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,456 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01584
2025-08-14 14:57:13,456 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,457 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01585
2025-08-14 14:57:13,457 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01586
2025-08-14 14:57:13,458 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,458 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,460 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,460 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,467 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,467 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,468 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01587
2025-08-14 14:57:13,469 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01588
2025-08-14 14:57:13,469 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01589
2025-08-14 14:57:13,476 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,476 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,476 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,477 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,479 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01590
2025-08-14 14:57:13,479 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01591
2025-08-14 14:57:13,488 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,488 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,489 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01592
2025-08-14 14:57:13,491 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,491 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,496 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,496 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,497 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01593
2025-08-14 14:57:13,497 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01594
2025-08-14 14:57:13,504 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,504 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,509 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,509 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,511 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,511 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,512 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,512 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,513 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01595
2025-08-14 14:57:13,513 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01596
2025-08-14 14:57:13,513 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01597
2025-08-14 14:57:13,514 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01598
2025-08-14 14:57:13,522 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,522 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,523 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,523 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,524 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01599
2025-08-14 14:57:13,527 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,527 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,528 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01600
2025-08-14 14:57:13,529 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01601
2025-08-14 14:57:13,532 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,532 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,533 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01602
2025-08-14 14:57:13,534 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,534 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,535 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01603
2025-08-14 14:57:13,547 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,547 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,551 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,551 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,552 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01604
2025-08-14 14:57:13,552 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01605
2025-08-14 14:57:13,560 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,560 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,561 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01606
2025-08-14 14:57:13,566 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,566 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,566 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,566 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,567 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01607
2025-08-14 14:57:13,572 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,572 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01608
2025-08-14 14:57:13,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01609
2025-08-14 14:57:13,576 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,576 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,576 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,577 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,579 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,580 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,581 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01610
2025-08-14 14:57:13,581 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01611
2025-08-14 14:57:13,581 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01612
2025-08-14 14:57:13,586 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,586 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,587 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01613
2025-08-14 14:57:13,591 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,591 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,592 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01614
2025-08-14 14:57:13,606 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,606 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,607 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01615
2025-08-14 14:57:13,610 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,610 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,611 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01616
2025-08-14 14:57:13,612 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,612 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,619 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,619 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,621 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,621 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,622 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01617
2025-08-14 14:57:13,623 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,623 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01618
2025-08-14 14:57:13,623 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,629 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,629 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,631 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,631 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,632 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01619
2025-08-14 14:57:13,632 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01620
2025-08-14 14:57:13,632 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01621
2025-08-14 14:57:13,633 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,633 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,637 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,637 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01622
2025-08-14 14:57:13,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01623
2025-08-14 14:57:13,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01624
2025-08-14 14:57:13,662 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,662 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,665 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,665 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,667 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,667 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,667 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,669 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01625
2025-08-14 14:57:13,669 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,669 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,669 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01626
2025-08-14 14:57:13,669 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,671 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01627
2025-08-14 14:57:13,672 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01628
2025-08-14 14:57:13,675 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,675 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,676 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,676 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,678 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,678 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01629
2025-08-14 14:57:13,678 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,678 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01630
2025-08-14 14:57:13,680 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01631
2025-08-14 14:57:13,689 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,689 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,690 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01632
2025-08-14 14:57:13,690 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01633
2025-08-14 14:57:13,706 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,706 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,717 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,718 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,718 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,718 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,718 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,721 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,723 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,723 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,723 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,723 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,727 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,727 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,737 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,737 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,746 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,746 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,748 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,748 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01634
2025-08-14 14:57:13,748 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,748 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01635
2025-08-14 14:57:13,750 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01636
2025-08-14 14:57:13,750 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01637
2025-08-14 14:57:13,750 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01638
2025-08-14 14:57:13,750 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01639
2025-08-14 14:57:13,750 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01640
2025-08-14 14:57:13,750 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01641
2025-08-14 14:57:13,750 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01642
2025-08-14 14:57:13,750 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01643
2025-08-14 14:57:13,751 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,751 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,752 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01644
2025-08-14 14:57:13,764 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,764 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,768 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,768 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,769 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,770 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,770 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,770 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,772 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01645
2025-08-14 14:57:13,772 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01646
2025-08-14 14:57:13,773 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01647
2025-08-14 14:57:13,776 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,776 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,778 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,778 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,779 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01648
2025-08-14 14:57:13,779 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01649
2025-08-14 14:57:13,779 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01650
2025-08-14 14:57:13,792 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,792 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,793 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01651
2025-08-14 14:57:13,795 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,795 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,806 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,807 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,807 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,807 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,808 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01652
2025-08-14 14:57:13,809 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01653
2025-08-14 14:57:13,809 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01654
2025-08-14 14:57:13,812 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,812 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,813 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01655
2025-08-14 14:57:13,814 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,814 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,821 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,821 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,823 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,823 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,824 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01656
2025-08-14 14:57:13,824 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,825 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01657
2025-08-14 14:57:13,825 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,825 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01658
2025-08-14 14:57:13,826 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01659
2025-08-14 14:57:13,833 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,833 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,834 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01660
2025-08-14 14:57:13,839 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,839 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,848 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,848 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,849 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01661
2025-08-14 14:57:13,849 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01662
2025-08-14 14:57:13,857 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,857 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,859 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,859 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,864 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,864 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,865 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,865 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01663
2025-08-14 14:57:13,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01664
2025-08-14 14:57:13,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01665
2025-08-14 14:57:13,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01666
2025-08-14 14:57:13,872 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,872 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01667
2025-08-14 14:57:13,874 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,875 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,875 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,875 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,877 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01668
2025-08-14 14:57:13,877 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01669
2025-08-14 14:57:13,883 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,883 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,888 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,888 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,890 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01670
2025-08-14 14:57:13,890 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01671
2025-08-14 14:57:13,900 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,900 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,903 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,903 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,904 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01672
2025-08-14 14:57:13,904 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01673
2025-08-14 14:57:13,914 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,914 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,915 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01674
2025-08-14 14:57:13,920 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,920 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01675
2025-08-14 14:57:13,923 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,923 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,924 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,924 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,926 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,926 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,928 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01676
2025-08-14 14:57:13,928 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,928 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01677
2025-08-14 14:57:13,928 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,928 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01678
2025-08-14 14:57:13,930 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,930 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,931 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01679
2025-08-14 14:57:13,931 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01680
2025-08-14 14:57:13,943 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,944 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,944 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,944 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,946 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01681
2025-08-14 14:57:13,946 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01682
2025-08-14 14:57:13,958 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,959 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,959 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,959 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,960 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01683
2025-08-14 14:57:13,961 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01684
2025-08-14 14:57:13,973 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,973 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,974 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,975 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,975 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,975 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,975 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,978 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,978 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,978 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,980 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01685
2025-08-14 14:57:13,981 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01686
2025-08-14 14:57:13,981 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01687
2025-08-14 14:57:13,985 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,985 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,986 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01688
2025-08-14 14:57:13,986 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01689
2025-08-14 14:57:13,986 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01690
2025-08-14 14:57:13,988 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,988 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:13,998 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:13,998 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,000 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01691
2025-08-14 14:57:14,000 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01692
2025-08-14 14:57:14,005 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,005 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,015 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,015 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,016 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01693
2025-08-14 14:57:14,016 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01694
2025-08-14 14:57:14,017 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,017 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,018 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01695
2025-08-14 14:57:14,023 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,023 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,024 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,024 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,025 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01696
2025-08-14 14:57:14,027 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,027 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,029 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01697
2025-08-14 14:57:14,029 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01698
2025-08-14 14:57:14,035 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,035 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,036 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,036 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01699
2025-08-14 14:57:14,036 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,043 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,043 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,044 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01700
2025-08-14 14:57:14,045 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01701
2025-08-14 14:57:14,053 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,054 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,055 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01702
2025-08-14 14:57:14,061 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,061 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,067 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,067 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,073 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,073 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,075 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,075 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,078 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,078 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,081 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,081 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,090 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,090 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,101 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,101 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,105 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,105 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,108 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,108 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,109 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01703
2025-08-14 14:57:14,110 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,110 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01704
2025-08-14 14:57:14,110 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,110 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01705
2025-08-14 14:57:14,111 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01706
2025-08-14 14:57:14,111 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01707
2025-08-14 14:57:14,111 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01708
2025-08-14 14:57:14,111 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01709
2025-08-14 14:57:14,112 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,112 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01710
2025-08-14 14:57:14,112 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,112 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01711
2025-08-14 14:57:14,113 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01712
2025-08-14 14:57:14,113 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01713
2025-08-14 14:57:14,113 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01714
2025-08-14 14:57:14,121 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,121 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,122 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01715
2025-08-14 14:57:14,125 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,125 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,129 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,129 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,131 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,131 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,132 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01716
2025-08-14 14:57:14,132 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01717
2025-08-14 14:57:14,132 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01718
2025-08-14 14:57:14,146 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,146 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,147 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01719
2025-08-14 14:57:14,150 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,150 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,162 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,162 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,163 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01720
2025-08-14 14:57:14,163 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01721
2025-08-14 14:57:14,165 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,165 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,169 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,169 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,174 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,174 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,175 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01722
2025-08-14 14:57:14,175 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01723
2025-08-14 14:57:14,179 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,179 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,180 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,181 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01724
2025-08-14 14:57:14,181 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,181 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01725
2025-08-14 14:57:14,186 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,186 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,189 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,189 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,190 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01726
2025-08-14 14:57:14,190 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01727
2025-08-14 14:57:14,190 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01728
2025-08-14 14:57:14,194 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,194 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,201 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,202 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,203 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01729
2025-08-14 14:57:14,203 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01730
2025-08-14 14:57:14,218 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,218 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,220 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,220 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,221 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,221 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,223 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01731
2025-08-14 14:57:14,223 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01732
2025-08-14 14:57:14,223 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01733
2025-08-14 14:57:14,233 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,233 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,238 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,238 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,241 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,241 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,241 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,242 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,243 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01734
2025-08-14 14:57:14,245 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,245 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,246 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01735
2025-08-14 14:57:14,246 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01736
2025-08-14 14:57:14,246 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01737
2025-08-14 14:57:14,255 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,255 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,256 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01738
2025-08-14 14:57:14,256 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01739
2025-08-14 14:57:14,257 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,257 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,258 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01740
2025-08-14 14:57:14,270 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,270 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,271 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01741
2025-08-14 14:57:14,275 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,275 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,276 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01742
2025-08-14 14:57:14,279 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,279 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,280 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01743
2025-08-14 14:57:14,282 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,282 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,284 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,284 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,285 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01744
2025-08-14 14:57:14,285 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01745
2025-08-14 14:57:14,296 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,296 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,297 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01746
2025-08-14 14:57:14,311 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,311 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,313 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,313 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01747
2025-08-14 14:57:14,313 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,314 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,314 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,316 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01748
2025-08-14 14:57:14,319 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,319 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,319 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,319 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,322 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01749
2025-08-14 14:57:14,322 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01750
2025-08-14 14:57:14,322 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01751
2025-08-14 14:57:14,326 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,326 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,329 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,329 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,330 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01752
2025-08-14 14:57:14,334 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,335 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,337 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,337 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,339 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01753
2025-08-14 14:57:14,339 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01754
2025-08-14 14:57:14,339 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01755
2025-08-14 14:57:14,351 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,351 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,352 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01756
2025-08-14 14:57:14,368 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,368 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,370 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,370 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,373 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,373 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,378 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,378 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01757
2025-08-14 14:57:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01758
2025-08-14 14:57:14,384 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,384 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,384 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,385 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,386 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,388 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,388 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01759
2025-08-14 14:57:14,388 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,388 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,388 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01760
2025-08-14 14:57:14,391 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01761
2025-08-14 14:57:14,391 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01762
2025-08-14 14:57:14,391 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01763
2025-08-14 14:57:14,391 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01764
2025-08-14 14:57:14,395 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,395 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,396 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01765
2025-08-14 14:57:14,411 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,411 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,412 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01766
2025-08-14 14:57:14,414 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,414 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,416 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,416 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,417 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01767
2025-08-14 14:57:14,417 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01768
2025-08-14 14:57:14,429 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,429 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,430 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01769
2025-08-14 14:57:14,439 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,440 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,440 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,440 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,444 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,444 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,445 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01770
2025-08-14 14:57:14,445 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01771
2025-08-14 14:57:14,453 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,453 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,455 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,455 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,457 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,458 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,458 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,458 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,459 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01772
2025-08-14 14:57:14,460 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01773
2025-08-14 14:57:14,461 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01774
2025-08-14 14:57:14,461 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01775
2025-08-14 14:57:14,464 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,464 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,466 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,466 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,467 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01776
2025-08-14 14:57:14,467 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01777
2025-08-14 14:57:14,467 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01778
2025-08-14 14:57:14,486 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,486 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,487 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01779
2025-08-14 14:57:14,492 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,492 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,494 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,494 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,496 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01780
2025-08-14 14:57:14,496 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01781
2025-08-14 14:57:14,502 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,502 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,514 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,514 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,515 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,515 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,516 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01782
2025-08-14 14:57:14,520 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,520 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,521 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,521 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,525 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,525 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,536 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,536 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01783
2025-08-14 14:57:14,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01784
2025-08-14 14:57:14,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01785
2025-08-14 14:57:14,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01786
2025-08-14 14:57:14,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01787
2025-08-14 14:57:14,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01788
2025-08-14 14:57:14,541 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,541 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,542 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01789
2025-08-14 14:57:14,545 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,545 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,546 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01790
2025-08-14 14:57:14,547 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,547 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,549 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,549 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,550 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01791
2025-08-14 14:57:14,550 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01792
2025-08-14 14:57:14,569 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,569 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,570 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01793
2025-08-14 14:57:14,576 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,576 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,580 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,580 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,581 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01794
2025-08-14 14:57:14,584 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,584 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,585 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01795
2025-08-14 14:57:14,586 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01796
2025-08-14 14:57:14,591 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,591 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,593 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,594 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,594 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,594 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,596 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01797
2025-08-14 14:57:14,597 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,597 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01798
2025-08-14 14:57:14,597 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,599 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,599 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,600 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01799
2025-08-14 14:57:14,600 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01800
2025-08-14 14:57:14,600 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01801
2025-08-14 14:57:14,605 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,605 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,606 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01802
2025-08-14 14:57:14,618 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,618 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,619 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01803
2025-08-14 14:57:14,635 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,635 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,636 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,637 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01804
2025-08-14 14:57:14,645 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,645 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,646 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01805
2025-08-14 14:57:14,650 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,650 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,651 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01806
2025-08-14 14:57:14,651 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01807
2025-08-14 14:57:14,653 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,653 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,653 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,653 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,655 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,655 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01808
2025-08-14 14:57:14,656 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,660 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,660 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,666 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,667 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,667 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,667 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,669 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01809
2025-08-14 14:57:14,669 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01810
2025-08-14 14:57:14,669 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01811
2025-08-14 14:57:14,669 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01812
2025-08-14 14:57:14,669 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01813
2025-08-14 14:57:14,681 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,681 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,682 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01814
2025-08-14 14:57:14,691 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,691 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,692 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01815
2025-08-14 14:57:14,704 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,704 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,712 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,712 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,713 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,714 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,714 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,714 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,716 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,716 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,717 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,718 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01816
2025-08-14 14:57:14,718 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,718 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,718 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,720 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01817
2025-08-14 14:57:14,722 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01818
2025-08-14 14:57:14,722 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01819
2025-08-14 14:57:14,722 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01820
2025-08-14 14:57:14,722 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01821
2025-08-14 14:57:14,722 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01822
2025-08-14 14:57:14,725 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,725 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,737 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,738 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,739 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01823
2025-08-14 14:57:14,739 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01824
2025-08-14 14:57:14,746 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,746 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,747 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01825
2025-08-14 14:57:14,759 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,759 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,760 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01826
2025-08-14 14:57:14,767 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,768 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,768 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,768 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,770 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01827
2025-08-14 14:57:14,771 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,771 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,771 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,772 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,778 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,778 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,779 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,780 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,781 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01828
2025-08-14 14:57:14,781 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01829
2025-08-14 14:57:14,781 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01830
2025-08-14 14:57:14,781 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01831
2025-08-14 14:57:14,786 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,786 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,787 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01832
2025-08-14 14:57:14,787 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01833
2025-08-14 14:57:14,803 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,803 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,808 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,808 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,809 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01834
2025-08-14 14:57:14,810 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01835
2025-08-14 14:57:14,811 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01836
2025-08-14 14:57:14,816 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,817 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,817 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,817 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,819 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01837
2025-08-14 14:57:14,824 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,824 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,826 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01838
2025-08-14 14:57:14,837 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,837 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,842 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,843 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,844 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01839
2025-08-14 14:57:14,844 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01840
2025-08-14 14:57:14,844 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01841
2025-08-14 14:57:14,847 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,847 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,848 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01842
2025-08-14 14:57:14,851 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,851 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,852 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01843
2025-08-14 14:57:14,858 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,858 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,859 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01844
2025-08-14 14:57:14,861 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,861 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,863 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,863 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,865 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,866 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,878 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,878 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,879 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01845
2025-08-14 14:57:14,879 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01846
2025-08-14 14:57:14,879 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01847
2025-08-14 14:57:14,879 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01848
2025-08-14 14:57:14,880 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,880 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,881 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01849
2025-08-14 14:57:14,895 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,895 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,896 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01850
2025-08-14 14:57:14,897 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,897 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,898 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01851
2025-08-14 14:57:14,907 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,907 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,912 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,912 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,914 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,914 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,915 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,916 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,916 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,916 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,924 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,924 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,925 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01852
2025-08-14 14:57:14,925 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01853
2025-08-14 14:57:14,925 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01854
2025-08-14 14:57:14,925 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01855
2025-08-14 14:57:14,925 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01856
2025-08-14 14:57:14,925 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01857
2025-08-14 14:57:14,935 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,935 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,949 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,949 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,950 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01858
2025-08-14 14:57:14,951 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,951 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01859
2025-08-14 14:57:14,951 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,953 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,953 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,953 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,953 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,956 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01860
2025-08-14 14:57:14,956 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01861
2025-08-14 14:57:14,956 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01862
2025-08-14 14:57:14,963 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,963 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,964 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01863
2025-08-14 14:57:14,965 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,965 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,968 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,969 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,970 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01864
2025-08-14 14:57:14,970 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01865
2025-08-14 14:57:14,982 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,982 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,983 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01866
2025-08-14 14:57:14,989 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,990 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,990 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,990 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:14,991 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01867
2025-08-14 14:57:14,993 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01868
2025-08-14 14:57:14,996 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:14,996 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,008 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,008 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,013 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,013 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,015 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,015 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,020 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,020 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,021 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01869
2025-08-14 14:57:15,021 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,021 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01870
2025-08-14 14:57:15,022 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,022 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01871
2025-08-14 14:57:15,023 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01872
2025-08-14 14:57:15,023 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01873
2025-08-14 14:57:15,023 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01874
2025-08-14 14:57:15,023 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,024 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,025 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01875
2025-08-14 14:57:15,040 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,040 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,047 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,047 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,047 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,047 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,050 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01876
2025-08-14 14:57:15,055 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,055 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,056 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01877
2025-08-14 14:57:15,056 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01878
2025-08-14 14:57:15,056 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01879
2025-08-14 14:57:15,063 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,063 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,064 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01880
2025-08-14 14:57:15,065 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,065 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,070 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,070 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,071 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,072 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01881
2025-08-14 14:57:15,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01882
2025-08-14 14:57:15,083 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,084 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,091 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,091 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,093 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01883
2025-08-14 14:57:15,093 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01884
2025-08-14 14:57:15,104 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,104 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,113 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,113 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,117 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,117 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,118 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,118 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,120 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,120 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,128 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,128 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,133 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,133 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,134 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,135 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,135 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,135 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,137 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01885
2025-08-14 14:57:15,137 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01886
2025-08-14 14:57:15,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01887
2025-08-14 14:57:15,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01888
2025-08-14 14:57:15,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01889
2025-08-14 14:57:15,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01890
2025-08-14 14:57:15,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01891
2025-08-14 14:57:15,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01892
2025-08-14 14:57:15,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01893
2025-08-14 14:57:15,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01894
2025-08-14 14:57:15,159 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,159 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,164 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,164 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,165 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01895
2025-08-14 14:57:15,165 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01896
2025-08-14 14:57:15,168 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,168 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,172 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,172 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,173 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,173 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,179 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,179 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,180 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01897
2025-08-14 14:57:15,180 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01898
2025-08-14 14:57:15,180 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01899
2025-08-14 14:57:15,181 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,182 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,185 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,185 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,186 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01900
2025-08-14 14:57:15,186 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01901
2025-08-14 14:57:15,186 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01902
2025-08-14 14:57:15,194 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,194 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,196 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,196 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,197 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01903
2025-08-14 14:57:15,197 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01904
2025-08-14 14:57:15,214 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,214 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,215 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01905
2025-08-14 14:57:15,218 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,219 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,219 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,219 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,228 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,228 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,231 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,231 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,232 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,232 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,234 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01906
2025-08-14 14:57:15,234 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01907
2025-08-14 14:57:15,234 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01908
2025-08-14 14:57:15,234 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01909
2025-08-14 14:57:15,243 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,244 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,245 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01910
2025-08-14 14:57:15,245 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01911
2025-08-14 14:57:15,251 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,251 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,252 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,252 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,252 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,252 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,253 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01912
2025-08-14 14:57:15,256 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01913
2025-08-14 14:57:15,256 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01914
2025-08-14 14:57:15,263 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,263 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,270 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,270 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,270 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,270 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,272 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01915
2025-08-14 14:57:15,273 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01916
2025-08-14 14:57:15,273 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01917
2025-08-14 14:57:15,279 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,279 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,283 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,283 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,284 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01918
2025-08-14 14:57:15,284 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01919
2025-08-14 14:57:15,298 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,298 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,299 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01920
2025-08-14 14:57:15,307 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,307 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,309 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,309 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,309 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,309 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,312 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01921
2025-08-14 14:57:15,313 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,313 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01922
2025-08-14 14:57:15,313 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,319 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,319 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,320 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01923
2025-08-14 14:57:15,320 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01924
2025-08-14 14:57:15,320 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01925
2025-08-14 14:57:15,321 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,321 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,322 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01926
2025-08-14 14:57:15,326 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,327 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,328 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01927
2025-08-14 14:57:15,328 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,328 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,329 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01928
2025-08-14 14:57:15,337 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,337 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,338 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01929
2025-08-14 14:57:15,351 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,351 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,364 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,364 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,368 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,368 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,369 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01930
2025-08-14 14:57:15,370 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01931
2025-08-14 14:57:15,370 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01932
2025-08-14 14:57:15,372 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,372 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,377 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,378 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01933
2025-08-14 14:57:15,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01934
2025-08-14 14:57:15,382 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,382 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,382 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,382 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,384 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,385 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,386 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01935
2025-08-14 14:57:15,392 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,392 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,395 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,395 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,423 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,423 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,430 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,430 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,431 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,431 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,437 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,437 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,438 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01936
2025-08-14 14:57:15,438 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,438 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01937
2025-08-14 14:57:15,438 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,439 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01938
2025-08-14 14:57:15,440 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,440 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01939
2025-08-14 14:57:15,440 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,441 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01940
2025-08-14 14:57:15,442 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01941
2025-08-14 14:57:15,442 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01942
2025-08-14 14:57:15,442 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01943
2025-08-14 14:57:15,443 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,443 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,444 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01944
2025-08-14 14:57:15,444 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01945
2025-08-14 14:57:15,446 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,447 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,447 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,447 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,478 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,478 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,480 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,480 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,487 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,488 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,488 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,488 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,492 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,492 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,496 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,496 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,502 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,502 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,508 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,508 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,510 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,510 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,511 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01946
2025-08-14 14:57:15,511 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01947
2025-08-14 14:57:15,512 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01948
2025-08-14 14:57:15,512 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01949
2025-08-14 14:57:15,512 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01950
2025-08-14 14:57:15,512 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01951
2025-08-14 14:57:15,512 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01952
2025-08-14 14:57:15,512 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01953
2025-08-14 14:57:15,512 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01954
2025-08-14 14:57:15,512 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01955
2025-08-14 14:57:15,528 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,528 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,530 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,530 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,531 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01956
2025-08-14 14:57:15,531 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01957
2025-08-14 14:57:15,531 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01958
2025-08-14 14:57:15,533 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,533 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,534 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01959
2025-08-14 14:57:15,534 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01960
2025-08-14 14:57:15,536 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,536 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,539 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,539 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,540 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01961
2025-08-14 14:57:15,548 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,548 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,549 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01962
2025-08-14 14:57:15,549 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01963
2025-08-14 14:57:15,557 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,557 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,558 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,558 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,560 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01964
2025-08-14 14:57:15,560 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01965
2025-08-14 14:57:15,575 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,575 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,577 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,577 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,578 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,578 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,579 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01966
2025-08-14 14:57:15,579 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,581 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01967
2025-08-14 14:57:15,581 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,581 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01968
2025-08-14 14:57:15,588 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,588 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,589 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,589 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,595 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,595 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,596 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01969
2025-08-14 14:57:15,596 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01970
2025-08-14 14:57:15,596 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01971
2025-08-14 14:57:15,596 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01972
2025-08-14 14:57:15,606 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,606 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,607 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01973
2025-08-14 14:57:15,612 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,612 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,613 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01974
2025-08-14 14:57:15,620 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,620 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,621 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01975
2025-08-14 14:57:15,623 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,623 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,627 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,627 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,640 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,640 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,641 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,641 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01976
2025-08-14 14:57:15,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01977
2025-08-14 14:57:15,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01978
2025-08-14 14:57:15,646 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,646 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,648 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,648 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,649 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01979
2025-08-14 14:57:15,649 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01980
2025-08-14 14:57:15,649 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01981
2025-08-14 14:57:15,660 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,660 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,661 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01982
2025-08-14 14:57:15,664 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,664 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,665 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01983
2025-08-14 14:57:15,667 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,667 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01984
2025-08-14 14:57:15,669 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,669 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,676 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,676 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,677 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,677 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,679 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01985
2025-08-14 14:57:15,679 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01986
2025-08-14 14:57:15,679 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01987
2025-08-14 14:57:15,691 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,691 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,692 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01988
2025-08-14 14:57:15,701 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,701 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,706 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,706 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,707 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01989
2025-08-14 14:57:15,707 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01990
2025-08-14 14:57:15,713 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,713 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,714 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,714 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,715 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01991
2025-08-14 14:57:15,722 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,722 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,722 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,722 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,725 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,726 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,726 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,726 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,728 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01992
2025-08-14 14:57:15,729 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01993
2025-08-14 14:57:15,729 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01994
2025-08-14 14:57:15,729 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01995
2025-08-14 14:57:15,729 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01996
2025-08-14 14:57:15,733 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,733 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,734 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01997
2025-08-14 14:57:15,745 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,745 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,746 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01998
2025-08-14 14:57:15,756 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,757 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,757 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,757 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,759 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01999
2025-08-14 14:57:15,771 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,771 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,772 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02000
2025-08-14 14:57:15,772 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02001
2025-08-14 14:57:15,775 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,775 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,777 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,777 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,781 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,781 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,784 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,784 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,785 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02002
2025-08-14 14:57:15,785 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02003
2025-08-14 14:57:15,785 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02004
2025-08-14 14:57:15,785 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02005
2025-08-14 14:57:15,788 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,788 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,792 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,792 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,793 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02006
2025-08-14 14:57:15,793 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02007
2025-08-14 14:57:15,796 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,796 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,798 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02008
2025-08-14 14:57:15,802 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,802 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,812 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,812 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,813 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02009
2025-08-14 14:57:15,813 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02010
2025-08-14 14:57:15,823 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,823 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,832 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,832 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,836 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,836 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,837 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02011
2025-08-14 14:57:15,837 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02012
2025-08-14 14:57:15,837 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02013
2025-08-14 14:57:15,839 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,839 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,840 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02014
2025-08-14 14:57:15,844 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,844 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,846 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,846 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,847 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,847 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,856 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,856 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,867 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,867 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,876 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,876 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,887 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,887 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,890 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,890 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,897 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,897 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,898 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,899 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,899 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,900 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,902 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,902 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,912 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,912 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,913 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02015
2025-08-14 14:57:15,913 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02016
2025-08-14 14:57:15,913 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02017
2025-08-14 14:57:15,913 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02018
2025-08-14 14:57:15,913 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02019
2025-08-14 14:57:15,913 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02020
2025-08-14 14:57:15,913 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02021
2025-08-14 14:57:15,913 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02022
2025-08-14 14:57:15,913 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02023
2025-08-14 14:57:15,913 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02024
2025-08-14 14:57:15,913 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02025
2025-08-14 14:57:15,913 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02026
2025-08-14 14:57:15,913 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02027
2025-08-14 14:57:15,921 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,921 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,922 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,922 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02028
2025-08-14 14:57:15,922 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,924 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02029
2025-08-14 14:57:15,925 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,925 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,926 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02030
2025-08-14 14:57:15,933 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,933 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,942 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,942 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,943 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02031
2025-08-14 14:57:15,943 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02032
2025-08-14 14:57:15,950 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,950 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,955 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,955 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,956 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02033
2025-08-14 14:57:15,956 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02034
2025-08-14 14:57:15,958 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,958 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,959 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02035
2025-08-14 14:57:15,967 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,967 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,968 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02036
2025-08-14 14:57:15,976 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,976 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,978 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,979 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,979 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,979 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,980 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02037
2025-08-14 14:57:15,982 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,983 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,986 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:15,987 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:15,988 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02038
2025-08-14 14:57:15,988 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02039
2025-08-14 14:57:15,988 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02040
2025-08-14 14:57:15,988 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02041
2025-08-14 14:57:16,001 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,001 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,003 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,003 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02042
2025-08-14 14:57:16,003 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,004 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02043
2025-08-14 14:57:16,013 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,013 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,014 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02044
2025-08-14 14:57:16,015 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,015 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,016 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02045
2025-08-14 14:57:16,020 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,020 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,027 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,027 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,032 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,032 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,033 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02046
2025-08-14 14:57:16,033 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02047
2025-08-14 14:57:16,033 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02048
2025-08-14 14:57:16,038 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,038 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,051 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,051 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,053 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,053 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02049
2025-08-14 14:57:16,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02050
2025-08-14 14:57:16,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02051
2025-08-14 14:57:16,054 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,055 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,056 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,056 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,057 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02052
2025-08-14 14:57:16,058 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02053
2025-08-14 14:57:16,064 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,064 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,071 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,071 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,072 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,072 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02054
2025-08-14 14:57:16,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02055
2025-08-14 14:57:16,074 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02056
2025-08-14 14:57:16,076 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,076 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,077 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02057
2025-08-14 14:57:16,094 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,094 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,097 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,097 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02058
2025-08-14 14:57:16,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02059
2025-08-14 14:57:16,106 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,106 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,110 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,110 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,115 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,115 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,116 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,117 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,118 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02060
2025-08-14 14:57:16,122 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,122 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,123 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02061
2025-08-14 14:57:16,123 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02062
2025-08-14 14:57:16,123 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02063
2025-08-14 14:57:16,123 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02064
2025-08-14 14:57:16,124 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,124 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,128 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,128 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,129 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02065
2025-08-14 14:57:16,130 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,130 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,131 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02066
2025-08-14 14:57:16,132 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02067
2025-08-14 14:57:16,150 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,150 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,151 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02068
2025-08-14 14:57:16,153 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,153 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,157 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,157 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,161 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,161 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,162 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02069
2025-08-14 14:57:16,163 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02070
2025-08-14 14:57:16,163 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02071
2025-08-14 14:57:16,169 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,169 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,171 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02072
2025-08-14 14:57:16,173 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,173 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,181 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,181 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,182 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02073
2025-08-14 14:57:16,183 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,183 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,188 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,188 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,188 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,188 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,189 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02074
2025-08-14 14:57:16,191 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02075
2025-08-14 14:57:16,191 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02076
2025-08-14 14:57:16,191 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02077
2025-08-14 14:57:16,198 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,198 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,206 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,206 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,207 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02078
2025-08-14 14:57:16,207 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02079
2025-08-14 14:57:16,208 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,208 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,209 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02080
2025-08-14 14:57:16,221 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,221 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,225 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,225 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,227 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,227 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,228 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02081
2025-08-14 14:57:16,228 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02082
2025-08-14 14:57:16,228 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02083
2025-08-14 14:57:16,239 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,239 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,241 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,241 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,246 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,247 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,247 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,247 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,249 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02084
2025-08-14 14:57:16,250 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02085
2025-08-14 14:57:16,250 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02086
2025-08-14 14:57:16,259 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,259 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,260 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02087
2025-08-14 14:57:16,260 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02088
2025-08-14 14:57:16,262 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,262 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,263 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02089
2025-08-14 14:57:16,264 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,264 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,265 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02090
2025-08-14 14:57:16,270 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,270 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,271 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02091
2025-08-14 14:57:16,280 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,280 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,281 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02092
2025-08-14 14:57:16,285 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,285 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,292 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,292 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,293 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02093
2025-08-14 14:57:16,297 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,297 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,298 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02094
2025-08-14 14:57:16,298 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02095
2025-08-14 14:57:16,305 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,305 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,306 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02096
2025-08-14 14:57:16,314 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,314 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,315 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02097
2025-08-14 14:57:16,316 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,316 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,317 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,318 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,319 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,319 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,324 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,325 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,326 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02098
2025-08-14 14:57:16,326 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02099
2025-08-14 14:57:16,326 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02100
2025-08-14 14:57:16,326 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02101
2025-08-14 14:57:16,332 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,332 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,339 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,339 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,340 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02102
2025-08-14 14:57:16,340 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02103
2025-08-14 14:57:16,352 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,352 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,357 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,357 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,359 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02104
2025-08-14 14:57:16,359 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02105
2025-08-14 14:57:16,363 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,363 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,364 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02106
2025-08-14 14:57:16,367 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,367 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,368 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,368 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,372 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,373 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,378 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,378 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,379 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,379 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,380 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02107
2025-08-14 14:57:16,381 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02108
2025-08-14 14:57:16,381 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02109
2025-08-14 14:57:16,381 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02110
2025-08-14 14:57:16,394 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,394 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,395 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,395 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,397 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02111
2025-08-14 14:57:16,397 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02112
2025-08-14 14:57:16,397 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02113
2025-08-14 14:57:16,408 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,408 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,409 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02114
2025-08-14 14:57:16,416 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,416 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,421 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,422 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,422 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,423 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,423 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,423 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,423 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,423 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,428 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02115
2025-08-14 14:57:16,429 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02116
2025-08-14 14:57:16,429 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02117
2025-08-14 14:57:16,430 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02118
2025-08-14 14:57:16,430 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02119
2025-08-14 14:57:16,430 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02120
2025-08-14 14:57:16,444 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,444 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,445 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02121
2025-08-14 14:57:16,450 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,450 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,451 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02122
2025-08-14 14:57:16,463 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,464 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,464 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,464 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,466 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02123
2025-08-14 14:57:16,467 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,467 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02124
2025-08-14 14:57:16,467 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,468 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02125
2025-08-14 14:57:16,471 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,471 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,474 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,474 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,475 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02126
2025-08-14 14:57:16,476 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02127
2025-08-14 14:57:16,484 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,484 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,486 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,486 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,496 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,496 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,497 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02128
2025-08-14 14:57:16,497 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02129
2025-08-14 14:57:16,497 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02130
2025-08-14 14:57:16,504 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,504 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,509 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,509 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,510 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02131
2025-08-14 14:57:16,510 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02132
2025-08-14 14:57:16,514 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,515 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,517 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,517 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,524 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,524 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,531 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,532 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,534 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,534 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,535 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02133
2025-08-14 14:57:16,535 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02134
2025-08-14 14:57:16,535 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02135
2025-08-14 14:57:16,535 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02136
2025-08-14 14:57:16,535 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02137
2025-08-14 14:57:16,539 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,539 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,540 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02138
2025-08-14 14:57:16,544 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,544 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,546 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02139
2025-08-14 14:57:16,561 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,561 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,563 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,563 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02140
2025-08-14 14:57:16,563 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,568 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,568 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,576 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,576 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,579 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,579 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,580 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02141
2025-08-14 14:57:16,581 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,581 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02142
2025-08-14 14:57:16,581 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,581 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02143
2025-08-14 14:57:16,582 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02144
2025-08-14 14:57:16,582 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02145
2025-08-14 14:57:16,587 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,587 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,588 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02146
2025-08-14 14:57:16,594 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,594 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,603 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,603 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02147
2025-08-14 14:57:16,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02148
2025-08-14 14:57:16,605 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,605 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,607 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02149
2025-08-14 14:57:16,608 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,608 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,618 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,618 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,626 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,626 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,627 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02150
2025-08-14 14:57:16,627 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02151
2025-08-14 14:57:16,627 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02152
2025-08-14 14:57:16,636 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,636 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,638 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,638 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,640 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,640 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,642 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,642 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02153
2025-08-14 14:57:16,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02154
2025-08-14 14:57:16,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02155
2025-08-14 14:57:16,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02156
2025-08-14 14:57:16,652 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,652 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,657 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,657 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,659 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02157
2025-08-14 14:57:16,663 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,663 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,666 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,666 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,672 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,672 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,673 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02158
2025-08-14 14:57:16,673 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02159
2025-08-14 14:57:16,673 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02160
2025-08-14 14:57:16,673 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02161
2025-08-14 14:57:16,690 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,690 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,692 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,692 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,693 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,693 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,693 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,693 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,696 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02162
2025-08-14 14:57:16,698 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,698 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02163
2025-08-14 14:57:16,698 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,698 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02164
2025-08-14 14:57:16,699 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02165
2025-08-14 14:57:16,707 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,707 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,708 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02166
2025-08-14 14:57:16,708 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02167
2025-08-14 14:57:16,712 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,712 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,713 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02168
2025-08-14 14:57:16,714 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,715 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,721 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,721 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,722 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02169
2025-08-14 14:57:16,722 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02170
2025-08-14 14:57:16,737 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,737 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02171
2025-08-14 14:57:16,741 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,741 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,742 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02172
2025-08-14 14:57:16,743 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,743 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,749 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,749 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,750 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02173
2025-08-14 14:57:16,751 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,751 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,759 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,759 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,761 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02174
2025-08-14 14:57:16,761 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02175
2025-08-14 14:57:16,761 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02176
2025-08-14 14:57:16,767 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,767 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,771 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,771 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,773 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02177
2025-08-14 14:57:16,773 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02178
2025-08-14 14:57:16,779 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,779 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,787 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,787 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,792 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,792 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,803 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,803 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,804 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02179
2025-08-14 14:57:16,805 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,805 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02180
2025-08-14 14:57:16,805 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,807 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,807 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,808 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,808 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,809 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02181
2025-08-14 14:57:16,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02182
2025-08-14 14:57:16,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02183
2025-08-14 14:57:16,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02184
2025-08-14 14:57:16,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02185
2025-08-14 14:57:16,822 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,822 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,825 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,825 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,827 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02186
2025-08-14 14:57:16,827 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02187
2025-08-14 14:57:16,831 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,831 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,836 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,836 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,838 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,838 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02188
2025-08-14 14:57:16,838 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,839 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02189
2025-08-14 14:57:16,839 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02190
2025-08-14 14:57:16,843 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,843 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,844 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02191
2025-08-14 14:57:16,852 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,852 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,853 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02192
2025-08-14 14:57:16,860 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,860 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,861 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02193
2025-08-14 14:57:16,862 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,862 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02194
2025-08-14 14:57:16,876 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,876 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,877 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,877 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,886 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,886 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,887 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02195
2025-08-14 14:57:16,887 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02196
2025-08-14 14:57:16,892 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,892 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,894 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,894 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02197
2025-08-14 14:57:16,894 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,894 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02198
2025-08-14 14:57:16,896 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,896 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,900 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,901 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,901 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,901 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,902 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02199
2025-08-14 14:57:16,903 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02200
2025-08-14 14:57:16,903 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02201
2025-08-14 14:57:16,904 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02202
2025-08-14 14:57:16,914 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,914 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,916 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02203
2025-08-14 14:57:16,918 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,918 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,919 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02204
2025-08-14 14:57:16,920 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,920 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02205
2025-08-14 14:57:16,932 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,932 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,933 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02206
2025-08-14 14:57:16,945 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,945 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,951 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,951 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,955 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,955 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,955 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,956 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,958 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,958 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02207
2025-08-14 14:57:16,959 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,960 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02208
2025-08-14 14:57:16,960 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02209
2025-08-14 14:57:16,960 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02210
2025-08-14 14:57:16,960 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02211
2025-08-14 14:57:16,964 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,965 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,967 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,967 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,968 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02212
2025-08-14 14:57:16,970 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,970 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,971 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02213
2025-08-14 14:57:16,974 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,974 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,975 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02214
2025-08-14 14:57:16,975 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02215
2025-08-14 14:57:16,989 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,989 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,990 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02216
2025-08-14 14:57:16,998 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:16,998 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:16,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02217
2025-08-14 14:57:17,000 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,000 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,001 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02218
2025-08-14 14:57:17,008 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,008 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,014 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,014 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,015 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02219
2025-08-14 14:57:17,024 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,024 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,026 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,026 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,027 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,028 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,029 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02220
2025-08-14 14:57:17,029 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02221
2025-08-14 14:57:17,029 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02222
2025-08-14 14:57:17,030 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,030 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,032 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,032 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,034 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02223
2025-08-14 14:57:17,034 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02224
2025-08-14 14:57:17,034 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02225
2025-08-14 14:57:17,044 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,044 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,045 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02226
2025-08-14 14:57:17,050 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,050 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,052 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,052 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,052 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,053 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02227
2025-08-14 14:57:17,055 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02228
2025-08-14 14:57:17,055 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02229
2025-08-14 14:57:17,072 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,072 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02230
2025-08-14 14:57:17,082 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,082 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,087 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,087 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,097 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,097 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,098 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,099 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,099 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,100 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,100 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,100 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,102 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,102 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,102 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,104 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,104 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,107 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,108 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02231
2025-08-14 14:57:17,110 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02232
2025-08-14 14:57:17,110 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02233
2025-08-14 14:57:17,110 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02234
2025-08-14 14:57:17,110 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02235
2025-08-14 14:57:17,110 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02236
2025-08-14 14:57:17,110 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02237
2025-08-14 14:57:17,110 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02238
2025-08-14 14:57:17,110 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02239
2025-08-14 14:57:17,131 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,131 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,132 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02240
2025-08-14 14:57:17,137 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,137 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02241
2025-08-14 14:57:17,142 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,142 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,143 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02242
2025-08-14 14:57:17,150 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,150 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,151 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,151 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,156 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,156 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,157 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,157 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,164 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,164 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,165 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02243
2025-08-14 14:57:17,165 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02244
2025-08-14 14:57:17,165 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02245
2025-08-14 14:57:17,165 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02246
2025-08-14 14:57:17,165 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02247
2025-08-14 14:57:17,172 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,172 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,173 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02248
2025-08-14 14:57:17,182 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,182 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,183 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02249
2025-08-14 14:57:17,192 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,193 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,193 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,193 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,194 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,196 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02250
2025-08-14 14:57:17,196 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,196 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02251
2025-08-14 14:57:17,197 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,198 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,199 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02252
2025-08-14 14:57:17,199 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02253
2025-08-14 14:57:17,200 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,200 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,201 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02254
2025-08-14 14:57:17,209 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,209 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,210 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02255
2025-08-14 14:57:17,212 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,212 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,213 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02256
2025-08-14 14:57:17,234 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,234 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02257
2025-08-14 14:57:17,239 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,239 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,240 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,240 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,241 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02258
2025-08-14 14:57:17,247 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,248 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,249 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,249 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,249 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,249 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,251 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02259
2025-08-14 14:57:17,253 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02260
2025-08-14 14:57:17,253 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,253 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02261
2025-08-14 14:57:17,253 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,255 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,255 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,256 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02262
2025-08-14 14:57:17,256 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02263
2025-08-14 14:57:17,256 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02264
2025-08-14 14:57:17,261 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,261 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,262 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02265
2025-08-14 14:57:17,267 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,267 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,268 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02266
2025-08-14 14:57:17,284 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,284 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,298 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,298 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,304 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,304 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,305 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,305 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,306 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02267
2025-08-14 14:57:17,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02268
2025-08-14 14:57:17,308 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,309 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,309 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,309 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,311 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02269
2025-08-14 14:57:17,311 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02270
2025-08-14 14:57:17,312 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02271
2025-08-14 14:57:17,312 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,313 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,316 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,317 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,318 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02272
2025-08-14 14:57:17,318 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02273
2025-08-14 14:57:17,318 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02274
2025-08-14 14:57:17,318 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,318 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,320 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02275
2025-08-14 14:57:17,321 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,321 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,323 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02276
2025-08-14 14:57:17,333 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,333 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,334 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02277
2025-08-14 14:57:17,347 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,347 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,348 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02278
2025-08-14 14:57:17,358 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,358 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,359 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02279
2025-08-14 14:57:17,366 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,366 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,369 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,369 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,370 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,371 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,372 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,372 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,373 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02280
2025-08-14 14:57:17,374 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,375 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,376 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02281
2025-08-14 14:57:17,377 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,377 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,377 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02282
2025-08-14 14:57:17,377 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,377 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,378 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02283
2025-08-14 14:57:17,382 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,382 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,383 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02284
2025-08-14 14:57:17,383 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02285
2025-08-14 14:57:17,383 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02286
2025-08-14 14:57:17,383 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02287
2025-08-14 14:57:17,410 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,410 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,411 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02288
2025-08-14 14:57:17,413 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,413 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,414 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02289
2025-08-14 14:57:17,420 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,420 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,421 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,422 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,423 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02290
2025-08-14 14:57:17,423 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02291
2025-08-14 14:57:17,429 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,429 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,430 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02292
2025-08-14 14:57:17,434 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,434 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,442 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,442 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,443 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,443 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02293
2025-08-14 14:57:17,443 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,445 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02294
2025-08-14 14:57:17,445 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02295
2025-08-14 14:57:17,453 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,453 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,458 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,458 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,468 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,468 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,470 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,471 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,473 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,473 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,474 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02296
2025-08-14 14:57:17,474 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02297
2025-08-14 14:57:17,474 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02298
2025-08-14 14:57:17,474 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02299
2025-08-14 14:57:17,475 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02300
2025-08-14 14:57:17,477 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,477 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,478 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02301
2025-08-14 14:57:17,486 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,487 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02302
2025-08-14 14:57:17,489 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,489 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,490 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02303
2025-08-14 14:57:17,507 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,507 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,508 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,508 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,513 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,513 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,514 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02304
2025-08-14 14:57:17,514 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02305
2025-08-14 14:57:17,517 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,517 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,519 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,519 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,520 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02306
2025-08-14 14:57:17,520 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02307
2025-08-14 14:57:17,521 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,521 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,523 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,524 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,525 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02308
2025-08-14 14:57:17,525 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02309
2025-08-14 14:57:17,525 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02310
2025-08-14 14:57:17,533 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,533 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,534 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02311
2025-08-14 14:57:17,543 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,543 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,546 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,546 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,547 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02312
2025-08-14 14:57:17,548 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02313
2025-08-14 14:57:17,555 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,555 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,556 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02314
2025-08-14 14:57:17,562 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,562 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,574 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,574 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,576 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,576 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,577 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02315
2025-08-14 14:57:17,579 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,579 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,582 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,582 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,583 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02316
2025-08-14 14:57:17,584 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,584 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02317
2025-08-14 14:57:17,584 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,585 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02318
2025-08-14 14:57:17,585 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02319
2025-08-14 14:57:17,585 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02320
2025-08-14 14:57:17,595 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,595 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,595 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02321
2025-08-14 14:57:17,598 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,598 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,599 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02322
2025-08-14 14:57:17,604 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,604 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,604 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,606 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,606 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,606 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,607 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02323
2025-08-14 14:57:17,609 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02324
2025-08-14 14:57:17,609 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02325
2025-08-14 14:57:17,625 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,625 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,626 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02326
2025-08-14 14:57:17,634 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,635 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,642 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,642 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02327
2025-08-14 14:57:17,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02328
2025-08-14 14:57:17,648 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,648 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,649 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,649 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02329
2025-08-14 14:57:17,650 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,650 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,650 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,651 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02330
2025-08-14 14:57:17,653 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,654 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,654 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,654 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,656 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,657 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,658 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02331
2025-08-14 14:57:17,659 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02332
2025-08-14 14:57:17,659 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02333
2025-08-14 14:57:17,659 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02334
2025-08-14 14:57:17,665 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,665 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,666 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02335
2025-08-14 14:57:17,676 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,676 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,677 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02336
2025-08-14 14:57:17,689 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,689 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,690 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02337
2025-08-14 14:57:17,695 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,695 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,703 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,703 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,710 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,710 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,711 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,711 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02338
2025-08-14 14:57:17,712 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,714 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,714 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,715 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02339
2025-08-14 14:57:17,715 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02340
2025-08-14 14:57:17,716 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,716 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,716 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,716 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,719 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02341
2025-08-14 14:57:17,719 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02342
2025-08-14 14:57:17,719 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02343
2025-08-14 14:57:17,719 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02344
2025-08-14 14:57:17,723 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,723 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,724 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02345
2025-08-14 14:57:17,726 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,727 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,728 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02346
2025-08-14 14:57:17,739 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,739 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,744 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,744 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,745 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02347
2025-08-14 14:57:17,745 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02348
2025-08-14 14:57:17,757 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,757 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02349
2025-08-14 14:57:17,767 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,767 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,773 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,773 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,775 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,775 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,776 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02350
2025-08-14 14:57:17,776 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02351
2025-08-14 14:57:17,780 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,780 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,782 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,782 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,783 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,784 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,784 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,784 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,786 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,787 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,788 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02352
2025-08-14 14:57:17,788 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02353
2025-08-14 14:57:17,788 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02354
2025-08-14 14:57:17,788 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02355
2025-08-14 14:57:17,788 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02356
2025-08-14 14:57:17,789 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02357
2025-08-14 14:57:17,799 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,799 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,800 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02358
2025-08-14 14:57:17,805 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,805 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,806 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02359
2025-08-14 14:57:17,822 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,822 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,823 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02360
2025-08-14 14:57:17,828 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,829 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,829 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,829 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,831 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02361
2025-08-14 14:57:17,833 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,833 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,838 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,838 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,840 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,840 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,841 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02362
2025-08-14 14:57:17,841 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02363
2025-08-14 14:57:17,841 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02364
2025-08-14 14:57:17,841 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02365
2025-08-14 14:57:17,852 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,853 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,854 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,855 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,855 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,855 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,873 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,873 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,873 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,874 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,876 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02366
2025-08-14 14:57:17,876 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,877 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02367
2025-08-14 14:57:17,878 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02368
2025-08-14 14:57:17,878 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02369
2025-08-14 14:57:17,878 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02370
2025-08-14 14:57:17,878 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02371
2025-08-14 14:57:17,884 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,884 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,886 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,886 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,887 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02372
2025-08-14 14:57:17,887 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02373
2025-08-14 14:57:17,896 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,896 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,897 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02374
2025-08-14 14:57:17,904 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,904 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,906 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,906 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,907 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02375
2025-08-14 14:57:17,909 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,910 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,917 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,917 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,918 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,919 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02376
2025-08-14 14:57:17,919 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,919 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02377
2025-08-14 14:57:17,920 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02378
2025-08-14 14:57:17,920 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02379
2025-08-14 14:57:17,931 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,932 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,935 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,935 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,941 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,941 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,952 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,952 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,953 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,953 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02380
2025-08-14 14:57:17,954 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,954 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02381
2025-08-14 14:57:17,955 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02382
2025-08-14 14:57:17,955 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02383
2025-08-14 14:57:17,963 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,963 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,965 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,965 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,972 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,972 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,982 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,982 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,986 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,986 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,986 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,986 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,995 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,996 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,997 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:17,997 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02384
2025-08-14 14:57:17,997 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:17,997 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02385
2025-08-14 14:57:17,998 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02386
2025-08-14 14:57:17,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02387
2025-08-14 14:57:17,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02388
2025-08-14 14:57:17,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02389
2025-08-14 14:57:17,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02390
2025-08-14 14:57:17,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02391
2025-08-14 14:57:17,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02392
2025-08-14 14:57:18,004 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,005 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,009 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,009 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,019 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,019 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,021 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,021 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,022 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02393
2025-08-14 14:57:18,022 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02394
2025-08-14 14:57:18,022 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02395
2025-08-14 14:57:18,022 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02396
2025-08-14 14:57:18,038 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,038 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,038 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,038 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,041 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02397
2025-08-14 14:57:18,043 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,043 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,048 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,048 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,049 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02398
2025-08-14 14:57:18,049 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02399
2025-08-14 14:57:18,049 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02400
2025-08-14 14:57:18,053 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,053 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,054 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,055 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,055 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,055 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,055 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,057 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,058 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02401
2025-08-14 14:57:18,059 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02402
2025-08-14 14:57:18,059 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02403
2025-08-14 14:57:18,059 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02404
2025-08-14 14:57:18,075 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,075 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02405
2025-08-14 14:57:18,089 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,089 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,090 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02406
2025-08-14 14:57:18,090 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,090 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,091 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02407
2025-08-14 14:57:18,102 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,102 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,103 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,104 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,105 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,106 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,106 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,106 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,107 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02408
2025-08-14 14:57:18,109 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,109 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02409
2025-08-14 14:57:18,109 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,113 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,113 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,114 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02410
2025-08-14 14:57:18,114 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02411
2025-08-14 14:57:18,114 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02412
2025-08-14 14:57:18,114 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02413
2025-08-14 14:57:18,116 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,116 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,117 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02414
2025-08-14 14:57:18,130 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,130 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,131 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02415
2025-08-14 14:57:18,141 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,141 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,146 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,146 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,155 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,155 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,158 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,159 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,160 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,160 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,161 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02416
2025-08-14 14:57:18,161 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02417
2025-08-14 14:57:18,162 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02418
2025-08-14 14:57:18,162 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02419
2025-08-14 14:57:18,162 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02420
2025-08-14 14:57:18,164 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,164 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,172 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,172 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,173 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02421
2025-08-14 14:57:18,173 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02422
2025-08-14 14:57:18,174 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,174 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,177 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,178 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,179 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02423
2025-08-14 14:57:18,179 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02424
2025-08-14 14:57:18,185 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,185 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,186 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02425
2025-08-14 14:57:18,190 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,190 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,192 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,192 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,193 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02426
2025-08-14 14:57:18,193 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02427
2025-08-14 14:57:18,203 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,203 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,204 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02428
2025-08-14 14:57:18,213 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,213 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,215 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02429
2025-08-14 14:57:18,220 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,220 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,230 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,231 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02430
2025-08-14 14:57:18,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02431
2025-08-14 14:57:18,232 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,233 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,234 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,234 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,237 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,237 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,238 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02432
2025-08-14 14:57:18,238 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02433
2025-08-14 14:57:18,241 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,241 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,243 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,243 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,246 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,246 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,247 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02434
2025-08-14 14:57:18,247 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02435
2025-08-14 14:57:18,247 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02436
2025-08-14 14:57:18,247 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02437
2025-08-14 14:57:18,252 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,252 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,253 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02438
2025-08-14 14:57:18,268 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,268 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,270 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02439
2025-08-14 14:57:18,277 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,277 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,279 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,279 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02440
2025-08-14 14:57:18,279 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,290 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,290 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,294 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,294 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,295 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,295 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,300 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,300 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,302 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,302 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,302 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,303 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,305 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02441
2025-08-14 14:57:18,305 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02442
2025-08-14 14:57:18,305 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02443
2025-08-14 14:57:18,305 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02444
2025-08-14 14:57:18,305 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02445
2025-08-14 14:57:18,305 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02446
2025-08-14 14:57:18,311 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,311 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,312 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02447
2025-08-14 14:57:18,312 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02448
2025-08-14 14:57:18,323 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,323 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,324 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,324 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,325 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02449
2025-08-14 14:57:18,332 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,332 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,333 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02450
2025-08-14 14:57:18,334 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02451
2025-08-14 14:57:18,345 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,345 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,349 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,349 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,351 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,351 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02452
2025-08-14 14:57:18,351 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,352 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,352 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02453
2025-08-14 14:57:18,352 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,353 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02454
2025-08-14 14:57:18,354 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02455
2025-08-14 14:57:18,367 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,367 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,368 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02456
2025-08-14 14:57:18,369 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,369 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,371 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,371 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,372 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02457
2025-08-14 14:57:18,376 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,376 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,377 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02458
2025-08-14 14:57:18,378 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,378 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,380 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02459
2025-08-14 14:57:18,380 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02460
2025-08-14 14:57:18,388 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,388 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,389 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02461
2025-08-14 14:57:18,395 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,395 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,396 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02462
2025-08-14 14:57:18,401 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,401 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,407 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,407 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,407 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,407 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,410 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02463
2025-08-14 14:57:18,410 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02464
2025-08-14 14:57:18,410 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02465
2025-08-14 14:57:18,413 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,413 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,436 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,436 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,437 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,438 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,440 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,441 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,441 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,441 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,443 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02466
2025-08-14 14:57:18,444 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,444 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02467
2025-08-14 14:57:18,444 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,444 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02468
2025-08-14 14:57:18,445 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02469
2025-08-14 14:57:18,445 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02470
2025-08-14 14:57:18,445 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02471
2025-08-14 14:57:18,446 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,446 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,447 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02472
2025-08-14 14:57:18,460 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,460 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,462 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,463 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,467 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,467 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,468 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,468 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,470 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02473
2025-08-14 14:57:18,470 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02474
2025-08-14 14:57:18,470 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02475
2025-08-14 14:57:18,470 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02476
2025-08-14 14:57:18,491 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,491 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,492 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02477
2025-08-14 14:57:18,497 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,497 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,502 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,502 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,504 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,504 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,504 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,505 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,506 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,507 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02478
2025-08-14 14:57:18,508 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,508 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,508 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,510 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02479
2025-08-14 14:57:18,511 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02480
2025-08-14 14:57:18,511 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02481
2025-08-14 14:57:18,511 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02482
2025-08-14 14:57:18,511 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02483
2025-08-14 14:57:18,517 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,517 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,518 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,518 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,520 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02484
2025-08-14 14:57:18,525 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,525 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,526 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02485
2025-08-14 14:57:18,526 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02486
2025-08-14 14:57:18,546 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,546 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,547 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02487
2025-08-14 14:57:18,548 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,549 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,549 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,549 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,552 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02488
2025-08-14 14:57:18,557 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,557 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,558 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02489
2025-08-14 14:57:18,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02490
2025-08-14 14:57:18,568 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,568 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,571 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,571 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02491
2025-08-14 14:57:18,573 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,573 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,575 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,575 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,579 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,579 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,580 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02492
2025-08-14 14:57:18,581 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02493
2025-08-14 14:57:18,581 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02494
2025-08-14 14:57:18,581 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02495
2025-08-14 14:57:18,583 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,583 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,584 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02496
2025-08-14 14:57:18,595 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,595 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,600 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,600 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,602 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,602 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,603 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02497
2025-08-14 14:57:18,603 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02498
2025-08-14 14:57:18,603 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02499
2025-08-14 14:57:18,613 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,613 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,614 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02500
2025-08-14 14:57:18,617 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,617 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,618 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02501
2025-08-14 14:57:18,629 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,629 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,639 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,639 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,639 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,639 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,641 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,641 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02502
2025-08-14 14:57:18,642 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,643 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02503
2025-08-14 14:57:18,643 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,646 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02504
2025-08-14 14:57:18,646 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,646 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,647 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02505
2025-08-14 14:57:18,647 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02506
2025-08-14 14:57:18,647 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02507
2025-08-14 14:57:18,651 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,651 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,652 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02508
2025-08-14 14:57:18,657 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,657 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,658 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02509
2025-08-14 14:57:18,665 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,665 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,668 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,668 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,669 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02510
2025-08-14 14:57:18,669 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02511
2025-08-14 14:57:18,683 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,683 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,685 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,685 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,686 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02512
2025-08-14 14:57:18,686 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02513
2025-08-14 14:57:18,701 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,701 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,702 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,702 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,706 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,706 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,707 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02514
2025-08-14 14:57:18,707 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02515
2025-08-14 14:57:18,709 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,710 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,711 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02516
2025-08-14 14:57:18,712 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,712 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,714 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,714 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,715 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,715 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,716 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02517
2025-08-14 14:57:18,717 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02518
2025-08-14 14:57:18,717 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02519
2025-08-14 14:57:18,717 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02520
2025-08-14 14:57:18,723 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,723 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,725 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02521
2025-08-14 14:57:18,728 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,728 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,729 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02522
2025-08-14 14:57:18,740 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,740 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,741 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02523
2025-08-14 14:57:18,753 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,753 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,759 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,759 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,760 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02524
2025-08-14 14:57:18,760 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02525
2025-08-14 14:57:18,762 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,762 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,767 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,767 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,772 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,772 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,772 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,773 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02526
2025-08-14 14:57:18,773 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,774 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,775 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,776 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02527
2025-08-14 14:57:18,776 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02528
2025-08-14 14:57:18,776 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02529
2025-08-14 14:57:18,778 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,778 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,784 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,784 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,785 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02530
2025-08-14 14:57:18,785 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02531
2025-08-14 14:57:18,785 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02532
2025-08-14 14:57:18,795 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,795 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,796 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02533
2025-08-14 14:57:18,806 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,806 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,808 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02534
2025-08-14 14:57:18,810 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,810 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,816 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,817 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,817 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,817 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,818 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02535
2025-08-14 14:57:18,819 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02536
2025-08-14 14:57:18,823 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,823 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,824 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02537
2025-08-14 14:57:18,824 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02538
2025-08-14 14:57:18,838 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,838 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,840 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,840 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,841 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02539
2025-08-14 14:57:18,846 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,846 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,847 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02540
2025-08-14 14:57:18,847 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02541
2025-08-14 14:57:18,850 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,850 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,852 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,852 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,853 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02542
2025-08-14 14:57:18,853 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02543
2025-08-14 14:57:18,858 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,858 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,859 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,859 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,859 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02544
2025-08-14 14:57:18,861 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,861 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02545
2025-08-14 14:57:18,861 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,862 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02546
2025-08-14 14:57:18,877 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,877 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,878 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02547
2025-08-14 14:57:18,878 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,878 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,880 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02548
2025-08-14 14:57:18,893 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,893 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,894 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02549
2025-08-14 14:57:18,905 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,905 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,906 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,907 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,907 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,907 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,909 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,910 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,911 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02550
2025-08-14 14:57:18,912 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,912 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,912 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,912 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,915 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02551
2025-08-14 14:57:18,916 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02552
2025-08-14 14:57:18,917 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,918 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,919 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02553
2025-08-14 14:57:18,919 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02554
2025-08-14 14:57:18,919 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02555
2025-08-14 14:57:18,919 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02556
2025-08-14 14:57:18,933 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,933 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,935 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,935 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,936 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02557
2025-08-14 14:57:18,936 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02558
2025-08-14 14:57:18,948 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,948 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,949 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02559
2025-08-14 14:57:18,951 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,951 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,960 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,960 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,961 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02560
2025-08-14 14:57:18,961 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02561
2025-08-14 14:57:18,964 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,964 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,967 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,967 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,968 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02562
2025-08-14 14:57:18,968 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02563
2025-08-14 14:57:18,983 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,983 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,990 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,990 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,993 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,993 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:18,995 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:18,995 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,000 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,000 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,001 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,001 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02564
2025-08-14 14:57:19,003 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02565
2025-08-14 14:57:19,003 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02566
2025-08-14 14:57:19,003 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02567
2025-08-14 14:57:19,003 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02568
2025-08-14 14:57:19,004 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,004 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,005 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02569
2025-08-14 14:57:19,005 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02570
2025-08-14 14:57:19,015 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,015 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,016 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,016 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,016 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,016 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,018 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02571
2025-08-14 14:57:19,020 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02572
2025-08-14 14:57:19,020 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02573
2025-08-14 14:57:19,039 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,039 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,046 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,046 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,051 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,051 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,053 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,054 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,055 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02574
2025-08-14 14:57:19,055 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02575
2025-08-14 14:57:19,055 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02576
2025-08-14 14:57:19,055 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02577
2025-08-14 14:57:19,060 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,060 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,066 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,066 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,067 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,067 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,067 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,067 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,071 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,071 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02578
2025-08-14 14:57:19,072 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,072 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,072 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02579
2025-08-14 14:57:19,072 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02580
2025-08-14 14:57:19,074 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02581
2025-08-14 14:57:19,074 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02582
2025-08-14 14:57:19,075 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02583
2025-08-14 14:57:19,083 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,083 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,084 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02584
2025-08-14 14:57:19,104 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,104 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,105 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02585
2025-08-14 14:57:19,109 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,109 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,110 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02586
2025-08-14 14:57:19,116 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,116 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,117 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,117 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,119 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,119 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,120 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02587
2025-08-14 14:57:19,120 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02588
2025-08-14 14:57:19,120 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02589
2025-08-14 14:57:19,124 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,124 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,127 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,128 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,129 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,129 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,133 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,133 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,134 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02590
2025-08-14 14:57:19,134 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,135 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,136 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02591
2025-08-14 14:57:19,136 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02592
2025-08-14 14:57:19,136 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02593
2025-08-14 14:57:19,136 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02594
2025-08-14 14:57:19,158 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,158 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,160 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02595
2025-08-14 14:57:19,165 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,165 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,167 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,167 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,168 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02596
2025-08-14 14:57:19,168 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02597
2025-08-14 14:57:19,172 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,172 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,174 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,174 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,175 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02598
2025-08-14 14:57:19,175 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,175 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,185 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,186 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,186 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,186 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,188 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02599
2025-08-14 14:57:19,188 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02600
2025-08-14 14:57:19,188 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02601
2025-08-14 14:57:19,188 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02602
2025-08-14 14:57:19,197 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,198 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,199 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02603
2025-08-14 14:57:19,200 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,200 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,201 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02604
2025-08-14 14:57:19,214 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,214 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,216 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,216 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,220 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,221 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,222 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02605
2025-08-14 14:57:19,222 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02606
2025-08-14 14:57:19,225 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,225 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,226 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02607
2025-08-14 14:57:19,226 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02608
2025-08-14 14:57:19,227 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,227 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,231 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,231 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02609
2025-08-14 14:57:19,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02610
2025-08-14 14:57:19,241 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,241 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,242 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02611
2025-08-14 14:57:19,254 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,254 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,255 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02612
2025-08-14 14:57:19,260 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,260 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,262 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,263 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,263 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,263 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,266 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,266 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02613
2025-08-14 14:57:19,266 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,267 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02614
2025-08-14 14:57:19,267 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02615
2025-08-14 14:57:19,267 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02616
2025-08-14 14:57:19,275 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,276 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,277 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02617
2025-08-14 14:57:19,278 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,278 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,283 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,283 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,284 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02618
2025-08-14 14:57:19,284 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02619
2025-08-14 14:57:19,286 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,286 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,287 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02620
2025-08-14 14:57:19,296 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,296 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,297 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02621
2025-08-14 14:57:19,303 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,303 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,318 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,319 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,320 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,320 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,322 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02622
2025-08-14 14:57:19,322 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02623
2025-08-14 14:57:19,322 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02624
2025-08-14 14:57:19,329 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,329 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,331 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,331 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,331 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,332 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,332 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,333 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,336 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02625
2025-08-14 14:57:19,336 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02626
2025-08-14 14:57:19,336 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02627
2025-08-14 14:57:19,336 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02628
2025-08-14 14:57:19,340 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,340 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,341 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02629
2025-08-14 14:57:19,342 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,342 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,343 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02630
2025-08-14 14:57:19,351 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,351 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,355 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,355 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,356 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02631
2025-08-14 14:57:19,357 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02632
2025-08-14 14:57:19,367 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,367 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,368 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02633
2025-08-14 14:57:19,380 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,380 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,387 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,387 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,393 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,393 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,394 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02634
2025-08-14 14:57:19,394 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02635
2025-08-14 14:57:19,394 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02636
2025-08-14 14:57:19,395 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,395 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,398 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,398 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,399 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,400 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,400 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,400 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,400 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,400 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,402 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02637
2025-08-14 14:57:19,404 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02638
2025-08-14 14:57:19,404 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02639
2025-08-14 14:57:19,404 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02640
2025-08-14 14:57:19,404 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02641
2025-08-14 14:57:19,410 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,410 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,411 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02642
2025-08-14 14:57:19,415 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,415 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,416 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02643
2025-08-14 14:57:19,430 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,431 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,432 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02644
2025-08-14 14:57:19,438 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,438 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,441 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,442 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,443 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02645
2025-08-14 14:57:19,453 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,453 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,460 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,460 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,463 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,463 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,465 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,465 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02646
2025-08-14 14:57:19,466 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,466 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,466 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02647
2025-08-14 14:57:19,466 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,467 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02648
2025-08-14 14:57:19,469 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,469 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02649
2025-08-14 14:57:19,469 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,470 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,470 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02650
2025-08-14 14:57:19,470 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,471 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02651
2025-08-14 14:57:19,472 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02652
2025-08-14 14:57:19,472 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02653
2025-08-14 14:57:19,481 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,481 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,482 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02654
2025-08-14 14:57:19,483 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,483 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,484 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02655
2025-08-14 14:57:19,497 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,497 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,498 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02656
2025-08-14 14:57:19,508 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,508 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,509 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02657
2025-08-14 14:57:19,515 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,515 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,517 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,517 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,518 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02658
2025-08-14 14:57:19,526 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,526 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,528 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,528 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,531 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,531 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,532 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,532 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,533 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,534 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,535 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02659
2025-08-14 14:57:19,535 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02660
2025-08-14 14:57:19,536 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02661
2025-08-14 14:57:19,536 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02662
2025-08-14 14:57:19,536 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,537 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,538 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02663
2025-08-14 14:57:19,538 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02664
2025-08-14 14:57:19,538 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02665
2025-08-14 14:57:19,553 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,553 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,554 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02666
2025-08-14 14:57:19,564 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,564 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,565 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02667
2025-08-14 14:57:19,567 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,567 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02668
2025-08-14 14:57:19,575 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,575 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,576 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02669
2025-08-14 14:57:19,577 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,577 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,581 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,581 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,582 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02670
2025-08-14 14:57:19,582 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02671
2025-08-14 14:57:19,585 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,585 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,597 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,597 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,598 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02672
2025-08-14 14:57:19,598 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02673
2025-08-14 14:57:19,599 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,599 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,601 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02674
2025-08-14 14:57:19,603 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,603 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02675
2025-08-14 14:57:19,607 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,607 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,608 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02676
2025-08-14 14:57:19,616 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,616 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,619 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,619 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,620 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02677
2025-08-14 14:57:19,621 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,621 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02678
2025-08-14 14:57:19,621 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,633 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,633 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02679
2025-08-14 14:57:19,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02680
2025-08-14 14:57:19,636 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,637 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,637 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,637 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,639 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02681
2025-08-14 14:57:19,639 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02682
2025-08-14 14:57:19,664 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,664 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,665 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02683
2025-08-14 14:57:19,665 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,666 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,667 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,667 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,669 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,669 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,671 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,671 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,672 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02684
2025-08-14 14:57:19,672 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02685
2025-08-14 14:57:19,672 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02686
2025-08-14 14:57:19,675 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,675 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,676 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,676 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,677 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02687
2025-08-14 14:57:19,678 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02688
2025-08-14 14:57:19,678 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02689
2025-08-14 14:57:19,690 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,690 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,691 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,691 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,693 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02690
2025-08-14 14:57:19,699 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,699 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,700 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02691
2025-08-14 14:57:19,700 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02692
2025-08-14 14:57:19,709 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,709 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,724 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,724 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,726 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,726 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,730 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,730 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,732 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,732 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,733 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,733 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,734 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02693
2025-08-14 14:57:19,735 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02694
2025-08-14 14:57:19,735 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02695
2025-08-14 14:57:19,735 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02696
2025-08-14 14:57:19,736 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,736 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02697
2025-08-14 14:57:19,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02698
2025-08-14 14:57:19,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02699
2025-08-14 14:57:19,742 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,742 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,743 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02700
2025-08-14 14:57:19,750 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,750 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,751 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02701
2025-08-14 14:57:19,754 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,754 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,754 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,754 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,756 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02702
2025-08-14 14:57:19,757 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02703
2025-08-14 14:57:19,774 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,775 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,779 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,779 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,780 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02704
2025-08-14 14:57:19,780 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02705
2025-08-14 14:57:19,785 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,785 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,786 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02706
2025-08-14 14:57:19,793 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,793 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,798 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,798 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,800 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,800 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02707
2025-08-14 14:57:19,800 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,801 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02708
2025-08-14 14:57:19,803 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,803 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,803 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,803 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,806 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02709
2025-08-14 14:57:19,806 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02710
2025-08-14 14:57:19,808 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,808 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,810 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02711
2025-08-14 14:57:19,810 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,811 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02712
2025-08-14 14:57:19,811 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02713
2025-08-14 14:57:19,823 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,823 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,824 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02714
2025-08-14 14:57:19,834 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,834 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,835 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02715
2025-08-14 14:57:19,840 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,840 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,841 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02716
2025-08-14 14:57:19,843 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,843 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,844 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02717
2025-08-14 14:57:19,848 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,848 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,865 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,865 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,866 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,867 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,867 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,867 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,867 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,869 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02718
2025-08-14 14:57:19,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02719
2025-08-14 14:57:19,872 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,872 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02720
2025-08-14 14:57:19,873 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,873 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02721
2025-08-14 14:57:19,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02722
2025-08-14 14:57:19,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02723
2025-08-14 14:57:19,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02724
2025-08-14 14:57:19,892 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,893 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,893 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,893 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,894 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02725
2025-08-14 14:57:19,896 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,896 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,896 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,897 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02726
2025-08-14 14:57:19,898 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02727
2025-08-14 14:57:19,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02728
2025-08-14 14:57:19,919 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,919 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,920 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02729
2025-08-14 14:57:19,923 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,923 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,925 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,925 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,926 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02730
2025-08-14 14:57:19,935 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,935 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,938 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,938 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,939 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,939 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,944 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,944 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,945 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02731
2025-08-14 14:57:19,945 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02732
2025-08-14 14:57:19,945 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02733
2025-08-14 14:57:19,945 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02734
2025-08-14 14:57:19,947 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,947 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,950 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,950 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,950 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02735
2025-08-14 14:57:19,950 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02736
2025-08-14 14:57:19,950 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02737
2025-08-14 14:57:19,953 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,953 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,953 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02738
2025-08-14 14:57:19,971 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,971 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,974 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'code': 'BadRequest', 'message': 'Model o3-mini is enabled only for api versions 2024-12-01-preview and later'}}
2025-08-14 14:57:19,974 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:19,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02739
2025-08-14 14:57:19,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02740
2025-08-14 14:57:19,974 - LLMsInterface - INFO - Model o3-mini-2025-01-31 executed 2740 prompts in 00:00:14
2025-08-14 14:57:19,974 - LLMsInterface - INFO - Total cost: 0.0 USD, Total tokens: 0, Prompt tokens: 0, Completion tokens: 0
2025-08-14 14:57:19,990 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00001 with 'simple' prompt is stored in the database.
2025-08-14 14:57:19,994 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00002 with 'simple' prompt is stored in the database.
2025-08-14 14:57:19,998 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00003 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,002 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00004 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,006 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00005 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,010 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00006 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,014 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00007 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,018 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00008 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,021 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00009 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,025 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00010 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,029 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00011 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,033 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00012 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,037 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00013 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,041 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00014 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,045 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00015 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,049 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00016 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,053 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00017 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,056 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00018 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,060 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00019 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,064 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00020 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,068 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00021 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,072 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00022 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,075 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00023 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,079 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00024 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,083 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00025 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,087 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00026 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,090 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00027 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,094 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00028 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,098 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00029 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,102 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00030 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,106 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00031 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,109 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00032 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,113 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00033 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,117 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00034 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,121 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00035 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,125 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00036 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,129 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00037 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,132 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00038 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,136 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00039 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,140 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00040 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,144 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00041 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,148 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00042 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,151 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00043 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,155 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00044 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,159 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00045 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,163 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00046 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,167 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00047 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,170 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00048 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,174 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00049 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,178 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00050 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,182 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00051 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,186 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00052 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,190 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00053 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,193 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00054 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,197 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00055 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,201 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00056 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,205 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00057 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,208 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00058 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,212 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00059 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,216 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00060 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,220 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00061 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,224 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00062 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,228 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00063 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,231 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00064 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,235 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00065 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,239 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00066 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,243 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00067 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,246 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00068 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,250 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00069 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,254 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00070 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,258 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00071 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,262 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00072 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,265 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00073 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,269 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00074 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,273 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00075 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,277 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00076 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,281 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00077 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,284 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00078 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,288 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00079 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,292 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00080 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,296 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00081 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,299 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00082 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,303 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00083 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,307 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00084 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,311 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00085 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,314 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00086 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,318 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00087 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,322 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00088 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,326 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00089 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,329 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00090 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,333 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00091 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,337 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00092 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,341 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00093 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,344 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00094 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,348 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00095 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,352 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00096 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,356 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00097 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,360 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00098 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,364 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00099 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,367 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00100 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,371 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00101 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,375 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00102 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,379 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00103 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,382 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00104 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,386 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00105 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,390 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00106 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,394 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00107 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,397 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00108 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,401 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00109 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,405 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00110 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,409 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00111 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,413 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00112 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,416 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00113 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,420 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00114 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,424 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00115 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,428 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00116 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,432 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00117 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,436 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00118 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,439 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00119 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,443 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00120 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,447 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00121 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,451 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00122 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,454 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00123 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,458 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00124 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,462 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00125 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,465 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00126 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,469 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00127 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,473 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00128 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,477 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00129 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,480 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00130 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,484 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00131 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,488 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00132 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,492 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00133 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,495 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00134 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,499 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00135 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,503 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00136 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,507 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00137 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,511 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00138 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,515 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00139 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,519 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00140 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,523 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00141 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,526 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00142 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,530 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00143 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,534 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00144 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,538 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00145 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,542 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00146 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,546 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00147 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,550 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00148 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,553 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00149 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,557 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00150 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,561 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00151 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,565 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00152 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,569 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00153 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,572 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00154 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,576 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00155 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,580 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00156 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,584 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00157 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,587 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00158 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,591 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00159 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,595 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00160 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,599 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00161 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,603 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00162 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,607 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00163 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,610 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00164 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,614 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00165 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,618 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00166 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,622 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00167 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,626 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00168 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,629 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00169 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,633 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00170 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,637 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00171 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,640 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00172 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,644 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00173 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,648 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00174 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,651 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00175 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,655 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00176 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,660 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00177 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,663 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00178 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,667 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00179 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,671 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00180 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,675 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00181 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,678 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00182 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,682 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00183 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,686 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00184 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,690 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00185 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,693 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00186 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,697 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00187 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,701 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00188 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,705 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00189 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,709 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00190 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,712 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00191 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,716 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00192 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,720 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00193 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,723 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00194 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,727 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00195 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,731 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00196 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,735 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00197 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,738 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00198 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,742 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00199 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,746 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00200 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,750 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00201 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,753 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00202 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,756 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00203 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,760 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00204 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,763 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00205 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,767 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00206 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,771 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00207 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,775 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00208 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,778 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00209 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,782 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00210 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,786 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00211 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,790 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00212 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,794 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00213 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,797 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00214 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,801 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00215 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,805 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00216 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,809 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00217 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,813 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00218 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,816 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00219 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,820 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00220 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,824 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00221 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,828 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00222 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,831 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00223 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,835 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00224 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,839 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00225 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,843 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00226 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,846 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00227 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,850 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00228 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,854 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00229 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,858 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00230 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,861 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00231 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,865 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00232 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,869 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00233 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,873 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00234 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,876 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00235 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,880 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00236 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,884 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00237 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,888 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00238 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,891 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00239 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,895 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00240 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,899 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00241 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,903 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00242 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,907 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00243 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,911 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00244 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,915 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00245 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,918 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00246 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,922 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00247 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,926 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00248 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,930 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00249 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,934 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00250 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,937 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00251 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,941 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00252 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,945 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00253 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,949 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00254 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,953 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00255 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,957 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00256 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,960 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00257 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,964 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00258 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,968 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00259 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,972 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00260 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,976 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00261 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,980 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00262 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,983 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00263 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,987 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00264 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,991 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00265 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,995 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00266 with 'simple' prompt is stored in the database.
2025-08-14 14:57:20,999 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00267 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,002 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00268 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,006 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00269 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,010 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00270 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,014 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00271 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,017 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00272 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,021 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00273 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,025 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00274 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,029 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00275 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,033 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00276 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,037 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00277 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,040 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00278 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,044 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00279 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,048 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00280 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,052 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00281 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,056 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00282 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,059 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00283 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,063 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00284 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,067 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00285 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,071 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00286 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,075 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00287 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,078 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00288 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,082 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00289 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,086 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00290 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,090 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00291 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,093 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00292 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,097 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00293 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,101 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00294 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,105 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00295 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,109 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00296 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,113 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00297 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,116 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00298 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,120 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00299 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,124 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00300 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,127 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00301 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,131 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00302 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,135 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00303 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,139 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00304 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,142 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00305 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,145 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00306 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,149 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00307 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,152 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00308 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,156 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00309 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,160 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00310 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,163 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00311 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,167 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00312 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,171 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00313 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,175 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00314 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,178 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00315 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,182 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00316 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,186 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00317 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,190 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00318 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,193 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00319 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,197 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00320 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,201 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00321 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,205 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00322 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,208 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00323 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,212 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00324 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,216 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00325 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,220 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00326 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,223 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00327 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,227 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00328 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,231 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00329 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,234 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00330 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,238 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00331 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,242 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00332 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,245 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00333 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,248 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00334 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,251 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00335 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,255 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00336 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,259 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00337 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,263 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00338 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,266 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00339 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,270 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00340 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,274 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00341 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,277 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00342 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,281 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00343 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,285 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00344 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,289 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00345 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,293 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00346 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,296 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00347 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,300 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00348 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,304 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00349 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,307 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00350 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,311 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00351 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,314 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00352 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,318 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00353 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,322 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00354 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,326 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00355 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,329 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00356 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,333 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00357 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,337 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00358 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,340 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00359 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,344 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00360 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,348 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00361 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,352 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00362 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,355 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00363 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,359 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00364 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,368 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00365 with 'simple' prompt is stored in the database.
2025-08-14 14:57:21,372 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00366 with 'simple' prompt is stored in the database.
2025-08-14 14:57:48,366 - VuLLMBench - INFO - Experiment exp11 started...
2025-08-14 14:57:48,382 - Controller - INFO - Loaded 2740 examples from the owasp dataset.
2025-08-14 14:57:49,077 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,077 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,080 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,080 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,108 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,109 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,110 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,111 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,118 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,118 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,135 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,135 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,143 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,143 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,144 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,144 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,146 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,146 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,150 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,150 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,151 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00001
2025-08-14 14:57:49,151 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00002
2025-08-14 14:57:49,151 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00003
2025-08-14 14:57:49,154 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,154 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,155 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00004
2025-08-14 14:57:49,187 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,187 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,196 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,196 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,200 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,200 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,201 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00005
2025-08-14 14:57:49,201 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00006
2025-08-14 14:57:49,202 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00007
2025-08-14 14:57:49,202 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00008
2025-08-14 14:57:49,202 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00009
2025-08-14 14:57:49,202 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00010
2025-08-14 14:57:49,202 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00011
2025-08-14 14:57:49,202 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00012
2025-08-14 14:57:49,202 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00013
2025-08-14 14:57:49,202 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00014
2025-08-14 14:57:49,204 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,204 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,212 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,213 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,213 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,213 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,227 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,227 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,229 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,229 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,231 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,231 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00015
2025-08-14 14:57:49,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00016
2025-08-14 14:57:49,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00017
2025-08-14 14:57:49,233 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00018
2025-08-14 14:57:49,233 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00019
2025-08-14 14:57:49,233 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00020
2025-08-14 14:57:49,242 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,242 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,243 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00021
2025-08-14 14:57:49,265 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,265 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,266 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00022
2025-08-14 14:57:49,270 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,270 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,271 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00023
2025-08-14 14:57:49,272 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,272 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,278 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,278 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,279 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,279 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,282 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,282 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,284 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00024
2025-08-14 14:57:49,284 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00025
2025-08-14 14:57:49,284 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00026
2025-08-14 14:57:49,284 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00027
2025-08-14 14:57:49,302 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,302 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,303 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00028
2025-08-14 14:57:49,307 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,307 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,328 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,328 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,329 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00029
2025-08-14 14:57:49,329 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00030
2025-08-14 14:57:49,337 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,337 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,340 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,340 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,343 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,343 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,344 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,344 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,345 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,346 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,347 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,347 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,350 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00031
2025-08-14 14:57:49,350 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00032
2025-08-14 14:57:49,350 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00033
2025-08-14 14:57:49,350 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00034
2025-08-14 14:57:49,350 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00035
2025-08-14 14:57:49,350 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00036
2025-08-14 14:57:49,365 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,365 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,366 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00037
2025-08-14 14:57:49,376 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,376 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,377 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00038
2025-08-14 14:57:49,383 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,383 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,384 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00039
2025-08-14 14:57:49,405 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,405 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,414 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,415 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,416 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,416 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,416 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,416 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,418 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,419 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00040
2025-08-14 14:57:49,420 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,421 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00041
2025-08-14 14:57:49,422 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00042
2025-08-14 14:57:49,422 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00043
2025-08-14 14:57:49,422 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00044
2025-08-14 14:57:49,423 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,423 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,458 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,458 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,464 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,464 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,469 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,470 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,470 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,470 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,482 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,482 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,488 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,488 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,489 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00045
2025-08-14 14:57:49,489 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00046
2025-08-14 14:57:49,489 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00047
2025-08-14 14:57:49,489 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00048
2025-08-14 14:57:49,489 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00049
2025-08-14 14:57:49,489 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00050
2025-08-14 14:57:49,489 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00051
2025-08-14 14:57:49,500 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,500 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,502 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,502 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,505 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,505 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,507 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,508 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,509 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00052
2025-08-14 14:57:49,509 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00053
2025-08-14 14:57:49,509 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00054
2025-08-14 14:57:49,509 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00055
2025-08-14 14:57:49,531 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,531 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,532 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00056
2025-08-14 14:57:49,539 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,539 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,544 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,544 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,546 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,546 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,549 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,549 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,550 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00057
2025-08-14 14:57:49,550 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00058
2025-08-14 14:57:49,550 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00059
2025-08-14 14:57:49,550 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00060
2025-08-14 14:57:49,573 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,573 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,580 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,580 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,582 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,582 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,584 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,584 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,585 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00061
2025-08-14 14:57:49,585 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00062
2025-08-14 14:57:49,585 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00063
2025-08-14 14:57:49,585 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00064
2025-08-14 14:57:49,600 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,600 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,601 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00065
2025-08-14 14:57:49,602 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,602 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,612 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,612 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,622 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,622 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,622 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,622 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,624 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00066
2025-08-14 14:57:49,625 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00067
2025-08-14 14:57:49,625 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00068
2025-08-14 14:57:49,625 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00069
2025-08-14 14:57:49,632 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,632 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,633 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00070
2025-08-14 14:57:49,642 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,642 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00071
2025-08-14 14:57:49,651 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,651 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,652 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00072
2025-08-14 14:57:49,655 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,655 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,656 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00073
2025-08-14 14:57:49,665 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,666 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,678 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,679 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,680 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00074
2025-08-14 14:57:49,687 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,687 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,687 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,689 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00075
2025-08-14 14:57:49,687 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,689 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00076
2025-08-14 14:57:49,690 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00077
2025-08-14 14:57:49,703 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,703 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,704 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,704 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,705 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00078
2025-08-14 14:57:49,706 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00079
2025-08-14 14:57:49,718 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,718 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,719 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00080
2025-08-14 14:57:49,725 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,726 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,727 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00081
2025-08-14 14:57:49,727 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,728 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,728 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,728 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,729 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00082
2025-08-14 14:57:49,734 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,734 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,735 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00083
2025-08-14 14:57:49,735 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00084
2025-08-14 14:57:49,758 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,759 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,768 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,768 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,769 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00085
2025-08-14 14:57:49,769 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00086
2025-08-14 14:57:49,776 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,776 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,777 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00087
2025-08-14 14:57:49,780 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,780 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,783 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,783 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,784 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00088
2025-08-14 14:57:49,784 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00089
2025-08-14 14:57:49,791 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,791 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,800 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,800 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,800 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,800 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,803 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00090
2025-08-14 14:57:49,805 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,805 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,807 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00091
2025-08-14 14:57:49,807 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00092
2025-08-14 14:57:49,807 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00093
2025-08-14 14:57:49,810 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,810 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,811 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00094
2025-08-14 14:57:49,826 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,826 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,827 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00095
2025-08-14 14:57:49,856 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,856 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,857 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,858 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,858 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,858 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,862 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,862 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,864 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,864 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00096
2025-08-14 14:57:49,864 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00097
2025-08-14 14:57:49,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00098
2025-08-14 14:57:49,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00099
2025-08-14 14:57:49,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00100
2025-08-14 14:57:49,874 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,874 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00101
2025-08-14 14:57:49,876 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,876 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,882 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,882 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00102
2025-08-14 14:57:49,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00103
2025-08-14 14:57:49,887 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,887 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,888 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00104
2025-08-14 14:57:49,894 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,894 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,895 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00105
2025-08-14 14:57:49,922 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,922 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,933 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,933 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,935 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,935 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,935 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00106
2025-08-14 14:57:49,936 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00107
2025-08-14 14:57:49,936 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00108
2025-08-14 14:57:49,947 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,947 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,951 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,951 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,952 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00109
2025-08-14 14:57:49,953 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,953 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,957 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,957 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,958 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00110
2025-08-14 14:57:49,958 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00111
2025-08-14 14:57:49,958 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00112
2025-08-14 14:57:49,964 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,964 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,966 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,966 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,967 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,968 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,969 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00113
2025-08-14 14:57:49,969 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00114
2025-08-14 14:57:49,969 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00115
2025-08-14 14:57:49,984 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:49,984 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:49,985 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00116
2025-08-14 14:57:50,005 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,005 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,006 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00117
2025-08-14 14:57:50,014 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,014 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,015 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00118
2025-08-14 14:57:50,028 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,028 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,029 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00119
2025-08-14 14:57:50,029 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,029 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,031 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,031 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,041 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,041 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,043 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,043 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,044 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00120
2025-08-14 14:57:50,044 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00121
2025-08-14 14:57:50,044 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00122
2025-08-14 14:57:50,044 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00123
2025-08-14 14:57:50,045 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,045 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,046 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00124
2025-08-14 14:57:50,048 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,048 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,050 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,050 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,051 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00125
2025-08-14 14:57:50,051 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00126
2025-08-14 14:57:50,075 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,075 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00127
2025-08-14 14:57:50,092 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,092 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,093 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00128
2025-08-14 14:57:50,101 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,101 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,102 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00129
2025-08-14 14:57:50,105 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,105 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,117 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,117 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,121 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,121 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,128 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,128 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,132 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,132 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,144 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,144 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,148 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,148 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,165 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,165 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,169 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,169 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,169 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,170 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,171 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00130
2025-08-14 14:57:50,172 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00131
2025-08-14 14:57:50,172 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00132
2025-08-14 14:57:50,172 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00133
2025-08-14 14:57:50,172 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00134
2025-08-14 14:57:50,172 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00135
2025-08-14 14:57:50,172 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00136
2025-08-14 14:57:50,172 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00137
2025-08-14 14:57:50,172 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00138
2025-08-14 14:57:50,183 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,183 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,183 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,183 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,185 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00139
2025-08-14 14:57:50,186 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00140
2025-08-14 14:57:50,186 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00141
2025-08-14 14:57:50,202 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,202 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,203 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00142
2025-08-14 14:57:50,212 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,212 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,223 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,223 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,229 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,229 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,230 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00143
2025-08-14 14:57:50,230 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00144
2025-08-14 14:57:50,235 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,235 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,236 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00145
2025-08-14 14:57:50,237 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00146
2025-08-14 14:57:50,240 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,240 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,250 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,250 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,259 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,259 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,271 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,271 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,279 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,279 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,292 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,292 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,296 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,296 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,310 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,310 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,327 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,327 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,329 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,329 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,334 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,334 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,335 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00147
2025-08-14 14:57:50,335 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00148
2025-08-14 14:57:50,336 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00149
2025-08-14 14:57:50,336 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00150
2025-08-14 14:57:50,336 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00151
2025-08-14 14:57:50,336 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00152
2025-08-14 14:57:50,336 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00153
2025-08-14 14:57:50,336 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00154
2025-08-14 14:57:50,341 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,341 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,342 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00155
2025-08-14 14:57:50,346 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,346 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,348 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,348 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,349 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00156
2025-08-14 14:57:50,349 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00157
2025-08-14 14:57:50,349 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00158
2025-08-14 14:57:50,349 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00159
2025-08-14 14:57:50,349 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00160
2025-08-14 14:57:50,354 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,354 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,355 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00161
2025-08-14 14:57:50,372 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,372 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,373 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00162
2025-08-14 14:57:50,376 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,377 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,383 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,383 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,384 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00163
2025-08-14 14:57:50,384 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00164
2025-08-14 14:57:50,397 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,397 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,402 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,402 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,403 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00165
2025-08-14 14:57:50,403 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00166
2025-08-14 14:57:50,406 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,406 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,407 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00167
2025-08-14 14:57:50,416 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,416 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,431 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,431 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,432 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00168
2025-08-14 14:57:50,432 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00169
2025-08-14 14:57:50,437 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,437 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,439 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,439 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,441 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00170
2025-08-14 14:57:50,441 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00171
2025-08-14 14:57:50,442 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,442 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,449 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,449 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,451 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00172
2025-08-14 14:57:50,451 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00173
2025-08-14 14:57:50,463 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,464 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,464 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,464 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,465 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00174
2025-08-14 14:57:50,466 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00175
2025-08-14 14:57:50,480 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,480 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,482 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,483 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,484 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00176
2025-08-14 14:57:50,484 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00177
2025-08-14 14:57:50,491 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,491 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,492 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00178
2025-08-14 14:57:50,510 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,510 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,513 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,513 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,523 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,523 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,524 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00179
2025-08-14 14:57:50,525 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00180
2025-08-14 14:57:50,527 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,527 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,532 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,532 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,536 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,536 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00181
2025-08-14 14:57:50,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00182
2025-08-14 14:57:50,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00183
2025-08-14 14:57:50,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00184
2025-08-14 14:57:50,546 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,546 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,547 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00185
2025-08-14 14:57:50,563 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,563 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,565 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,565 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,565 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,566 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00186
2025-08-14 14:57:50,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00187
2025-08-14 14:57:50,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00188
2025-08-14 14:57:50,579 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,579 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,580 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00189
2025-08-14 14:57:50,587 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,587 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,588 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00190
2025-08-14 14:57:50,603 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,603 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,605 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,605 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,609 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,609 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,610 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00191
2025-08-14 14:57:50,611 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00192
2025-08-14 14:57:50,611 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00193
2025-08-14 14:57:50,626 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,626 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,630 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,630 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,631 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00194
2025-08-14 14:57:50,631 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00195
2025-08-14 14:57:50,636 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,636 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,640 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,640 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,641 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00196
2025-08-14 14:57:50,643 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,643 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,645 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00197
2025-08-14 14:57:50,645 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,645 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00198
2025-08-14 14:57:50,645 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,647 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00199
2025-08-14 14:57:50,667 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,667 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00200
2025-08-14 14:57:50,678 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,678 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,679 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00201
2025-08-14 14:57:50,685 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,685 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,686 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00202
2025-08-14 14:57:50,705 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,705 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,709 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,709 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,712 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,712 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,714 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,714 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00203
2025-08-14 14:57:50,714 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,714 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00204
2025-08-14 14:57:50,716 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,717 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,721 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,721 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,724 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,724 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,725 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00205
2025-08-14 14:57:50,725 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00206
2025-08-14 14:57:50,725 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00207
2025-08-14 14:57:50,725 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00208
2025-08-14 14:57:50,725 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00209
2025-08-14 14:57:50,749 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,749 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,750 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00210
2025-08-14 14:57:50,751 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,751 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,752 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00211
2025-08-14 14:57:50,761 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,762 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,763 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00212
2025-08-14 14:57:50,774 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,774 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,775 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00213
2025-08-14 14:57:50,779 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,779 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,789 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,790 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,790 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,790 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,791 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00214
2025-08-14 14:57:50,798 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,798 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,804 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,805 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,806 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00215
2025-08-14 14:57:50,806 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00216
2025-08-14 14:57:50,806 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00217
2025-08-14 14:57:50,806 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00218
2025-08-14 14:57:50,817 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,817 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,818 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00219
2025-08-14 14:57:50,823 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,823 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,824 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00220
2025-08-14 14:57:50,825 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,825 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,826 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00221
2025-08-14 14:57:50,835 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,835 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,836 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00222
2025-08-14 14:57:50,847 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,847 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,849 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,849 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,850 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00223
2025-08-14 14:57:50,850 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00224
2025-08-14 14:57:50,871 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,872 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,872 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,872 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00225
2025-08-14 14:57:50,875 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,875 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00226
2025-08-14 14:57:50,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00227
2025-08-14 14:57:50,900 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,900 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,902 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,902 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,904 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,904 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,910 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,910 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,912 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,912 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,922 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,922 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,939 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,939 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,940 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00228
2025-08-14 14:57:50,940 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00229
2025-08-14 14:57:50,940 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00230
2025-08-14 14:57:50,940 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00231
2025-08-14 14:57:50,940 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00232
2025-08-14 14:57:50,940 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00233
2025-08-14 14:57:50,940 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00234
2025-08-14 14:57:50,950 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,950 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,951 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00235
2025-08-14 14:57:50,959 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,959 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,965 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,965 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,967 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,967 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,968 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00236
2025-08-14 14:57:50,968 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00237
2025-08-14 14:57:50,968 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00238
2025-08-14 14:57:50,976 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,976 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,980 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,980 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,981 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00239
2025-08-14 14:57:50,989 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,989 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:50,990 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00240
2025-08-14 14:57:50,990 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00241
2025-08-14 14:57:50,996 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:50,996 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,001 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,001 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00242
2025-08-14 14:57:51,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00243
2025-08-14 14:57:51,025 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,025 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,026 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00244
2025-08-14 14:57:51,030 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,030 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,031 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,031 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,033 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00245
2025-08-14 14:57:51,039 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,039 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,041 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,041 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,042 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00246
2025-08-14 14:57:51,042 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00247
2025-08-14 14:57:51,042 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00248
2025-08-14 14:57:51,043 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,043 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,044 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00249
2025-08-14 14:57:51,056 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,056 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,057 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00250
2025-08-14 14:57:51,063 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,063 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,065 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00251
2025-08-14 14:57:51,070 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,070 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,071 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00252
2025-08-14 14:57:51,094 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,094 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,110 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,110 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,111 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,112 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,112 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,112 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,122 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,122 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,124 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,124 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,125 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,125 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00253
2025-08-14 14:57:51,126 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,126 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00254
2025-08-14 14:57:51,127 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00255
2025-08-14 14:57:51,127 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00256
2025-08-14 14:57:51,127 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00257
2025-08-14 14:57:51,127 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00258
2025-08-14 14:57:51,127 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00259
2025-08-14 14:57:51,130 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,130 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,131 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00260
2025-08-14 14:57:51,136 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,136 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,137 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00261
2025-08-14 14:57:51,143 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,143 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,144 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00262
2025-08-14 14:57:51,155 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,155 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,156 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00263
2025-08-14 14:57:51,179 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,179 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,187 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,187 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,195 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,195 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,196 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00264
2025-08-14 14:57:51,196 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00265
2025-08-14 14:57:51,197 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00266
2025-08-14 14:57:51,203 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,203 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,204 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00267
2025-08-14 14:57:51,204 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,204 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,213 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,213 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,216 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,216 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,218 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,218 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,219 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00268
2025-08-14 14:57:51,222 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,222 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,226 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,227 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,228 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00269
2025-08-14 14:57:51,228 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00270
2025-08-14 14:57:51,228 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00271
2025-08-14 14:57:51,228 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00272
2025-08-14 14:57:51,228 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00273
2025-08-14 14:57:51,254 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,254 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,255 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00274
2025-08-14 14:57:51,260 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,260 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,261 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00275
2025-08-14 14:57:51,278 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,278 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,279 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,279 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,279 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,281 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00276
2025-08-14 14:57:51,282 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,283 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00277
2025-08-14 14:57:51,283 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,283 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00278
2025-08-14 14:57:51,284 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,289 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,290 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,291 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,291 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,292 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00279
2025-08-14 14:57:51,292 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00280
2025-08-14 14:57:51,308 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,308 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,309 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00281
2025-08-14 14:57:51,309 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00282
2025-08-14 14:57:51,312 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,313 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,314 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00283
2025-08-14 14:57:51,318 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,318 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,319 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00284
2025-08-14 14:57:51,333 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,333 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,334 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00285
2025-08-14 14:57:51,347 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,347 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,351 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,351 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,352 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00286
2025-08-14 14:57:51,355 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,355 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,361 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,362 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,362 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,362 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,363 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00287
2025-08-14 14:57:51,365 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00288
2025-08-14 14:57:51,365 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00289
2025-08-14 14:57:51,365 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00290
2025-08-14 14:57:51,370 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,370 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,371 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00291
2025-08-14 14:57:51,383 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,383 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,394 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,394 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,399 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,399 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,400 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00292
2025-08-14 14:57:51,400 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00293
2025-08-14 14:57:51,400 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00294
2025-08-14 14:57:51,405 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,405 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,406 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00295
2025-08-14 14:57:51,410 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,410 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,411 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00296
2025-08-14 14:57:51,424 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,424 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,425 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00297
2025-08-14 14:57:51,428 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,428 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00298
2025-08-14 14:57:51,434 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,434 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,448 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,448 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,460 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,461 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,462 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00299
2025-08-14 14:57:51,462 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00300
2025-08-14 14:57:51,462 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,463 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,464 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00301
2025-08-14 14:57:51,464 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00302
2025-08-14 14:57:51,472 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,472 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,476 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,476 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,480 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,480 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,481 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00303
2025-08-14 14:57:51,490 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,490 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,491 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00304
2025-08-14 14:57:51,491 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00305
2025-08-14 14:57:51,491 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00306
2025-08-14 14:57:51,504 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,504 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,505 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,506 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,506 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,506 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,507 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00307
2025-08-14 14:57:51,509 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00308
2025-08-14 14:57:51,509 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00309
2025-08-14 14:57:51,516 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,516 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,517 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00310
2025-08-14 14:57:51,534 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,535 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,543 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,543 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,561 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,561 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,564 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,564 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,579 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,579 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,581 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,582 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,582 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,582 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,583 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,583 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,590 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,590 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,597 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,597 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,598 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00311
2025-08-14 14:57:51,599 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,599 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00312
2025-08-14 14:57:51,599 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,599 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00313
2025-08-14 14:57:51,600 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00314
2025-08-14 14:57:51,600 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00315
2025-08-14 14:57:51,600 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00316
2025-08-14 14:57:51,600 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00317
2025-08-14 14:57:51,600 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00318
2025-08-14 14:57:51,600 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00319
2025-08-14 14:57:51,600 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00320
2025-08-14 14:57:51,600 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00321
2025-08-14 14:57:51,624 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,624 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,625 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00322
2025-08-14 14:57:51,642 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,642 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,648 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,648 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,649 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00323
2025-08-14 14:57:51,649 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00324
2025-08-14 14:57:51,653 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,653 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,654 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00325
2025-08-14 14:57:51,654 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,654 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,657 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,657 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,658 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,659 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,660 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00326
2025-08-14 14:57:51,660 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00327
2025-08-14 14:57:51,669 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,669 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,687 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,687 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,688 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00328
2025-08-14 14:57:51,688 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00329
2025-08-14 14:57:51,691 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,691 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,692 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00330
2025-08-14 14:57:51,692 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00331
2025-08-14 14:57:51,708 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,708 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,709 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00332
2025-08-14 14:57:51,715 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,715 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,716 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00333
2025-08-14 14:57:51,718 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,718 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,727 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,727 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,730 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,730 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,732 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,732 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,733 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,733 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,735 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,735 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,736 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00334
2025-08-14 14:57:51,736 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00335
2025-08-14 14:57:51,736 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00336
2025-08-14 14:57:51,736 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00337
2025-08-14 14:57:51,736 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00338
2025-08-14 14:57:51,736 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00339
2025-08-14 14:57:51,776 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,776 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,778 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00340
2025-08-14 14:57:51,781 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,781 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,784 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,784 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,786 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00341
2025-08-14 14:57:51,788 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,788 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,798 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,799 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,799 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,799 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,801 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00342
2025-08-14 14:57:51,801 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00343
2025-08-14 14:57:51,801 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00344
2025-08-14 14:57:51,801 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00345
2025-08-14 14:57:51,807 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,807 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,808 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00346
2025-08-14 14:57:51,811 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,811 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,816 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,816 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,817 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00347
2025-08-14 14:57:51,817 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00348
2025-08-14 14:57:51,825 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,825 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,826 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00349
2025-08-14 14:57:51,848 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,848 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,866 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,867 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,869 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,869 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,870 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,870 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,870 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,870 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,871 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,872 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00350
2025-08-14 14:57:51,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00351
2025-08-14 14:57:51,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00352
2025-08-14 14:57:51,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00353
2025-08-14 14:57:51,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00354
2025-08-14 14:57:51,877 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,877 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,878 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00355
2025-08-14 14:57:51,878 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00356
2025-08-14 14:57:51,882 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,882 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00357
2025-08-14 14:57:51,892 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,892 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,893 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00358
2025-08-14 14:57:51,917 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,917 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,918 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00359
2025-08-14 14:57:51,920 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,920 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00360
2025-08-14 14:57:51,934 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,934 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,943 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,943 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,945 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,945 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,952 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,952 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,954 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,954 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,962 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,962 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,963 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00361
2025-08-14 14:57:51,963 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00362
2025-08-14 14:57:51,963 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00363
2025-08-14 14:57:51,967 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,967 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,970 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,970 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,971 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00364
2025-08-14 14:57:51,971 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00365
2025-08-14 14:57:51,972 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00366
2025-08-14 14:57:51,972 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00367
2025-08-14 14:57:51,972 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00368
2025-08-14 14:57:51,986 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,986 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:51,995 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:51,996 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,001 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,001 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00369
2025-08-14 14:57:52,003 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00370
2025-08-14 14:57:52,003 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00371
2025-08-14 14:57:52,016 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,016 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,017 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00372
2025-08-14 14:57:52,019 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,020 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,021 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00373
2025-08-14 14:57:52,025 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,025 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,037 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,037 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,038 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00374
2025-08-14 14:57:52,038 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00375
2025-08-14 14:57:52,042 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,043 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,049 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,049 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,050 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00376
2025-08-14 14:57:52,050 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00377
2025-08-14 14:57:52,054 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,054 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,058 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,058 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,063 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,063 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,064 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00378
2025-08-14 14:57:52,064 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00379
2025-08-14 14:57:52,064 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00380
2025-08-14 14:57:52,084 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,084 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,085 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00381
2025-08-14 14:57:52,094 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,094 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,096 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,097 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00382
2025-08-14 14:57:52,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00383
2025-08-14 14:57:52,102 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,102 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,103 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00384
2025-08-14 14:57:52,114 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,114 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,115 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00385
2025-08-14 14:57:52,117 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,117 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,119 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,119 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00386
2025-08-14 14:57:52,119 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,125 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,125 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,136 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,136 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00387
2025-08-14 14:57:52,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00388
2025-08-14 14:57:52,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00389
2025-08-14 14:57:52,153 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,154 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,155 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00390
2025-08-14 14:57:52,169 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,169 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,170 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,171 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,180 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,180 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,188 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,188 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,189 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,189 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,201 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,202 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,216 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,216 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,217 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00391
2025-08-14 14:57:52,217 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00392
2025-08-14 14:57:52,217 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00393
2025-08-14 14:57:52,217 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00394
2025-08-14 14:57:52,217 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00395
2025-08-14 14:57:52,218 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00396
2025-08-14 14:57:52,218 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00397
2025-08-14 14:57:52,223 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,224 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,247 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,247 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,252 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,252 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,253 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00398
2025-08-14 14:57:52,254 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00399
2025-08-14 14:57:52,255 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,255 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,256 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,257 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,257 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,257 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,258 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00400
2025-08-14 14:57:52,259 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00401
2025-08-14 14:57:52,259 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00402
2025-08-14 14:57:52,259 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00403
2025-08-14 14:57:52,260 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,260 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,265 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,265 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,266 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00404
2025-08-14 14:57:52,266 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00405
2025-08-14 14:57:52,282 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,282 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,283 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00406
2025-08-14 14:57:52,309 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,310 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,310 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,310 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,311 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00407
2025-08-14 14:57:52,312 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00408
2025-08-14 14:57:52,315 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,315 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,316 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,316 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,317 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00409
2025-08-14 14:57:52,317 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00410
2025-08-14 14:57:52,324 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,324 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,331 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,331 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,335 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,336 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,337 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00411
2025-08-14 14:57:52,337 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00412
2025-08-14 14:57:52,349 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,349 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,350 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00413
2025-08-14 14:57:52,350 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00414
2025-08-14 14:57:52,362 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,362 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,363 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00415
2025-08-14 14:57:52,366 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,366 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,367 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00416
2025-08-14 14:57:52,378 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,378 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,389 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,389 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,393 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,393 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,396 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,396 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,398 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,398 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,399 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00417
2025-08-14 14:57:52,399 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00418
2025-08-14 14:57:52,399 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00419
2025-08-14 14:57:52,399 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00420
2025-08-14 14:57:52,399 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00421
2025-08-14 14:57:52,407 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,408 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,409 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,409 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00422
2025-08-14 14:57:52,409 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,411 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00423
2025-08-14 14:57:52,439 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,439 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,440 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,440 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00424
2025-08-14 14:57:52,440 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,447 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,447 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,448 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00425
2025-08-14 14:57:52,449 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,449 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,450 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00426
2025-08-14 14:57:52,450 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00427
2025-08-14 14:57:52,456 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,456 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,462 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,462 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,464 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00428
2025-08-14 14:57:52,464 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00429
2025-08-14 14:57:52,482 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,482 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,484 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,484 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,484 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,485 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,487 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00430
2025-08-14 14:57:52,487 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00431
2025-08-14 14:57:52,490 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,490 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,491 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00432
2025-08-14 14:57:52,491 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00433
2025-08-14 14:57:52,507 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,508 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,522 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,522 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,524 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,524 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,526 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,526 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,528 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,528 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,529 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00434
2025-08-14 14:57:52,529 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00435
2025-08-14 14:57:52,529 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00436
2025-08-14 14:57:52,529 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00437
2025-08-14 14:57:52,529 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00438
2025-08-14 14:57:52,532 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,532 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,533 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00439
2025-08-14 14:57:52,559 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,559 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,565 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,566 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,567 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,567 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,569 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,569 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,569 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,569 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,571 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00440
2025-08-14 14:57:52,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00441
2025-08-14 14:57:52,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00442
2025-08-14 14:57:52,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00443
2025-08-14 14:57:52,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00444
2025-08-14 14:57:52,590 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,590 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,600 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,600 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,604 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,605 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,607 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,607 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,608 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00445
2025-08-14 14:57:52,608 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00446
2025-08-14 14:57:52,608 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00447
2025-08-14 14:57:52,618 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,618 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,619 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00448
2025-08-14 14:57:52,619 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00449
2025-08-14 14:57:52,630 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,630 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,632 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00450
2025-08-14 14:57:52,635 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,635 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,641 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,641 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,642 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00451
2025-08-14 14:57:52,653 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,653 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,655 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,655 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,657 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,657 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,657 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00452
2025-08-14 14:57:52,658 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00453
2025-08-14 14:57:52,658 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00454
2025-08-14 14:57:52,658 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00455
2025-08-14 14:57:52,683 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,683 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,685 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,685 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,689 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,689 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,691 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00456
2025-08-14 14:57:52,691 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00457
2025-08-14 14:57:52,691 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00458
2025-08-14 14:57:52,706 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,706 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,708 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,708 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,712 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,712 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,713 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00459
2025-08-14 14:57:52,713 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00460
2025-08-14 14:57:52,713 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00461
2025-08-14 14:57:52,722 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,722 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,723 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00462
2025-08-14 14:57:52,723 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,723 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,738 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,738 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,739 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00463
2025-08-14 14:57:52,740 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,740 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,741 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00464
2025-08-14 14:57:52,741 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00465
2025-08-14 14:57:52,755 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,755 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,756 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00466
2025-08-14 14:57:52,766 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,766 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,767 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,767 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,769 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00467
2025-08-14 14:57:52,769 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,769 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00468
2025-08-14 14:57:52,769 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,771 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00469
2025-08-14 14:57:52,779 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,779 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,780 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00470
2025-08-14 14:57:52,787 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,787 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,795 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,795 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,817 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,817 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,818 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00471
2025-08-14 14:57:52,818 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00472
2025-08-14 14:57:52,818 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00473
2025-08-14 14:57:52,823 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,823 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,824 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00474
2025-08-14 14:57:52,828 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,828 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,832 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,832 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,834 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,834 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,835 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00475
2025-08-14 14:57:52,835 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00476
2025-08-14 14:57:52,840 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,840 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,841 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00477
2025-08-14 14:57:52,852 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,852 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,855 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,855 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,870 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,870 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00478
2025-08-14 14:57:52,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00479
2025-08-14 14:57:52,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00480
2025-08-14 14:57:52,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00481
2025-08-14 14:57:52,881 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,881 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,882 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00482
2025-08-14 14:57:52,904 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,904 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,904 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,905 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,906 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,907 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,909 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00483
2025-08-14 14:57:52,913 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,913 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,918 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,918 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,919 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,919 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00484
2025-08-14 14:57:52,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00485
2025-08-14 14:57:52,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00486
2025-08-14 14:57:52,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00487
2025-08-14 14:57:52,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00488
2025-08-14 14:57:52,922 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,922 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,926 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,927 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,928 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00489
2025-08-14 14:57:52,928 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00490
2025-08-14 14:57:52,947 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,947 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,948 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00491
2025-08-14 14:57:52,964 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,964 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,965 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00492
2025-08-14 14:57:52,967 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,967 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,968 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00493
2025-08-14 14:57:52,989 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,989 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,990 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,991 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:52,992 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:52,992 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,000 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,000 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,001 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00494
2025-08-14 14:57:53,002 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00495
2025-08-14 14:57:53,003 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00496
2025-08-14 14:57:53,011 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,011 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,012 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,012 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00497
2025-08-14 14:57:53,012 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,014 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00498
2025-08-14 14:57:53,014 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00499
2025-08-14 14:57:53,014 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00500
2025-08-14 14:57:53,025 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,025 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,026 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00501
2025-08-14 14:57:53,031 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,031 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,042 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,043 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,044 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00502
2025-08-14 14:57:53,044 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00503
2025-08-14 14:57:53,057 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,057 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,060 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,060 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,061 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00504
2025-08-14 14:57:53,071 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,071 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,072 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00505
2025-08-14 14:57:53,072 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00506
2025-08-14 14:57:53,073 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,073 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,074 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00507
2025-08-14 14:57:53,095 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,095 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,096 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00508
2025-08-14 14:57:53,103 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,103 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,108 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,108 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,109 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,110 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,111 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00509
2025-08-14 14:57:53,111 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00510
2025-08-14 14:57:53,111 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00511
2025-08-14 14:57:53,114 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,114 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,115 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00512
2025-08-14 14:57:53,123 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,123 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,124 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00513
2025-08-14 14:57:53,130 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,130 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,131 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00514
2025-08-14 14:57:53,133 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,133 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,134 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00515
2025-08-14 14:57:53,146 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,146 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,149 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,149 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,151 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00516
2025-08-14 14:57:53,151 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00517
2025-08-14 14:57:53,182 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,182 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,185 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,185 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,187 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00518
2025-08-14 14:57:53,187 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,188 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,188 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,188 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,189 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00519
2025-08-14 14:57:53,190 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00520
2025-08-14 14:57:53,198 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,198 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,199 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00521
2025-08-14 14:57:53,200 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,200 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00522
2025-08-14 14:57:53,200 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,201 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00523
2025-08-14 14:57:53,203 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,203 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,204 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00524
2025-08-14 14:57:53,204 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,205 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,206 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00525
2025-08-14 14:57:53,221 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,221 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,222 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00526
2025-08-14 14:57:53,232 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,232 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,233 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00527
2025-08-14 14:57:53,253 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,253 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,259 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,259 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,260 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00528
2025-08-14 14:57:53,274 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,274 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,276 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,277 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,277 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,277 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,277 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,279 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,280 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,282 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00529
2025-08-14 14:57:53,282 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,284 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,284 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,285 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00530
2025-08-14 14:57:53,285 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00531
2025-08-14 14:57:53,285 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00532
2025-08-14 14:57:53,285 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00533
2025-08-14 14:57:53,285 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00534
2025-08-14 14:57:53,285 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00535
2025-08-14 14:57:53,303 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,303 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,304 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00536
2025-08-14 14:57:53,308 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,308 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,309 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00537
2025-08-14 14:57:53,315 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,315 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,316 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00538
2025-08-14 14:57:53,344 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,344 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,345 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00539
2025-08-14 14:57:53,346 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,346 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,347 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00540
2025-08-14 14:57:53,349 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,349 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,350 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00541
2025-08-14 14:57:53,352 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,352 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,373 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,373 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,375 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,375 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,376 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,377 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,377 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,378 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,378 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00542
2025-08-14 14:57:53,379 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,381 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00543
2025-08-14 14:57:53,382 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,382 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00544
2025-08-14 14:57:53,382 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,382 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00545
2025-08-14 14:57:53,384 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00546
2025-08-14 14:57:53,384 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00547
2025-08-14 14:57:53,384 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00548
2025-08-14 14:57:53,414 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,414 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,419 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,419 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,420 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00549
2025-08-14 14:57:53,420 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00550
2025-08-14 14:57:53,422 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,422 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,426 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,426 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,427 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00551
2025-08-14 14:57:53,427 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00552
2025-08-14 14:57:53,448 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,448 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,455 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,455 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,456 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,456 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,463 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,463 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,465 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,465 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,467 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 14:57:53,467 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 14:57:53,468 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00553
2025-08-14 14:57:53,468 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00554
2025-08-14 14:57:53,468 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00555
2025-08-14 14:57:53,468 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00556
2025-08-14 14:57:53,468 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00557
2025-08-14 14:57:53,469 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00558
2025-08-14 15:14:01,999 - VuLLMBench - INFO - Experiment exp11 started...
2025-08-14 15:14:02,016 - Controller - INFO - Loaded 2740 examples from the owasp dataset.
2025-08-14 15:14:02,857 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,857 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,858 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,857 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,861 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,862 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,862 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,863 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,863 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,863 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,866 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,867 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00001
2025-08-14 15:14:02,883 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,883 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,888 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,888 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,889 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00002
2025-08-14 15:14:02,889 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00003
2025-08-14 15:14:02,889 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00004
2025-08-14 15:14:02,889 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00005
2025-08-14 15:14:02,889 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00006
2025-08-14 15:14:02,892 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,892 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,900 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,901 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,902 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00007
2025-08-14 15:14:02,902 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00008
2025-08-14 15:14:02,902 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00009
2025-08-14 15:14:02,902 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00010
2025-08-14 15:14:02,929 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,929 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,933 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,933 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,934 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00011
2025-08-14 15:14:02,935 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00012
2025-08-14 15:14:02,939 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,939 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,940 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00013
2025-08-14 15:14:02,941 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,941 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,945 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,945 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,946 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00014
2025-08-14 15:14:02,946 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00015
2025-08-14 15:14:02,950 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,950 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,951 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00016
2025-08-14 15:14:02,963 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,964 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,965 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00017
2025-08-14 15:14:02,979 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,979 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:02,984 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:02,984 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,007 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,007 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,009 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,009 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,011 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,011 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,011 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,012 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,022 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,022 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,022 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,022 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,029 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,029 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,030 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00018
2025-08-14 15:14:03,030 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00019
2025-08-14 15:14:03,031 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00020
2025-08-14 15:14:03,031 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00021
2025-08-14 15:14:03,031 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00022
2025-08-14 15:14:03,031 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00023
2025-08-14 15:14:03,031 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00024
2025-08-14 15:14:03,031 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00025
2025-08-14 15:14:03,031 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00026
2025-08-14 15:14:03,043 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,043 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,044 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00027
2025-08-14 15:14:03,062 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,062 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,063 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00028
2025-08-14 15:14:03,076 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,076 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,077 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00029
2025-08-14 15:14:03,080 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,080 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,083 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,083 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,085 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,085 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00030
2025-08-14 15:14:03,085 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,085 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00031
2025-08-14 15:14:03,086 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00032
2025-08-14 15:14:03,095 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,095 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,096 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00033
2025-08-14 15:14:03,098 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,098 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,103 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,103 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,105 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,105 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00034
2025-08-14 15:14:03,105 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,105 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00035
2025-08-14 15:14:03,106 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00036
2025-08-14 15:14:03,125 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,125 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,126 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00037
2025-08-14 15:14:03,150 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,150 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,152 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,152 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,153 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00038
2025-08-14 15:14:03,155 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,155 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,160 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,160 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,165 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,165 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,166 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00039
2025-08-14 15:14:03,166 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00040
2025-08-14 15:14:03,166 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00041
2025-08-14 15:14:03,166 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00042
2025-08-14 15:14:03,176 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,176 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,176 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,177 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,187 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,187 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,202 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,202 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,203 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00043
2025-08-14 15:14:03,203 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00044
2025-08-14 15:14:03,204 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00045
2025-08-14 15:14:03,204 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00046
2025-08-14 15:14:03,219 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,219 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,220 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00047
2025-08-14 15:14:03,229 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,229 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,230 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00048
2025-08-14 15:14:03,232 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,232 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,234 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,234 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,237 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,237 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,238 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00049
2025-08-14 15:14:03,238 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00050
2025-08-14 15:14:03,238 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00051
2025-08-14 15:14:03,249 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,249 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,250 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00052
2025-08-14 15:14:03,251 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,251 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,252 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00053
2025-08-14 15:14:03,256 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,257 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,258 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00054
2025-08-14 15:14:03,278 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,278 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,279 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00055
2025-08-14 15:14:03,281 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,281 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,282 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00056
2025-08-14 15:14:03,300 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,300 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,301 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00057
2025-08-14 15:14:03,302 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,302 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,303 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00058
2025-08-14 15:14:03,305 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,306 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00059
2025-08-14 15:14:03,310 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,310 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,311 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00060
2025-08-14 15:14:03,320 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,320 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,321 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00061
2025-08-14 15:14:03,325 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,325 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,332 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,332 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,347 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,348 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,349 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00062
2025-08-14 15:14:03,349 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00063
2025-08-14 15:14:03,349 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00064
2025-08-14 15:14:03,355 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,355 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,358 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,358 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,359 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00065
2025-08-14 15:14:03,359 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00066
2025-08-14 15:14:03,377 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,377 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,380 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,380 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,381 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00067
2025-08-14 15:14:03,381 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00068
2025-08-14 15:14:03,385 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,385 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,386 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00069
2025-08-14 15:14:03,388 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,388 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,389 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00070
2025-08-14 15:14:03,400 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,400 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,401 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,401 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,403 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00071
2025-08-14 15:14:03,403 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00072
2025-08-14 15:14:03,409 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,409 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,410 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00073
2025-08-14 15:14:03,434 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,434 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,435 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00074
2025-08-14 15:14:03,437 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,437 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,439 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,439 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,440 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00075
2025-08-14 15:14:03,440 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00076
2025-08-14 15:14:03,450 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,450 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,451 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00077
2025-08-14 15:14:03,461 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,461 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,462 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00078
2025-08-14 15:14:03,469 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,469 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,474 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,474 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,486 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,486 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,512 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,513 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,513 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,513 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,514 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00079
2025-08-14 15:14:03,516 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,517 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,517 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00080
2025-08-14 15:14:03,517 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,517 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,517 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00081
2025-08-14 15:14:03,522 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,522 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,541 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,541 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,543 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,543 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,547 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,547 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,558 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,558 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00082
2025-08-14 15:14:03,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00083
2025-08-14 15:14:03,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00084
2025-08-14 15:14:03,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00085
2025-08-14 15:14:03,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00086
2025-08-14 15:14:03,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00087
2025-08-14 15:14:03,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00088
2025-08-14 15:14:03,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00089
2025-08-14 15:14:03,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00090
2025-08-14 15:14:03,570 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,570 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,571 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00091
2025-08-14 15:14:03,591 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,591 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,593 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00092
2025-08-14 15:14:03,597 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,598 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,599 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,600 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,600 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,600 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00093
2025-08-14 15:14:03,600 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,601 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00094
2025-08-14 15:14:03,603 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,603 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00095
2025-08-14 15:14:03,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00096
2025-08-14 15:14:03,620 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,621 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,621 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,621 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,622 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00097
2025-08-14 15:14:03,624 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00098
2025-08-14 15:14:03,625 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,625 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,626 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00099
2025-08-14 15:14:03,641 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,641 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,642 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00100
2025-08-14 15:14:03,649 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,650 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,651 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00101
2025-08-14 15:14:03,666 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,666 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00102
2025-08-14 15:14:03,671 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,671 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,672 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00103
2025-08-14 15:14:03,677 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,677 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,686 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,686 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,687 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,688 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00104
2025-08-14 15:14:03,688 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00105
2025-08-14 15:14:03,688 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,689 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00106
2025-08-14 15:14:03,695 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,696 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,697 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00107
2025-08-14 15:14:03,700 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,700 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,701 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00108
2025-08-14 15:14:03,719 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,719 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,720 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00109
2025-08-14 15:14:03,726 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,726 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,728 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00110
2025-08-14 15:14:03,732 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,732 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,733 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00111
2025-08-14 15:14:03,745 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,745 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,747 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,747 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,748 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00112
2025-08-14 15:14:03,748 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00113
2025-08-14 15:14:03,757 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,757 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00114
2025-08-14 15:14:03,765 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,766 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,767 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00115
2025-08-14 15:14:03,769 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,769 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,779 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,779 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,780 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00116
2025-08-14 15:14:03,781 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,781 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00117
2025-08-14 15:14:03,781 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,783 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00118
2025-08-14 15:14:03,804 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,805 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,806 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00119
2025-08-14 15:14:03,807 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,807 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,809 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,810 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,811 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00120
2025-08-14 15:14:03,811 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00121
2025-08-14 15:14:03,817 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,817 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,818 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00122
2025-08-14 15:14:03,826 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,827 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,828 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,828 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,830 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00123
2025-08-14 15:14:03,830 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00124
2025-08-14 15:14:03,842 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,842 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,844 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,844 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00125
2025-08-14 15:14:03,844 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,846 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00126
2025-08-14 15:14:03,860 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,860 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,865 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,866 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00127
2025-08-14 15:14:03,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00128
2025-08-14 15:14:03,881 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,881 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,882 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,882 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,884 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00129
2025-08-14 15:14:03,884 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00130
2025-08-14 15:14:03,888 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,888 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,892 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,892 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,894 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00131
2025-08-14 15:14:03,894 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00132
2025-08-14 15:14:03,900 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,900 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,907 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,907 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,908 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00133
2025-08-14 15:14:03,908 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00134
2025-08-14 15:14:03,915 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,915 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,920 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,920 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00135
2025-08-14 15:14:03,921 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00136
2025-08-14 15:14:03,947 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,947 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,948 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00137
2025-08-14 15:14:03,953 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,953 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,954 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00138
2025-08-14 15:14:03,956 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,956 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,960 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,960 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,961 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00139
2025-08-14 15:14:03,961 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00140
2025-08-14 15:14:03,963 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,963 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,964 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00141
2025-08-14 15:14:03,977 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,977 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,978 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00142
2025-08-14 15:14:03,979 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,979 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,980 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00143
2025-08-14 15:14:03,984 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,985 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,987 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:03,987 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:03,988 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00144
2025-08-14 15:14:03,988 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00145
2025-08-14 15:14:04,010 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,011 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,012 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00146
2025-08-14 15:14:04,027 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,027 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,028 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00147
2025-08-14 15:14:04,035 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,035 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,036 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,036 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,038 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,038 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,043 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,043 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,044 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00148
2025-08-14 15:14:04,044 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00149
2025-08-14 15:14:04,044 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00150
2025-08-14 15:14:04,044 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00151
2025-08-14 15:14:04,053 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,053 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,058 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,058 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,062 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,063 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,070 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,070 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,071 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00152
2025-08-14 15:14:04,072 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00153
2025-08-14 15:14:04,072 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00154
2025-08-14 15:14:04,072 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00155
2025-08-14 15:14:04,103 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,103 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,104 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00156
2025-08-14 15:14:04,108 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,108 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,110 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,111 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,111 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00157
2025-08-14 15:14:04,110 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,112 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,113 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00158
2025-08-14 15:14:04,114 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,114 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00159
2025-08-14 15:14:04,114 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,115 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00160
2025-08-14 15:14:04,133 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,133 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,135 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,135 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,139 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,139 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,170 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,170 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,178 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,178 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,184 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,184 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,188 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,188 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,188 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,188 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,193 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,193 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,205 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,205 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,212 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,212 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,214 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,214 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,238 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,238 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,239 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00161
2025-08-14 15:14:04,239 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00162
2025-08-14 15:14:04,239 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00163
2025-08-14 15:14:04,239 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00164
2025-08-14 15:14:04,240 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00165
2025-08-14 15:14:04,240 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00166
2025-08-14 15:14:04,240 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00167
2025-08-14 15:14:04,240 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00168
2025-08-14 15:14:04,240 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00169
2025-08-14 15:14:04,240 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00170
2025-08-14 15:14:04,240 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00171
2025-08-14 15:14:04,240 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00172
2025-08-14 15:14:04,240 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00173
2025-08-14 15:14:04,255 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,255 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,256 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00174
2025-08-14 15:14:04,259 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,259 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,260 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00175
2025-08-14 15:14:04,262 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,262 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,266 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,266 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,267 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,267 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,270 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,270 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,271 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00176
2025-08-14 15:14:04,271 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00177
2025-08-14 15:14:04,271 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00178
2025-08-14 15:14:04,271 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00179
2025-08-14 15:14:04,276 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,276 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,277 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00180
2025-08-14 15:14:04,288 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,288 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,289 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00181
2025-08-14 15:14:04,336 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,336 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,338 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,339 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,339 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,339 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,342 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,342 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,345 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,346 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,346 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,346 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,348 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,349 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,352 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,352 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,360 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,360 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,412 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,412 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,417 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,417 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,422 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,423 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,424 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,424 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,426 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,426 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,426 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,426 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,430 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,430 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,432 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,432 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,434 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,434 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,484 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,484 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,490 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,490 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,494 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,494 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00182
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00183
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00184
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00185
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00186
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00187
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00188
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00189
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00190
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00191
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00192
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00193
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00194
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00195
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00196
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00197
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00198
2025-08-14 15:14:04,495 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00199
2025-08-14 15:14:04,496 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00200
2025-08-14 15:14:04,496 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00201
2025-08-14 15:14:04,496 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00202
2025-08-14 15:14:04,497 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,497 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,499 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,499 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,510 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,511 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,511 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,512 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,512 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,512 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,515 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00203
2025-08-14 15:14:04,516 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00204
2025-08-14 15:14:04,516 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00205
2025-08-14 15:14:04,516 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00206
2025-08-14 15:14:04,516 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00207
2025-08-14 15:14:04,517 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,517 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,518 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00208
2025-08-14 15:14:04,561 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,561 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,563 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,563 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,567 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,567 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,571 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,571 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,577 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,577 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,588 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,589 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00209
2025-08-14 15:14:04,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00210
2025-08-14 15:14:04,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00211
2025-08-14 15:14:04,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00212
2025-08-14 15:14:04,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00213
2025-08-14 15:14:04,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00214
2025-08-14 15:14:04,591 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,591 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,592 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00215
2025-08-14 15:14:04,603 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,604 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,604 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,604 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,606 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00216
2025-08-14 15:14:04,607 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00217
2025-08-14 15:14:04,622 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,622 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,622 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00218
2025-08-14 15:14:04,635 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,635 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,637 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00219
2025-08-14 15:14:04,637 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,637 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,645 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,645 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,646 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00220
2025-08-14 15:14:04,646 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00221
2025-08-14 15:14:04,648 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,648 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,649 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00222
2025-08-14 15:14:04,651 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,651 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,652 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00223
2025-08-14 15:14:04,666 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,666 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00224
2025-08-14 15:14:04,670 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,670 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,672 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00225
2025-08-14 15:14:04,683 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,684 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,685 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00226
2025-08-14 15:14:04,703 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,703 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,704 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00227
2025-08-14 15:14:04,713 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,713 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,714 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,715 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,722 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,722 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,723 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,723 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,723 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,723 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,726 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,727 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00228
2025-08-14 15:14:04,727 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,728 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00229
2025-08-14 15:14:04,729 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00230
2025-08-14 15:14:04,729 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00231
2025-08-14 15:14:04,729 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00232
2025-08-14 15:14:04,729 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00233
2025-08-14 15:14:04,737 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,737 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00234
2025-08-14 15:14:04,748 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,748 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,749 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00235
2025-08-14 15:14:04,767 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,767 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,768 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00236
2025-08-14 15:14:04,788 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,788 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,790 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,790 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,792 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,792 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00237
2025-08-14 15:14:04,792 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,792 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00238
2025-08-14 15:14:04,793 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00239
2025-08-14 15:14:04,796 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,796 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,798 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,798 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,804 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,804 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,810 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,810 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,811 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00240
2025-08-14 15:14:04,811 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00241
2025-08-14 15:14:04,811 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00242
2025-08-14 15:14:04,811 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00243
2025-08-14 15:14:04,813 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,813 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,814 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00244
2025-08-14 15:14:04,833 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,833 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,834 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00245
2025-08-14 15:14:04,845 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,845 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,846 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00246
2025-08-14 15:14:04,862 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,862 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00247
2025-08-14 15:14:04,865 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,865 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,867 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,867 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,870 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,870 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,875 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,875 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00248
2025-08-14 15:14:04,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00249
2025-08-14 15:14:04,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00250
2025-08-14 15:14:04,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00251
2025-08-14 15:14:04,877 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,877 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,878 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00252
2025-08-14 15:14:04,887 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,887 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,895 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,895 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,896 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00253
2025-08-14 15:14:04,896 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00254
2025-08-14 15:14:04,909 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,909 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,910 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00255
2025-08-14 15:14:04,927 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,927 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,928 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00256
2025-08-14 15:14:04,940 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,940 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,941 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00257
2025-08-14 15:14:04,941 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,942 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,943 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00258
2025-08-14 15:14:04,945 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,945 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,949 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,949 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,950 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00259
2025-08-14 15:14:04,950 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00260
2025-08-14 15:14:04,955 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,955 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,963 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,963 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,963 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,963 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,965 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00261
2025-08-14 15:14:04,966 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00262
2025-08-14 15:14:04,966 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00263
2025-08-14 15:14:04,980 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,980 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,981 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00264
2025-08-14 15:14:04,993 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:04,993 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:04,994 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00265
2025-08-14 15:14:05,012 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,012 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,015 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,015 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,018 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,018 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,019 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00266
2025-08-14 15:14:05,019 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00267
2025-08-14 15:14:05,019 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00268
2025-08-14 15:14:05,021 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,021 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,022 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,022 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00269
2025-08-14 15:14:05,022 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,023 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00270
2025-08-14 15:14:05,031 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,031 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,032 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00271
2025-08-14 15:14:05,035 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,035 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,036 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00272
2025-08-14 15:14:05,047 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,047 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,048 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00273
2025-08-14 15:14:05,065 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,065 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,066 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00274
2025-08-14 15:14:05,085 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,085 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,092 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,092 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,094 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,094 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,098 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,099 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,099 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,099 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,107 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,107 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,108 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00275
2025-08-14 15:14:05,108 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00276
2025-08-14 15:14:05,108 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00277
2025-08-14 15:14:05,108 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00278
2025-08-14 15:14:05,108 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00279
2025-08-14 15:14:05,108 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00280
2025-08-14 15:14:05,111 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,111 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,112 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00281
2025-08-14 15:14:05,130 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,130 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,136 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,136 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00282
2025-08-14 15:14:05,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00283
2025-08-14 15:14:05,150 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,150 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,151 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00284
2025-08-14 15:14:05,155 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,155 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,156 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00285
2025-08-14 15:14:05,166 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,166 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,166 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,167 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,168 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00286
2025-08-14 15:14:05,169 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00287
2025-08-14 15:14:05,170 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,170 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,171 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00288
2025-08-14 15:14:05,182 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,182 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,183 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00289
2025-08-14 15:14:05,186 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,186 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,187 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00290
2025-08-14 15:14:05,193 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,194 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,195 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00291
2025-08-14 15:14:05,209 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,209 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,216 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,216 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,217 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00292
2025-08-14 15:14:05,217 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00293
2025-08-14 15:14:05,230 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,230 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,242 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,243 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,243 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,244 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,244 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,244 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,244 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,244 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,249 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00294
2025-08-14 15:14:05,249 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00295
2025-08-14 15:14:05,249 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00296
2025-08-14 15:14:05,249 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00297
2025-08-14 15:14:05,249 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00298
2025-08-14 15:14:05,262 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,262 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,263 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,264 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00299
2025-08-14 15:14:05,264 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,265 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00300
2025-08-14 15:14:05,275 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,275 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,276 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00301
2025-08-14 15:14:05,279 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,279 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,280 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00302
2025-08-14 15:14:05,303 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,303 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,304 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00303
2025-08-14 15:14:05,307 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,307 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,308 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00304
2025-08-14 15:14:05,315 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,315 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,320 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,320 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,322 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,322 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,323 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00305
2025-08-14 15:14:05,331 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,331 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,332 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00306
2025-08-14 15:14:05,332 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00307
2025-08-14 15:14:05,332 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00308
2025-08-14 15:14:05,338 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,338 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,339 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00309
2025-08-14 15:14:05,342 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,343 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,344 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00310
2025-08-14 15:14:05,354 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,354 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,363 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,363 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,364 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00311
2025-08-14 15:14:05,364 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00312
2025-08-14 15:14:05,379 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,379 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,389 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,389 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,390 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,390 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,391 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00313
2025-08-14 15:14:05,391 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00314
2025-08-14 15:14:05,391 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00315
2025-08-14 15:14:05,393 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,393 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,394 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00316
2025-08-14 15:14:05,399 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,399 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,400 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00317
2025-08-14 15:14:05,417 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,417 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,418 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,419 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,420 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00318
2025-08-14 15:14:05,420 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00319
2025-08-14 15:14:05,423 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,423 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,424 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00320
2025-08-14 15:14:05,426 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,426 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,427 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00321
2025-08-14 15:14:05,438 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,438 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,440 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00322
2025-08-14 15:14:05,458 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,458 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,459 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00323
2025-08-14 15:14:05,466 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,466 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,468 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,468 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,469 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00324
2025-08-14 15:14:05,473 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,473 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,474 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00325
2025-08-14 15:14:05,475 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00326
2025-08-14 15:14:05,496 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,496 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,500 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,500 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,502 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,503 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,504 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,504 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,506 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,506 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,507 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00327
2025-08-14 15:14:05,507 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00328
2025-08-14 15:14:05,507 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00329
2025-08-14 15:14:05,507 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00330
2025-08-14 15:14:05,508 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00331
2025-08-14 15:14:05,530 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,530 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,539 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,539 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,540 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,541 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,558 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,558 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,571 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,572 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,574 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,575 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,575 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,575 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,576 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00332
2025-08-14 15:14:05,577 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00333
2025-08-14 15:14:05,577 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00334
2025-08-14 15:14:05,577 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00335
2025-08-14 15:14:05,577 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00336
2025-08-14 15:14:05,577 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00337
2025-08-14 15:14:05,580 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,580 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,582 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,582 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,592 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,592 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,594 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00338
2025-08-14 15:14:05,594 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00339
2025-08-14 15:14:05,594 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00340
2025-08-14 15:14:05,594 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00341
2025-08-14 15:14:05,614 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,614 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,616 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,616 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,617 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,618 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,619 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00342
2025-08-14 15:14:05,619 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00343
2025-08-14 15:14:05,619 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00344
2025-08-14 15:14:05,646 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,646 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,647 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00345
2025-08-14 15:14:05,650 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,650 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,651 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00346
2025-08-14 15:14:05,653 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,653 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,654 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,654 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00347
2025-08-14 15:14:05,654 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,656 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,656 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00348
2025-08-14 15:14:05,656 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,657 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00349
2025-08-14 15:14:05,665 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,665 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,666 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00350
2025-08-14 15:14:05,684 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,684 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,686 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,686 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,688 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00351
2025-08-14 15:14:05,688 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00352
2025-08-14 15:14:05,691 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,691 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,694 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,694 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,695 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00353
2025-08-14 15:14:05,695 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00354
2025-08-14 15:14:05,728 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,728 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,730 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,730 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,730 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,731 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,733 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,733 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,735 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,735 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,736 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00355
2025-08-14 15:14:05,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00356
2025-08-14 15:14:05,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00357
2025-08-14 15:14:05,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00358
2025-08-14 15:14:05,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00359
2025-08-14 15:14:05,746 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,746 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,747 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00360
2025-08-14 15:14:05,759 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,759 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,760 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00361
2025-08-14 15:14:05,766 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,766 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,769 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,769 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,770 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,771 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,772 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00362
2025-08-14 15:14:05,772 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00363
2025-08-14 15:14:05,772 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00364
2025-08-14 15:14:05,803 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,803 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,806 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,806 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,807 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00365
2025-08-14 15:14:05,807 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00366
2025-08-14 15:14:05,809 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,809 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,811 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,811 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00367
2025-08-14 15:14:05,811 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,812 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00368
2025-08-14 15:14:05,817 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,817 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,818 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00369
2025-08-14 15:14:05,822 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,822 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,823 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00370
2025-08-14 15:14:05,831 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,831 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,832 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00371
2025-08-14 15:14:05,841 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,841 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,842 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00372
2025-08-14 15:14:05,847 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,847 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,848 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00373
2025-08-14 15:14:05,856 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,856 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,857 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00374
2025-08-14 15:14:05,874 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,874 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00375
2025-08-14 15:14:05,886 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,887 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,887 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,887 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,887 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,887 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,889 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00376
2025-08-14 15:14:05,891 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00377
2025-08-14 15:14:05,891 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00378
2025-08-14 15:14:05,899 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,899 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,900 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,900 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,901 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00379
2025-08-14 15:14:05,902 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,902 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00380
2025-08-14 15:14:05,902 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,903 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00381
2025-08-14 15:14:05,914 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,914 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,915 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00382
2025-08-14 15:14:05,918 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,918 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,919 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00383
2025-08-14 15:14:05,944 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,944 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,961 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,961 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,967 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,967 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,969 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,969 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,970 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,970 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,971 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00384
2025-08-14 15:14:05,971 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00385
2025-08-14 15:14:05,972 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00386
2025-08-14 15:14:05,972 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00387
2025-08-14 15:14:05,972 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00388
2025-08-14 15:14:05,977 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,977 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,977 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,977 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,980 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00389
2025-08-14 15:14:05,981 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,981 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,982 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00390
2025-08-14 15:14:05,982 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00391
2025-08-14 15:14:05,989 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,989 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,991 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:05,991 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00392
2025-08-14 15:14:05,991 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:05,992 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00393
2025-08-14 15:14:06,023 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,023 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,024 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00394
2025-08-14 15:14:06,042 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,042 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,043 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,044 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,045 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00395
2025-08-14 15:14:06,045 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00396
2025-08-14 15:14:06,050 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,050 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,051 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00397
2025-08-14 15:14:06,053 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,053 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00398
2025-08-14 15:14:06,055 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,055 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,058 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,058 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,059 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00399
2025-08-14 15:14:06,059 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00400
2025-08-14 15:14:06,060 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,060 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,064 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,064 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,072 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,072 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00401
2025-08-14 15:14:06,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00402
2025-08-14 15:14:06,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00403
2025-08-14 15:14:06,097 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,097 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00404
2025-08-14 15:14:06,118 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,118 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,123 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,123 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,125 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00405
2025-08-14 15:14:06,125 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00406
2025-08-14 15:14:06,128 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,128 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,141 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,141 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,142 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00407
2025-08-14 15:14:06,145 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,145 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,147 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,147 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,157 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,157 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,158 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00408
2025-08-14 15:14:06,158 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00409
2025-08-14 15:14:06,158 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00410
2025-08-14 15:14:06,158 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00411
2025-08-14 15:14:06,159 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,159 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,171 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,171 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,194 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,194 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,199 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,199 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,201 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,201 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,201 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,201 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,203 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00412
2025-08-14 15:14:06,204 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00413
2025-08-14 15:14:06,204 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00414
2025-08-14 15:14:06,204 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00415
2025-08-14 15:14:06,204 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00416
2025-08-14 15:14:06,204 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00417
2025-08-14 15:14:06,219 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,220 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,220 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,220 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,221 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00418
2025-08-14 15:14:06,222 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00419
2025-08-14 15:14:06,224 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,225 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,226 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00420
2025-08-14 15:14:06,243 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,243 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,244 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00421
2025-08-14 15:14:06,246 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,246 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,256 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,256 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,257 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00422
2025-08-14 15:14:06,257 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00423
2025-08-14 15:14:06,269 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,269 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,270 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00424
2025-08-14 15:14:06,278 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,278 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,280 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,280 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,281 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,281 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00425
2025-08-14 15:14:06,281 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,283 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00426
2025-08-14 15:14:06,283 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00427
2025-08-14 15:14:06,293 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,293 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,294 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00428
2025-08-14 15:14:06,299 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,299 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,316 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,316 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,317 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00429
2025-08-14 15:14:06,317 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00430
2025-08-14 15:14:06,318 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,318 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,334 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,334 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,335 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00431
2025-08-14 15:14:06,335 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00432
2025-08-14 15:14:06,339 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,339 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,340 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00433
2025-08-14 15:14:06,349 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,349 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,350 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00434
2025-08-14 15:14:06,353 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,353 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,355 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,355 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00435
2025-08-14 15:14:06,355 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,359 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,359 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,360 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00436
2025-08-14 15:14:06,360 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00437
2025-08-14 15:14:06,364 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,364 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,365 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00438
2025-08-14 15:14:06,377 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,377 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,378 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00439
2025-08-14 15:14:06,389 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,389 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,396 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,396 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,397 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00440
2025-08-14 15:14:06,397 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00441
2025-08-14 15:14:06,421 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,421 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,421 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,421 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,423 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,425 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,425 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00442
2025-08-14 15:14:06,425 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,425 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,425 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00443
2025-08-14 15:14:06,428 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,428 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00444
2025-08-14 15:14:06,428 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,428 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00445
2025-08-14 15:14:06,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00446
2025-08-14 15:14:06,434 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,435 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,436 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00447
2025-08-14 15:14:06,438 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,438 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,439 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00448
2025-08-14 15:14:06,455 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,455 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,456 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00449
2025-08-14 15:14:06,461 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,461 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,462 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00450
2025-08-14 15:14:06,475 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,476 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,477 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00451
2025-08-14 15:14:06,492 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,492 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,500 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,501 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,505 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,505 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,506 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00452
2025-08-14 15:14:06,506 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00453
2025-08-14 15:14:06,507 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00454
2025-08-14 15:14:06,507 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,507 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,509 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,509 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,510 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,512 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,512 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,512 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,514 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00455
2025-08-14 15:14:06,515 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00456
2025-08-14 15:14:06,515 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00457
2025-08-14 15:14:06,515 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00458
2025-08-14 15:14:06,529 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,529 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,530 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00459
2025-08-14 15:14:06,540 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,541 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,542 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00460
2025-08-14 15:14:06,552 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,552 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,553 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00461
2025-08-14 15:14:06,569 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,569 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,570 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00462
2025-08-14 15:14:06,580 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,580 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,587 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,587 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,589 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,589 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,591 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,592 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,592 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,592 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,593 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00463
2025-08-14 15:14:06,594 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00464
2025-08-14 15:14:06,594 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00465
2025-08-14 15:14:06,594 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00466
2025-08-14 15:14:06,594 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00467
2025-08-14 15:14:06,598 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,598 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,599 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00468
2025-08-14 15:14:06,604 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,604 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,605 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00469
2025-08-14 15:14:06,615 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,615 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,616 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00470
2025-08-14 15:14:06,638 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,639 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,658 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,658 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,664 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,664 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,665 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,665 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,666 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,667 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,674 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,674 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,675 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00471
2025-08-14 15:14:06,675 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00472
2025-08-14 15:14:06,675 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00473
2025-08-14 15:14:06,675 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00474
2025-08-14 15:14:06,675 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00475
2025-08-14 15:14:06,675 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00476
2025-08-14 15:14:06,683 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,683 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,691 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,691 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,695 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,695 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,696 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,696 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,698 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00477
2025-08-14 15:14:06,698 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00478
2025-08-14 15:14:06,698 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00479
2025-08-14 15:14:06,698 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00480
2025-08-14 15:14:06,715 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,715 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,716 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00481
2025-08-14 15:14:06,730 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,730 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,731 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00482
2025-08-14 15:14:06,738 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,738 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,746 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,746 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,749 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,749 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,750 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00483
2025-08-14 15:14:06,750 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00484
2025-08-14 15:14:06,750 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00485
2025-08-14 15:14:06,754 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,754 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,755 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00486
2025-08-14 15:14:06,766 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,766 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,767 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,768 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,769 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00487
2025-08-14 15:14:06,772 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,772 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,773 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00488
2025-08-14 15:14:06,773 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00489
2025-08-14 15:14:06,787 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,787 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,789 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,789 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,790 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00490
2025-08-14 15:14:06,791 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00491
2025-08-14 15:14:06,804 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,804 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,805 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00492
2025-08-14 15:14:06,811 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,811 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,812 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00493
2025-08-14 15:14:06,820 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,820 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,821 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00494
2025-08-14 15:14:06,828 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,829 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,830 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00495
2025-08-14 15:14:06,834 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,834 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,835 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00496
2025-08-14 15:14:06,838 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,838 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,839 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00497
2025-08-14 15:14:06,850 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,850 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,851 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00498
2025-08-14 15:14:06,856 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,856 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,857 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00499
2025-08-14 15:14:06,860 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,860 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,862 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00500
2025-08-14 15:14:06,873 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,873 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00501
2025-08-14 15:14:06,878 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,878 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,879 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00502
2025-08-14 15:14:06,885 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,885 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,887 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00503
2025-08-14 15:14:06,894 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,895 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,896 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00504
2025-08-14 15:14:06,900 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,900 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,901 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00505
2025-08-14 15:14:06,910 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,910 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,919 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,919 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,920 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00506
2025-08-14 15:14:06,920 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00507
2025-08-14 15:14:06,934 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,934 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,949 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,949 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,949 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,949 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,950 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00508
2025-08-14 15:14:06,952 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00509
2025-08-14 15:14:06,952 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00510
2025-08-14 15:14:06,953 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,953 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,957 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,957 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,958 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00511
2025-08-14 15:14:06,958 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00512
2025-08-14 15:14:06,963 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,963 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,964 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00513
2025-08-14 15:14:06,972 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,972 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,974 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,974 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,975 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00514
2025-08-14 15:14:06,975 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00515
2025-08-14 15:14:06,985 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,985 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,986 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00516
2025-08-14 15:14:06,997 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:06,998 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:06,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00517
2025-08-14 15:14:07,004 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,004 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,005 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00518
2025-08-14 15:14:07,024 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,024 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,025 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00519
2025-08-14 15:14:07,026 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,027 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,035 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,035 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,036 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00520
2025-08-14 15:14:07,036 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00521
2025-08-14 15:14:07,046 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,046 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,048 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,048 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00522
2025-08-14 15:14:07,048 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,051 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,051 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,051 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,052 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00523
2025-08-14 15:14:07,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00524
2025-08-14 15:14:07,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00525
2025-08-14 15:14:07,056 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,056 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,057 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00526
2025-08-14 15:14:07,076 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,076 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,077 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,078 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,079 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00527
2025-08-14 15:14:07,079 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00528
2025-08-14 15:14:07,100 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,100 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,103 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,103 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,104 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00529
2025-08-14 15:14:07,105 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00530
2025-08-14 15:14:07,119 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,120 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,121 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00531
2025-08-14 15:14:07,134 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,134 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,136 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,136 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,138 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,138 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,138 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,138 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,144 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,144 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,145 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00532
2025-08-14 15:14:07,145 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00533
2025-08-14 15:14:07,145 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00534
2025-08-14 15:14:07,146 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00535
2025-08-14 15:14:07,146 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00536
2025-08-14 15:14:07,151 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,151 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,152 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00537
2025-08-14 15:14:07,161 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,161 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,162 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00538
2025-08-14 15:14:07,173 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,173 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,174 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00539
2025-08-14 15:14:07,185 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,185 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,186 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00540
2025-08-14 15:14:07,203 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,203 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,205 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00541
2025-08-14 15:14:07,209 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,209 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,211 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,211 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00542
2025-08-14 15:14:07,211 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,212 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00543
2025-08-14 15:14:07,213 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,213 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,214 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00544
2025-08-14 15:14:07,217 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,218 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,219 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00545
2025-08-14 15:14:07,222 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,222 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,241 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,241 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,243 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,243 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,244 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00546
2025-08-14 15:14:07,244 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00547
2025-08-14 15:14:07,244 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00548
2025-08-14 15:14:07,245 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,245 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,246 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00549
2025-08-14 15:14:07,266 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,266 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,267 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00550
2025-08-14 15:14:07,282 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,283 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,284 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,285 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,285 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,285 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,287 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00551
2025-08-14 15:14:07,287 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00552
2025-08-14 15:14:07,287 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00553
2025-08-14 15:14:07,288 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,288 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,289 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00554
2025-08-14 15:14:07,291 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,291 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,296 - LLMsInterface - ERROR - Error invoking model: Error code: 400 - {'error': {'message': "Unsupported parameter: 'temperature' is not supported with this model.", 'type': 'invalid_request_error', 'param': 'temperature', 'code': 'unsupported_parameter'}}
2025-08-14 15:14:07,296 - LLMsInterface - ERROR - max_tokens error encountered, returning None.
2025-08-14 15:14:07,297 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00555
2025-08-14 15:14:07,297 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00556
2025-08-14 15:20:35,510 - VuLLMBench - INFO - Experiment exp11 started...
2025-08-14 15:20:35,526 - Controller - INFO - Loaded 2740 examples from the owasp dataset.
2025-08-14 15:20:39,151 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00001
2025-08-14 15:20:39,347 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00002
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00003
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00004
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00005
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00006
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00007
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00008
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00009
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00010
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00011
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00012
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00013
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00014
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00015
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00016
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00017
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00018
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00019
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00020
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00021
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00022
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00023
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00024
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00025
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00026
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00027
2025-08-14 15:20:52,089 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00028
2025-08-14 15:20:56,231 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00029
2025-08-14 15:20:56,231 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00030
2025-08-14 15:20:56,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00031
2025-08-14 15:20:56,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00032
2025-08-14 15:20:56,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00033
2025-08-14 15:20:56,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00034
2025-08-14 15:20:56,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00035
2025-08-14 15:20:56,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00036
2025-08-14 15:20:56,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00037
2025-08-14 15:20:56,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00038
2025-08-14 15:20:56,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00039
2025-08-14 15:20:56,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00040
2025-08-14 15:20:56,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00041
2025-08-14 15:20:56,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00042
2025-08-14 15:20:56,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00043
2025-08-14 15:20:56,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00044
2025-08-14 15:20:56,374 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00045
2025-08-14 15:20:57,420 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00046
2025-08-14 15:20:57,732 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00047
2025-08-14 15:20:57,732 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00048
2025-08-14 15:20:57,732 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00049
2025-08-14 15:20:58,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00050
2025-08-14 15:20:58,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00051
2025-08-14 15:20:58,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00052
2025-08-14 15:21:00,130 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00053
2025-08-14 15:21:03,055 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00054
2025-08-14 15:21:03,055 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00055
2025-08-14 15:21:03,055 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00056
2025-08-14 15:21:03,055 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00057
2025-08-14 15:21:07,505 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00058
2025-08-14 15:21:07,505 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00059
2025-08-14 15:21:07,505 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00060
2025-08-14 15:21:07,505 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00061
2025-08-14 15:21:07,505 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00062
2025-08-14 15:21:07,506 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00063
2025-08-14 15:21:07,506 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00064
2025-08-14 15:21:07,506 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00065
2025-08-14 15:21:07,506 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00066
2025-08-14 15:21:07,506 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00067
2025-08-14 15:21:07,506 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00068
2025-08-14 15:21:07,506 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00069
2025-08-14 15:21:11,335 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00070
2025-08-14 15:21:11,335 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00071
2025-08-14 15:21:11,335 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00072
2025-08-14 15:21:11,336 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00073
2025-08-14 15:21:12,414 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00074
2025-08-14 15:21:12,414 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00075
2025-08-14 15:21:12,414 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00076
2025-08-14 15:21:12,414 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00077
2025-08-14 15:21:12,414 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00078
2025-08-14 15:21:12,414 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00079
2025-08-14 15:21:14,444 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00080
2025-08-14 15:21:14,444 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00081
2025-08-14 15:21:14,444 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00082
2025-08-14 15:21:14,445 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00083
2025-08-14 15:21:15,011 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00084
2025-08-14 15:21:15,012 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00085
2025-08-14 15:21:15,012 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00086
2025-08-14 15:21:15,012 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00087
2025-08-14 15:21:18,672 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00088
2025-08-14 15:21:21,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00089
2025-08-14 15:21:21,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00090
2025-08-14 15:21:21,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00091
2025-08-14 15:21:21,162 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00092
2025-08-14 15:21:21,162 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00093
2025-08-14 15:21:21,162 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00094
2025-08-14 15:21:25,630 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00095
2025-08-14 15:21:25,631 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00096
2025-08-14 15:21:25,631 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00097
2025-08-14 15:21:27,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00098
2025-08-14 15:21:27,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00099
2025-08-14 15:21:27,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00100
2025-08-14 15:21:27,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00101
2025-08-14 15:21:27,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00102
2025-08-14 15:21:27,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00103
2025-08-14 15:21:27,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00104
2025-08-14 15:21:27,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00105
2025-08-14 15:21:27,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00106
2025-08-14 15:21:27,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00107
2025-08-14 15:21:27,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00108
2025-08-14 15:21:27,668 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00109
2025-08-14 15:21:30,006 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00110
2025-08-14 15:21:30,006 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00111
2025-08-14 15:21:30,006 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00112
2025-08-14 15:21:30,006 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00113
2025-08-14 15:21:35,666 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00114
2025-08-14 15:21:35,667 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00115
2025-08-14 15:21:35,667 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00116
2025-08-14 15:21:35,667 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00117
2025-08-14 15:21:35,667 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00118
2025-08-14 15:21:35,667 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00119
2025-08-14 15:21:35,667 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00120
2025-08-14 15:21:35,667 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00121
2025-08-14 15:21:35,667 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00122
2025-08-14 15:21:35,667 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00123
2025-08-14 15:21:35,667 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00124
2025-08-14 15:21:35,667 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00125
2025-08-14 15:21:37,714 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00126
2025-08-14 15:21:37,714 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00127
2025-08-14 15:21:38,692 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00128
2025-08-14 15:21:38,693 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00129
2025-08-14 15:21:38,954 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00130
2025-08-14 15:21:38,954 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00131
2025-08-14 15:21:39,335 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00132
2025-08-14 15:21:39,336 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00133
2025-08-14 15:21:40,193 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00134
2025-08-14 15:21:40,193 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00135
2025-08-14 15:21:41,914 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00136
2025-08-14 15:21:41,914 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00137
2025-08-14 15:21:42,995 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00138
2025-08-14 15:21:43,196 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00139
2025-08-14 15:21:43,196 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00140
2025-08-14 15:21:44,642 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00141
2025-08-14 15:21:45,137 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00142
2025-08-14 15:21:45,137 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00143
2025-08-14 15:21:46,886 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00144
2025-08-14 15:21:46,886 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00145
2025-08-14 15:21:47,486 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00146
2025-08-14 15:21:47,486 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00147
2025-08-14 15:21:47,486 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00148
2025-08-14 15:21:48,060 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00149
2025-08-14 15:21:48,060 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00150
2025-08-14 15:21:49,500 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00151
2025-08-14 15:21:49,500 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00152
2025-08-14 15:21:49,500 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00153
2025-08-14 15:21:49,500 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00154
2025-08-14 15:21:50,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00155
2025-08-14 15:21:50,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00156
2025-08-14 15:21:50,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00157
2025-08-14 15:21:50,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00158
2025-08-14 15:21:51,387 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00159
2025-08-14 15:21:51,387 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00160
2025-08-14 15:21:51,387 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00161
2025-08-14 15:21:51,387 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00162
2025-08-14 15:21:51,821 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00163
2025-08-14 15:21:52,362 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00164
2025-08-14 15:21:56,439 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00165
2025-08-14 15:21:56,439 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00166
2025-08-14 15:21:56,439 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00167
2025-08-14 15:21:56,439 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00168
2025-08-14 15:21:56,439 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00169
2025-08-14 15:21:56,439 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00170
2025-08-14 15:21:56,733 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00171
2025-08-14 15:21:56,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00172
2025-08-14 15:21:56,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00173
2025-08-14 15:21:57,717 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00174
2025-08-14 15:21:58,413 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00175
2025-08-14 15:21:58,414 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00176
2025-08-14 15:21:59,570 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00177
2025-08-14 15:22:00,267 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00178
2025-08-14 15:22:06,174 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00179
2025-08-14 15:22:06,174 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00180
2025-08-14 15:22:07,988 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00181
2025-08-14 15:22:07,988 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00182
2025-08-14 15:22:07,988 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00183
2025-08-14 15:22:07,988 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00184
2025-08-14 15:22:07,988 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00185
2025-08-14 15:22:08,555 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00186
2025-08-14 15:22:08,555 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00187
2025-08-14 15:22:08,555 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00188
2025-08-14 15:22:08,556 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00189
2025-08-14 15:22:08,556 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00190
2025-08-14 15:22:08,556 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00191
2025-08-14 15:22:08,556 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00192
2025-08-14 15:22:08,556 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00193
2025-08-14 15:22:08,556 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00194
2025-08-14 15:22:08,556 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00195
2025-08-14 15:22:08,556 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00196
2025-08-14 15:22:10,338 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00197
2025-08-14 15:22:10,338 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00198
2025-08-14 15:22:10,339 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00199
2025-08-14 15:22:11,611 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00200
2025-08-14 15:22:11,611 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00201
2025-08-14 15:22:11,611 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00202
2025-08-14 15:22:11,611 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00203
2025-08-14 15:22:11,611 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00204
2025-08-14 15:22:11,611 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00205
2025-08-14 15:22:11,611 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00206
2025-08-14 15:22:11,611 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00207
2025-08-14 15:22:14,394 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00208
2025-08-14 15:22:19,482 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00209
2025-08-14 15:22:19,483 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00210
2025-08-14 15:22:19,483 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00211
2025-08-14 15:22:19,483 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00212
2025-08-14 15:22:19,483 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00213
2025-08-14 15:22:19,483 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00214
2025-08-14 15:22:19,483 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00215
2025-08-14 15:22:19,483 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00216
2025-08-14 15:22:19,483 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00217
2025-08-14 15:22:19,483 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00218
2025-08-14 15:22:19,549 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00219
2025-08-14 15:22:19,550 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00220
2025-08-14 15:22:19,550 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00221
2025-08-14 15:22:19,550 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00222
2025-08-14 15:22:20,230 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00223
2025-08-14 15:22:20,230 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00224
2025-08-14 15:22:20,230 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00225
2025-08-14 15:22:20,851 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00226
2025-08-14 15:22:23,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00227
2025-08-14 15:22:23,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00228
2025-08-14 15:22:23,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00229
2025-08-14 15:22:23,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00230
2025-08-14 15:22:23,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00231
2025-08-14 15:22:23,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00232
2025-08-14 15:22:27,589 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00233
2025-08-14 15:22:27,589 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00234
2025-08-14 15:22:27,589 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00235
2025-08-14 15:22:27,589 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00236
2025-08-14 15:22:27,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00237
2025-08-14 15:22:27,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00238
2025-08-14 15:22:27,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00239
2025-08-14 15:22:27,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00240
2025-08-14 15:22:27,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00241
2025-08-14 15:22:29,959 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00242
2025-08-14 15:22:29,959 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00243
2025-08-14 15:22:29,959 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00244
2025-08-14 15:22:35,019 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00245
2025-08-14 15:22:35,019 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00246
2025-08-14 15:22:35,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00247
2025-08-14 15:22:37,531 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00248
2025-08-14 15:22:37,531 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00249
2025-08-14 15:22:37,531 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00250
2025-08-14 15:22:37,531 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00251
2025-08-14 15:22:37,531 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00252
2025-08-14 15:22:37,531 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00253
2025-08-14 15:22:37,531 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00254
2025-08-14 15:22:37,531 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00255
2025-08-14 15:22:37,531 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00256
2025-08-14 15:22:37,531 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00257
2025-08-14 15:22:37,531 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00258
2025-08-14 15:22:40,882 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00259
2025-08-14 15:22:40,884 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00260
2025-08-14 15:22:40,884 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00261
2025-08-14 15:22:40,884 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00262
2025-08-14 15:22:40,884 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00263
2025-08-14 15:22:40,884 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00264
2025-08-14 15:22:40,884 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00265
2025-08-14 15:22:41,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00266
2025-08-14 15:22:43,800 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00267
2025-08-14 15:22:44,669 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00268
2025-08-14 15:22:44,669 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00269
2025-08-14 15:22:44,669 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00270
2025-08-14 15:22:49,615 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00271
2025-08-14 15:22:49,615 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00272
2025-08-14 15:22:49,615 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00273
2025-08-14 15:22:49,615 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00274
2025-08-14 15:22:49,615 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00275
2025-08-14 15:22:49,615 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00276
2025-08-14 15:22:49,616 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00277
2025-08-14 15:22:49,616 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00278
2025-08-14 15:22:49,616 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00279
2025-08-14 15:22:49,616 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00280
2025-08-14 15:22:49,616 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00281
2025-08-14 15:22:49,616 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00282
2025-08-14 15:22:49,616 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00283
2025-08-14 15:22:49,616 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00284
2025-08-14 15:22:49,760 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00285
2025-08-14 15:22:51,400 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00286
2025-08-14 15:22:51,400 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00287
2025-08-14 15:22:51,400 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00288
2025-08-14 15:22:51,400 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00289
2025-08-14 15:22:52,780 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00290
2025-08-14 15:22:52,780 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00291
2025-08-14 15:22:52,780 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00292
2025-08-14 15:22:52,780 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00293
2025-08-14 15:22:52,805 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00294
2025-08-14 15:22:53,405 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00295
2025-08-14 15:22:53,405 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00296
2025-08-14 15:22:54,835 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00297
2025-08-14 15:22:54,835 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00298
2025-08-14 15:22:57,274 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00299
2025-08-14 15:22:57,274 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00300
2025-08-14 15:22:57,274 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00301
2025-08-14 15:22:57,274 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00302
2025-08-14 15:22:57,274 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00303
2025-08-14 15:22:57,274 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00304
2025-08-14 15:22:57,452 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00305
2025-08-14 15:22:57,453 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00306
2025-08-14 15:22:57,453 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00307
2025-08-14 15:23:00,203 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00308
2025-08-14 15:23:00,203 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00309
2025-08-14 15:23:00,203 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00310
2025-08-14 15:23:00,203 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00311
2025-08-14 15:23:01,892 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00312
2025-08-14 15:23:03,498 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00313
2025-08-14 15:23:03,498 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00314
2025-08-14 15:23:03,498 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00315
2025-08-14 15:23:14,378 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00316
2025-08-14 15:23:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00317
2025-08-14 15:23:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00318
2025-08-14 15:23:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00319
2025-08-14 15:23:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00320
2025-08-14 15:23:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00321
2025-08-14 15:23:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00322
2025-08-14 15:23:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00323
2025-08-14 15:23:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00324
2025-08-14 15:23:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00325
2025-08-14 15:23:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00326
2025-08-14 15:23:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00327
2025-08-14 15:23:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00328
2025-08-14 15:23:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00329
2025-08-14 15:23:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00330
2025-08-14 15:23:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00331
2025-08-14 15:23:14,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00332
2025-08-14 15:23:16,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00333
2025-08-14 15:23:16,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00334
2025-08-14 15:23:16,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00335
2025-08-14 15:23:16,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00336
2025-08-14 15:23:16,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00337
2025-08-14 15:23:16,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00338
2025-08-14 15:23:16,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00339
2025-08-14 15:23:16,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00340
2025-08-14 15:23:16,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00341
2025-08-14 15:23:16,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00342
2025-08-14 15:23:16,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00343
2025-08-14 15:23:16,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00344
2025-08-14 15:23:20,649 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00345
2025-08-14 15:23:20,650 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00346
2025-08-14 15:23:20,650 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00347
2025-08-14 15:23:20,650 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00348
2025-08-14 15:23:20,650 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00349
2025-08-14 15:23:20,650 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00350
2025-08-14 15:23:20,650 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00351
2025-08-14 15:23:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00352
2025-08-14 15:23:23,489 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00353
2025-08-14 15:23:23,489 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00354
2025-08-14 15:23:24,192 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00355
2025-08-14 15:23:25,143 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00356
2025-08-14 15:23:25,144 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00357
2025-08-14 15:23:25,144 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00358
2025-08-14 15:23:25,144 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00359
2025-08-14 15:23:25,144 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00360
2025-08-14 15:23:25,144 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00361
2025-08-14 15:23:25,144 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00362
2025-08-14 15:23:25,533 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00363
2025-08-14 15:23:26,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00364
2025-08-14 15:23:26,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00365
2025-08-14 15:23:26,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00366
2025-08-14 15:23:26,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00367
2025-08-14 15:23:26,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00368
2025-08-14 15:23:27,769 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00369
2025-08-14 15:23:28,326 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00370
2025-08-14 15:23:30,732 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00371
2025-08-14 15:23:30,732 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00372
2025-08-14 15:23:30,732 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00373
2025-08-14 15:23:31,177 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00374
2025-08-14 15:23:32,837 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00375
2025-08-14 15:23:32,837 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00376
2025-08-14 15:23:32,837 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00377
2025-08-14 15:23:32,837 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00378
2025-08-14 15:23:32,837 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00379
2025-08-14 15:23:32,837 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00380
2025-08-14 15:23:32,837 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00381
2025-08-14 15:23:36,260 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00382
2025-08-14 15:23:42,001 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00383
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00384
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00385
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00386
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00387
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00388
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00389
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00390
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00391
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00392
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00393
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00394
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00395
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00396
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00397
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00398
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00399
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00400
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00401
2025-08-14 15:23:42,002 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00402
2025-08-14 15:23:42,692 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00403
2025-08-14 15:23:46,097 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00404
2025-08-14 15:23:46,097 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00405
2025-08-14 15:23:46,097 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00406
2025-08-14 15:23:46,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00407
2025-08-14 15:23:46,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00408
2025-08-14 15:23:46,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00409
2025-08-14 15:23:46,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00410
2025-08-14 15:23:46,654 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00411
2025-08-14 15:23:47,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00412
2025-08-14 15:23:47,098 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00413
2025-08-14 15:23:47,993 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00414
2025-08-14 15:23:52,221 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00415
2025-08-14 15:23:52,221 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00416
2025-08-14 15:23:52,221 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00417
2025-08-14 15:23:52,221 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00418
2025-08-14 15:23:55,696 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00419
2025-08-14 15:24:00,437 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00420
2025-08-14 15:24:00,437 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00421
2025-08-14 15:24:00,437 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00422
2025-08-14 15:24:00,437 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00423
2025-08-14 15:24:00,437 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00424
2025-08-14 15:24:00,437 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00425
2025-08-14 15:24:00,437 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00426
2025-08-14 15:24:00,437 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00427
2025-08-14 15:24:00,437 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00428
2025-08-14 15:24:00,437 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00429
2025-08-14 15:24:00,437 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00430
2025-08-14 15:24:00,437 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00431
2025-08-14 15:24:00,437 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00432
2025-08-14 15:24:00,437 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00433
2025-08-14 15:24:00,437 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00434
2025-08-14 15:24:00,437 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00435
2025-08-14 15:24:01,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00436
2025-08-14 15:24:01,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00437
2025-08-14 15:24:01,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00438
2025-08-14 15:24:01,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00439
2025-08-14 15:24:01,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00440
2025-08-14 15:24:01,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00441
2025-08-14 15:24:01,643 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00442
2025-08-14 15:24:02,659 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00443
2025-08-14 15:24:06,675 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00444
2025-08-14 15:24:06,675 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00445
2025-08-14 15:24:10,571 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00446
2025-08-14 15:24:10,571 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00447
2025-08-14 15:24:10,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00448
2025-08-14 15:24:10,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00449
2025-08-14 15:24:10,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00450
2025-08-14 15:24:10,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00451
2025-08-14 15:24:10,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00452
2025-08-14 15:24:10,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00453
2025-08-14 15:24:10,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00454
2025-08-14 15:24:10,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00455
2025-08-14 15:24:10,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00456
2025-08-14 15:24:10,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00457
2025-08-14 15:24:10,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00458
2025-08-14 15:24:10,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00459
2025-08-14 15:24:10,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00460
2025-08-14 15:24:10,572 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00461
2025-08-14 15:24:12,986 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00462
2025-08-14 15:24:14,332 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00463
2025-08-14 15:24:17,705 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00464
2025-08-14 15:24:17,705 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00465
2025-08-14 15:24:17,705 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00466
2025-08-14 15:24:17,705 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00467
2025-08-14 15:24:17,705 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00468
2025-08-14 15:24:17,705 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00469
2025-08-14 15:24:17,705 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00470
2025-08-14 15:24:17,705 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00471
2025-08-14 15:24:17,705 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00472
2025-08-14 15:24:19,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00473
2025-08-14 15:24:19,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00474
2025-08-14 15:24:19,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00475
2025-08-14 15:24:19,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00476
2025-08-14 15:24:19,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00477
2025-08-14 15:24:19,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00478
2025-08-14 15:24:19,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00479
2025-08-14 15:24:19,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00480
2025-08-14 15:24:20,256 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00481
2025-08-14 15:24:20,574 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00482
2025-08-14 15:24:20,574 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00483
2025-08-14 15:24:20,574 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00484
2025-08-14 15:24:20,574 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00485
2025-08-14 15:24:21,119 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00486
2025-08-14 15:24:22,614 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00487
2025-08-14 15:24:22,615 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00488
2025-08-14 15:24:22,615 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00489
2025-08-14 15:24:22,615 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00490
2025-08-14 15:24:26,085 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00491
2025-08-14 15:24:26,085 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00492
2025-08-14 15:24:26,085 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00493
2025-08-14 15:24:26,085 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00494
2025-08-14 15:24:26,085 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00495
2025-08-14 15:24:26,085 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00496
2025-08-14 15:24:26,085 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00497
2025-08-14 15:24:30,526 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00498
2025-08-14 15:24:30,527 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00499
2025-08-14 15:24:30,527 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00500
2025-08-14 15:24:30,527 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00501
2025-08-14 15:24:30,527 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00502
2025-08-14 15:24:30,527 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00503
2025-08-14 15:24:30,527 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00504
2025-08-14 15:24:39,234 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00505
2025-08-14 15:24:39,234 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00506
2025-08-14 15:24:39,234 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00507
2025-08-14 15:24:39,234 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00508
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00509
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00510
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00511
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00512
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00513
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00514
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00515
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00516
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00517
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00518
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00519
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00520
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00521
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00522
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00523
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00524
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00525
2025-08-14 15:24:39,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00526
2025-08-14 15:24:41,711 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00527
2025-08-14 15:24:41,711 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00528
2025-08-14 15:24:41,711 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00529
2025-08-14 15:24:42,018 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00530
2025-08-14 15:24:45,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00531
2025-08-14 15:24:45,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00532
2025-08-14 15:24:45,641 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00533
2025-08-14 15:24:45,641 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00534
2025-08-14 15:24:46,620 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00535
2025-08-14 15:24:46,620 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00536
2025-08-14 15:24:46,620 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00537
2025-08-14 15:24:46,620 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00538
2025-08-14 15:24:46,620 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00539
2025-08-14 15:24:50,708 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00540
2025-08-14 15:24:50,709 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00541
2025-08-14 15:24:53,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00542
2025-08-14 15:24:53,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00543
2025-08-14 15:24:53,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00544
2025-08-14 15:24:53,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00545
2025-08-14 15:24:53,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00546
2025-08-14 15:24:53,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00547
2025-08-14 15:24:53,074 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00548
2025-08-14 15:24:53,074 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00549
2025-08-14 15:24:53,074 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00550
2025-08-14 15:24:53,074 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00551
2025-08-14 15:24:53,074 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00552
2025-08-14 15:24:53,375 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00553
2025-08-14 15:24:54,376 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00554
2025-08-14 15:24:54,376 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00555
2025-08-14 15:24:54,376 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00556
2025-08-14 15:24:54,885 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00557
2025-08-14 15:24:54,885 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00558
2025-08-14 15:24:56,551 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00559
2025-08-14 15:24:56,551 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00560
2025-08-14 15:24:57,431 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00561
2025-08-14 15:24:59,135 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00562
2025-08-14 15:24:59,135 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00563
2025-08-14 15:24:59,135 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00564
2025-08-14 15:24:59,135 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00565
2025-08-14 15:24:59,135 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00566
2025-08-14 15:24:59,511 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00567
2025-08-14 15:24:59,512 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00568
2025-08-14 15:25:03,206 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00569
2025-08-14 15:25:03,206 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00570
2025-08-14 15:25:03,968 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00571
2025-08-14 15:25:03,968 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00572
2025-08-14 15:25:03,968 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00573
2025-08-14 15:25:04,603 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00574
2025-08-14 15:25:04,603 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00575
2025-08-14 15:25:04,603 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00576
2025-08-14 15:25:05,339 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00577
2025-08-14 15:25:05,339 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00578
2025-08-14 15:25:06,214 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00579
2025-08-14 15:25:06,435 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00580
2025-08-14 15:25:10,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00581
2025-08-14 15:25:10,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00582
2025-08-14 15:25:10,590 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00583
2025-08-14 15:25:11,312 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00584
2025-08-14 15:25:11,312 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00585
2025-08-14 15:25:11,313 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00586
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00587
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00588
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00589
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00590
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00591
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00592
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00593
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00594
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00595
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00596
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00597
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00598
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00599
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00600
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00601
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00602
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00603
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00604
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00605
2025-08-14 15:25:18,076 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00606
2025-08-14 15:25:18,831 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00607
2025-08-14 15:25:18,831 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00608
2025-08-14 15:25:18,831 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00609
2025-08-14 15:25:21,405 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00610
2025-08-14 15:25:21,406 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00611
2025-08-14 15:25:24,576 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00612
2025-08-14 15:25:24,577 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00613
2025-08-14 15:25:24,577 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00614
2025-08-14 15:25:24,577 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00615
2025-08-14 15:25:25,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00616
2025-08-14 15:25:25,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00617
2025-08-14 15:25:25,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00618
2025-08-14 15:25:25,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00619
2025-08-14 15:25:25,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00620
2025-08-14 15:25:25,598 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00621
2025-08-14 15:25:25,598 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00622
2025-08-14 15:25:27,419 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00623
2025-08-14 15:25:27,419 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00624
2025-08-14 15:25:27,419 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00625
2025-08-14 15:25:29,942 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00626
2025-08-14 15:25:29,942 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00627
2025-08-14 15:25:29,942 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00628
2025-08-14 15:25:29,942 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00629
2025-08-14 15:25:29,942 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00630
2025-08-14 15:25:30,827 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00631
2025-08-14 15:25:30,827 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00632
2025-08-14 15:25:31,108 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00633
2025-08-14 15:25:31,959 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00634
2025-08-14 15:25:35,986 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00635
2025-08-14 15:25:35,986 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00636
2025-08-14 15:25:35,986 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00637
2025-08-14 15:25:35,986 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00638
2025-08-14 15:25:35,986 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00639
2025-08-14 15:25:35,986 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00640
2025-08-14 15:25:35,987 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00641
2025-08-14 15:25:35,987 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00642
2025-08-14 15:25:35,987 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00643
2025-08-14 15:25:35,987 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00644
2025-08-14 15:25:38,808 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00645
2025-08-14 15:25:38,809 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00646
2025-08-14 15:25:38,809 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00647
2025-08-14 15:25:38,809 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00648
2025-08-14 15:25:38,809 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00649
2025-08-14 15:25:39,020 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00650
2025-08-14 15:25:39,020 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00651
2025-08-14 15:25:42,557 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00652
2025-08-14 15:25:42,557 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00653
2025-08-14 15:25:42,557 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00654
2025-08-14 15:25:50,998 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00655
2025-08-14 15:25:50,998 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00656
2025-08-14 15:25:50,998 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00657
2025-08-14 15:25:50,998 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00658
2025-08-14 15:25:50,998 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00659
2025-08-14 15:25:50,998 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00660
2025-08-14 15:25:50,998 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00661
2025-08-14 15:25:50,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00662
2025-08-14 15:25:50,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00663
2025-08-14 15:25:50,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00664
2025-08-14 15:25:53,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00665
2025-08-14 15:25:53,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00666
2025-08-14 15:25:53,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00667
2025-08-14 15:25:53,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00668
2025-08-14 15:25:53,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00669
2025-08-14 15:25:53,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00670
2025-08-14 15:25:53,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00671
2025-08-14 15:25:53,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00672
2025-08-14 15:25:53,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00673
2025-08-14 15:25:53,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00674
2025-08-14 15:25:53,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00675
2025-08-14 15:25:53,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00676
2025-08-14 15:25:53,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00677
2025-08-14 15:25:53,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00678
2025-08-14 15:25:53,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00679
2025-08-14 15:25:55,028 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00680
2025-08-14 15:25:55,028 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00681
2025-08-14 15:25:56,527 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00682
2025-08-14 15:25:56,527 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00683
2025-08-14 15:25:56,527 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00684
2025-08-14 15:25:56,527 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00685
2025-08-14 15:26:00,211 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00686
2025-08-14 15:26:00,211 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00687
2025-08-14 15:26:00,211 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00688
2025-08-14 15:26:00,242 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00689
2025-08-14 15:26:00,242 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00690
2025-08-14 15:26:00,288 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00691
2025-08-14 15:26:00,288 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00692
2025-08-14 15:26:00,288 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00693
2025-08-14 15:26:00,288 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00694
2025-08-14 15:26:00,288 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00695
2025-08-14 15:26:00,670 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00696
2025-08-14 15:26:02,715 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00697
2025-08-14 15:26:03,160 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00698
2025-08-14 15:26:03,160 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00699
2025-08-14 15:26:03,160 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00700
2025-08-14 15:26:03,160 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00701
2025-08-14 15:26:05,237 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00702
2025-08-14 15:26:05,837 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00703
2025-08-14 15:26:05,837 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00704
2025-08-14 15:26:05,838 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00705
2025-08-14 15:26:05,838 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00706
2025-08-14 15:26:08,169 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00707
2025-08-14 15:26:08,169 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00708
2025-08-14 15:26:08,169 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00709
2025-08-14 15:26:08,169 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00710
2025-08-14 15:26:08,169 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00711
2025-08-14 15:26:08,169 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00712
2025-08-14 15:26:11,082 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00713
2025-08-14 15:26:11,082 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00714
2025-08-14 15:26:11,082 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00715
2025-08-14 15:26:11,082 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00716
2025-08-14 15:26:12,196 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00717
2025-08-14 15:26:12,196 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00718
2025-08-14 15:26:14,200 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00719
2025-08-14 15:26:14,200 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00720
2025-08-14 15:26:14,200 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00721
2025-08-14 15:26:14,200 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00722
2025-08-14 15:26:14,200 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00723
2025-08-14 15:26:14,200 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00724
2025-08-14 15:26:14,200 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00725
2025-08-14 15:26:14,200 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00726
2025-08-14 15:26:14,200 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00727
2025-08-14 15:26:14,666 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00728
2025-08-14 15:26:14,667 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00729
2025-08-14 15:26:15,359 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00730
2025-08-14 15:26:15,360 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00731
2025-08-14 15:26:15,360 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00732
2025-08-14 15:26:15,360 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00733
2025-08-14 15:26:19,309 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00734
2025-08-14 15:26:19,309 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00735
2025-08-14 15:26:19,743 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00736
2025-08-14 15:26:19,743 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00737
2025-08-14 15:26:19,743 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00738
2025-08-14 15:26:19,743 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00739
2025-08-14 15:26:19,743 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00740
2025-08-14 15:26:21,698 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00741
2025-08-14 15:26:21,698 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00742
2025-08-14 15:26:21,698 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00743
2025-08-14 15:26:27,896 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00744
2025-08-14 15:26:27,896 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00745
2025-08-14 15:26:27,896 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00746
2025-08-14 15:26:27,896 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00747
2025-08-14 15:26:27,896 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00748
2025-08-14 15:26:27,896 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00749
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00750
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00751
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00752
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00753
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00754
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00755
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00756
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00757
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00758
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00759
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00760
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00761
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00762
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00763
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00764
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00765
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00766
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00767
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00768
2025-08-14 15:26:36,974 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00769
2025-08-14 15:26:36,975 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00770
2025-08-14 15:26:36,975 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00771
2025-08-14 15:26:36,975 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00772
2025-08-14 15:26:36,975 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00773
2025-08-14 15:26:37,349 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00774
2025-08-14 15:26:38,501 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00775
2025-08-14 15:26:38,535 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00776
2025-08-14 15:26:38,535 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00777
2025-08-14 15:26:38,535 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00778
2025-08-14 15:26:38,535 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00779
2025-08-14 15:26:40,689 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00780
2025-08-14 15:26:40,689 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00781
2025-08-14 15:26:44,201 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00782
2025-08-14 15:26:44,202 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00783
2025-08-14 15:26:44,202 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00784
2025-08-14 15:26:44,202 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00785
2025-08-14 15:26:44,202 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00786
2025-08-14 15:26:44,202 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00787
2025-08-14 15:26:44,202 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00788
2025-08-14 15:26:45,461 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00789
2025-08-14 15:26:45,461 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00790
2025-08-14 15:26:45,461 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00791
2025-08-14 15:26:45,632 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00792
2025-08-14 15:26:45,632 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00793
2025-08-14 15:26:46,766 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00794
2025-08-14 15:26:48,754 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00795
2025-08-14 15:26:50,218 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00796
2025-08-14 15:26:50,218 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00797
2025-08-14 15:26:50,218 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00798
2025-08-14 15:26:50,218 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00799
2025-08-14 15:26:50,218 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00800
2025-08-14 15:26:51,181 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00801
2025-08-14 15:26:51,182 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00802
2025-08-14 15:26:51,182 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00803
2025-08-14 15:26:51,182 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00804
2025-08-14 15:26:52,959 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00805
2025-08-14 15:26:52,959 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00806
2025-08-14 15:26:52,959 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00807
2025-08-14 15:26:53,940 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00808
2025-08-14 15:26:53,941 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00809
2025-08-14 15:26:53,941 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00810
2025-08-14 15:26:53,941 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00811
2025-08-14 15:26:54,413 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00812
2025-08-14 15:26:56,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00813
2025-08-14 15:26:56,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00814
2025-08-14 15:26:56,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00815
2025-08-14 15:26:56,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00816
2025-08-14 15:26:56,559 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00817
2025-08-14 15:26:57,740 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00818
2025-08-14 15:26:57,740 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00819
2025-08-14 15:26:57,740 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00820
2025-08-14 15:26:58,392 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00821
2025-08-14 15:26:58,392 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00822
2025-08-14 15:27:01,085 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00823
2025-08-14 15:27:01,086 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00824
2025-08-14 15:27:01,086 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00825
2025-08-14 15:27:01,086 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00826
2025-08-14 15:27:01,513 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00827
2025-08-14 15:27:02,686 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00828
2025-08-14 15:27:02,687 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00829
2025-08-14 15:27:05,614 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00830
2025-08-14 15:27:06,618 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00831
2025-08-14 15:27:06,618 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00832
2025-08-14 15:27:06,618 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00833
2025-08-14 15:27:06,618 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00834
2025-08-14 15:27:06,618 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00835
2025-08-14 15:27:06,618 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00836
2025-08-14 15:27:06,618 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00837
2025-08-14 15:27:06,774 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00838
2025-08-14 15:27:06,774 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00839
2025-08-14 15:27:06,774 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00840
2025-08-14 15:27:07,580 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00841
2025-08-14 15:27:07,580 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00842
2025-08-14 15:27:07,912 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00843
2025-08-14 15:27:12,435 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00844
2025-08-14 15:27:12,435 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00845
2025-08-14 15:27:12,435 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00846
2025-08-14 15:27:12,435 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00847
2025-08-14 15:27:12,435 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00848
2025-08-14 15:27:12,435 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00849
2025-08-14 15:27:12,435 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00850
2025-08-14 15:27:13,565 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00851
2025-08-14 15:27:13,565 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00852
2025-08-14 15:27:15,815 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00853
2025-08-14 15:27:15,816 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00854
2025-08-14 15:27:15,816 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00855
2025-08-14 15:27:15,816 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00856
2025-08-14 15:27:15,816 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00857
2025-08-14 15:27:16,008 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00858
2025-08-14 15:27:16,009 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00859
2025-08-14 15:27:20,160 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00860
2025-08-14 15:27:20,161 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00861
2025-08-14 15:27:20,161 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00862
2025-08-14 15:27:20,161 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00863
2025-08-14 15:27:20,161 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00864
2025-08-14 15:27:20,161 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00865
2025-08-14 15:27:20,161 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00866
2025-08-14 15:27:20,161 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00867
2025-08-14 15:27:23,951 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00868
2025-08-14 15:27:23,951 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00869
2025-08-14 15:27:24,598 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00870
2025-08-14 15:27:24,598 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00871
2025-08-14 15:27:24,598 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00872
2025-08-14 15:27:24,598 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00873
2025-08-14 15:27:25,317 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00874
2025-08-14 15:27:25,317 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00875
2025-08-14 15:27:25,317 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00876
2025-08-14 15:27:27,118 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00877
2025-08-14 15:27:27,118 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00878
2025-08-14 15:27:27,118 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00879
2025-08-14 15:27:27,118 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00880
2025-08-14 15:27:27,118 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00881
2025-08-14 15:27:27,534 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00882
2025-08-14 15:27:29,304 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00883
2025-08-14 15:27:29,304 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00884
2025-08-14 15:27:35,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00885
2025-08-14 15:27:35,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00886
2025-08-14 15:27:35,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00887
2025-08-14 15:27:35,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00888
2025-08-14 15:27:35,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00889
2025-08-14 15:27:35,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00890
2025-08-14 15:27:35,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00891
2025-08-14 15:27:35,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00892
2025-08-14 15:27:35,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00893
2025-08-14 15:27:35,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00894
2025-08-14 15:27:35,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00895
2025-08-14 15:27:35,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00896
2025-08-14 15:27:35,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00897
2025-08-14 15:27:35,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00898
2025-08-14 15:27:35,568 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00899
2025-08-14 15:27:35,819 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00900
2025-08-14 15:27:35,819 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00901
2025-08-14 15:27:35,819 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00902
2025-08-14 15:27:35,900 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00903
2025-08-14 15:27:45,124 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00904
2025-08-14 15:27:45,124 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00905
2025-08-14 15:27:45,124 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00906
2025-08-14 15:27:45,124 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00907
2025-08-14 15:27:45,124 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00908
2025-08-14 15:27:45,124 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00909
2025-08-14 15:27:45,124 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00910
2025-08-14 15:27:45,124 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00911
2025-08-14 15:27:45,124 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00912
2025-08-14 15:27:45,124 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00913
2025-08-14 15:27:45,124 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00914
2025-08-14 15:27:45,380 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00915
2025-08-14 15:27:47,602 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00916
2025-08-14 15:27:47,602 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00917
2025-08-14 15:27:47,602 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00918
2025-08-14 15:27:49,660 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00919
2025-08-14 15:27:49,660 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00920
2025-08-14 15:27:50,993 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00921
2025-08-14 15:27:50,993 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00922
2025-08-14 15:27:50,993 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00923
2025-08-14 15:27:50,993 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00924
2025-08-14 15:27:50,993 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00925
2025-08-14 15:27:50,993 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00926
2025-08-14 15:27:50,993 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00927
2025-08-14 15:27:50,993 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00928
2025-08-14 15:27:50,993 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00929
2025-08-14 15:27:50,993 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00930
2025-08-14 15:27:52,254 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00931
2025-08-14 15:27:52,254 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00932
2025-08-14 15:27:52,254 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00933
2025-08-14 15:27:52,527 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00934
2025-08-14 15:27:54,396 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00935
2025-08-14 15:27:54,396 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00936
2025-08-14 15:27:54,396 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00937
2025-08-14 15:27:54,396 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00938
2025-08-14 15:27:54,396 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00939
2025-08-14 15:27:54,396 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00940
2025-08-14 15:27:56,765 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00941
2025-08-14 15:27:56,766 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00942
2025-08-14 15:28:02,569 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00943
2025-08-14 15:28:02,570 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00944
2025-08-14 15:28:02,570 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00945
2025-08-14 15:28:03,244 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00946
2025-08-14 15:28:03,245 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00947
2025-08-14 15:28:03,245 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00948
2025-08-14 15:28:03,245 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00949
2025-08-14 15:28:03,245 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00950
2025-08-14 15:28:03,245 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00951
2025-08-14 15:28:03,245 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00952
2025-08-14 15:28:03,245 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00953
2025-08-14 15:28:03,245 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00954
2025-08-14 15:28:03,245 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00955
2025-08-14 15:28:03,245 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00956
2025-08-14 15:28:04,522 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00957
2025-08-14 15:28:04,522 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00958
2025-08-14 15:28:04,522 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00959
2025-08-14 15:28:04,838 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00960
2025-08-14 15:28:11,031 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00961
2025-08-14 15:28:11,031 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00962
2025-08-14 15:28:11,031 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00963
2025-08-14 15:28:11,031 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00964
2025-08-14 15:28:11,031 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00965
2025-08-14 15:28:18,138 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00966
2025-08-14 15:28:18,139 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00967
2025-08-14 15:28:18,139 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00968
2025-08-14 15:28:18,139 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00969
2025-08-14 15:28:18,139 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00970
2025-08-14 15:28:18,139 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00971
2025-08-14 15:28:18,139 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00972
2025-08-14 15:28:18,139 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00973
2025-08-14 15:28:18,139 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00974
2025-08-14 15:28:18,139 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00975
2025-08-14 15:28:18,139 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00976
2025-08-14 15:28:18,139 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00977
2025-08-14 15:28:18,139 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00978
2025-08-14 15:28:18,139 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00979
2025-08-14 15:28:18,696 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00980
2025-08-14 15:28:18,696 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00981
2025-08-14 15:28:18,696 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00982
2025-08-14 15:28:18,696 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00983
2025-08-14 15:28:19,968 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00984
2025-08-14 15:28:19,968 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00985
2025-08-14 15:28:20,304 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00986
2025-08-14 15:28:26,094 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00987
2025-08-14 15:28:29,637 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00988
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00989
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00990
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00991
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00992
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00993
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00994
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00995
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00996
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00997
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00998
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest00999
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01000
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01001
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01002
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01003
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01004
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01005
2025-08-14 15:28:29,638 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01006
2025-08-14 15:28:30,519 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01007
2025-08-14 15:28:30,519 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01008
2025-08-14 15:28:30,519 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01009
2025-08-14 15:28:33,780 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01010
2025-08-14 15:28:33,780 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01011
2025-08-14 15:28:38,113 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01012
2025-08-14 15:28:38,113 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01013
2025-08-14 15:28:38,113 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01014
2025-08-14 15:28:38,113 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01015
2025-08-14 15:28:38,113 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01016
2025-08-14 15:28:38,113 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01017
2025-08-14 15:28:38,113 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01018
2025-08-14 15:28:38,113 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01019
2025-08-14 15:28:38,113 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01020
2025-08-14 15:28:38,113 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01021
2025-08-14 15:28:38,156 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01022
2025-08-14 15:28:38,156 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01023
2025-08-14 15:28:38,508 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01024
2025-08-14 15:28:38,509 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01025
2025-08-14 15:28:38,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01026
2025-08-14 15:28:38,884 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01027
2025-08-14 15:28:41,042 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01028
2025-08-14 15:28:41,042 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01029
2025-08-14 15:28:41,042 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01030
2025-08-14 15:28:41,349 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01031
2025-08-14 15:28:41,349 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01032
2025-08-14 15:28:41,535 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01033
2025-08-14 15:28:41,535 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01034
2025-08-14 15:28:41,535 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01035
2025-08-14 15:28:41,536 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01036
2025-08-14 15:28:48,468 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01037
2025-08-14 15:28:48,468 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01038
2025-08-14 15:28:48,468 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01039
2025-08-14 15:28:48,468 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01040
2025-08-14 15:28:48,468 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01041
2025-08-14 15:28:48,468 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01042
2025-08-14 15:28:48,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01043
2025-08-14 15:28:48,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01044
2025-08-14 15:28:48,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01045
2025-08-14 15:28:48,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01046
2025-08-14 15:28:48,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01047
2025-08-14 15:28:51,408 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01048
2025-08-14 15:28:51,408 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01049
2025-08-14 15:28:51,409 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01050
2025-08-14 15:28:51,409 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01051
2025-08-14 15:28:51,409 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01052
2025-08-14 15:28:51,409 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01053
2025-08-14 15:28:51,409 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01054
2025-08-14 15:28:51,409 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01055
2025-08-14 15:28:51,424 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01056
2025-08-14 15:28:54,248 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01057
2025-08-14 15:28:54,248 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01058
2025-08-14 15:28:54,248 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01059
2025-08-14 15:28:54,248 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01060
2025-08-14 15:28:54,248 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01061
2025-08-14 15:28:55,580 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01062
2025-08-14 15:28:55,820 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01063
2025-08-14 15:28:55,820 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01064
2025-08-14 15:28:57,167 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01065
2025-08-14 15:28:57,167 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01066
2025-08-14 15:28:57,167 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01067
2025-08-14 15:28:57,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01068
2025-08-14 15:28:58,915 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01069
2025-08-14 15:28:59,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01070
2025-08-14 15:28:59,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01071
2025-08-14 15:29:00,511 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01072
2025-08-14 15:29:01,675 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01073
2025-08-14 15:29:01,675 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01074
2025-08-14 15:29:02,043 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01075
2025-08-14 15:29:07,728 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01076
2025-08-14 15:29:07,728 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01077
2025-08-14 15:29:08,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01078
2025-08-14 15:29:08,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01079
2025-08-14 15:29:08,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01080
2025-08-14 15:29:08,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01081
2025-08-14 15:29:08,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01082
2025-08-14 15:29:08,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01083
2025-08-14 15:29:08,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01084
2025-08-14 15:29:08,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01085
2025-08-14 15:29:08,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01086
2025-08-14 15:29:08,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01087
2025-08-14 15:29:08,574 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01088
2025-08-14 15:29:08,574 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01089
2025-08-14 15:29:08,574 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01090
2025-08-14 15:29:08,574 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01091
2025-08-14 15:29:08,719 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01092
2025-08-14 15:29:08,719 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01093
2025-08-14 15:29:08,859 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01094
2025-08-14 15:29:10,901 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01095
2025-08-14 15:29:10,901 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01096
2025-08-14 15:29:10,901 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01097
2025-08-14 15:29:11,282 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01098
2025-08-14 15:29:12,524 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01099
2025-08-14 15:29:14,778 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01100
2025-08-14 15:29:14,778 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01101
2025-08-14 15:29:14,778 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01102
2025-08-14 15:29:14,779 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01103
2025-08-14 15:29:14,779 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01104
2025-08-14 15:29:15,149 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01105
2025-08-14 15:29:15,149 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01106
2025-08-14 15:29:16,413 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01107
2025-08-14 15:29:17,164 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01108
2025-08-14 15:29:17,732 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01109
2025-08-14 15:29:17,732 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01110
2025-08-14 15:29:17,996 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01111
2025-08-14 15:29:17,996 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01112
2025-08-14 15:29:17,997 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01113
2025-08-14 15:29:18,845 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01114
2025-08-14 15:29:18,845 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01115
2025-08-14 15:29:21,306 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01116
2025-08-14 15:29:21,306 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01117
2025-08-14 15:29:21,306 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01118
2025-08-14 15:29:21,327 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01119
2025-08-14 15:29:25,019 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01120
2025-08-14 15:29:25,019 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01121
2025-08-14 15:29:28,224 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01122
2025-08-14 15:29:28,224 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01123
2025-08-14 15:29:28,224 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01124
2025-08-14 15:29:28,224 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01125
2025-08-14 15:29:28,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01126
2025-08-14 15:29:28,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01127
2025-08-14 15:29:28,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01128
2025-08-14 15:29:28,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01129
2025-08-14 15:29:28,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01130
2025-08-14 15:29:28,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01131
2025-08-14 15:29:28,225 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01132
2025-08-14 15:29:28,459 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01133
2025-08-14 15:29:30,012 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01134
2025-08-14 15:29:30,551 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01135
2025-08-14 15:29:30,551 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01136
2025-08-14 15:29:36,529 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01137
2025-08-14 15:29:36,529 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01138
2025-08-14 15:29:39,035 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01139
2025-08-14 15:29:39,035 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01140
2025-08-14 15:29:39,035 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01141
2025-08-14 15:29:39,035 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01142
2025-08-14 15:29:39,035 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01143
2025-08-14 15:29:39,035 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01144
2025-08-14 15:29:39,035 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01145
2025-08-14 15:29:39,035 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01146
2025-08-14 15:29:39,035 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01147
2025-08-14 15:29:39,035 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01148
2025-08-14 15:29:39,035 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01149
2025-08-14 15:29:39,035 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01150
2025-08-14 15:29:40,203 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01151
2025-08-14 15:29:41,062 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01152
2025-08-14 15:29:41,500 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01153
2025-08-14 15:29:41,500 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01154
2025-08-14 15:29:41,500 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01155
2025-08-14 15:29:41,500 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01156
2025-08-14 15:29:41,695 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01157
2025-08-14 15:29:41,695 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01158
2025-08-14 15:29:43,348 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01159
2025-08-14 15:29:43,348 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01160
2025-08-14 15:29:43,348 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01161
2025-08-14 15:29:44,394 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01162
2025-08-14 15:29:44,395 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01163
2025-08-14 15:29:47,486 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01164
2025-08-14 15:29:50,199 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01165
2025-08-14 15:29:50,199 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01166
2025-08-14 15:29:50,199 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01167
2025-08-14 15:29:50,199 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01168
2025-08-14 15:29:50,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01169
2025-08-14 15:29:50,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01170
2025-08-14 15:29:50,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01171
2025-08-14 15:29:50,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01172
2025-08-14 15:29:50,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01173
2025-08-14 15:29:50,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01174
2025-08-14 15:29:50,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01175
2025-08-14 15:29:50,537 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01176
2025-08-14 15:29:51,213 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01177
2025-08-14 15:29:51,213 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01178
2025-08-14 15:29:51,376 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01179
2025-08-14 15:29:51,376 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01180
2025-08-14 15:29:51,667 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01181
2025-08-14 15:29:51,897 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01182
2025-08-14 15:29:53,302 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01183
2025-08-14 15:29:53,302 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01184
2025-08-14 15:29:56,050 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01185
2025-08-14 15:29:56,051 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01186
2025-08-14 15:29:59,165 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01187
2025-08-14 15:29:59,165 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01188
2025-08-14 15:29:59,165 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01189
2025-08-14 15:29:59,165 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01190
2025-08-14 15:29:59,165 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01191
2025-08-14 15:29:59,165 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01192
2025-08-14 15:29:59,165 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01193
2025-08-14 15:29:59,165 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01194
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01195
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01196
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01197
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01198
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01199
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01200
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01201
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01202
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01203
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01204
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01205
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01206
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01207
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01208
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01209
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01210
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01211
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01212
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01213
2025-08-14 15:30:11,737 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01214
2025-08-14 15:30:11,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01215
2025-08-14 15:30:11,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01216
2025-08-14 15:30:11,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01217
2025-08-14 15:30:11,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01218
2025-08-14 15:30:11,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01219
2025-08-14 15:30:11,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01220
2025-08-14 15:30:11,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01221
2025-08-14 15:30:11,738 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01222
2025-08-14 15:30:13,385 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01223
2025-08-14 15:30:13,385 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01224
2025-08-14 15:30:13,785 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01225
2025-08-14 15:30:16,290 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01226
2025-08-14 15:30:18,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01227
2025-08-14 15:30:18,308 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01228
2025-08-14 15:30:18,308 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01229
2025-08-14 15:30:18,308 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01230
2025-08-14 15:30:18,308 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01231
2025-08-14 15:30:18,308 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01232
2025-08-14 15:30:18,308 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01233
2025-08-14 15:30:18,415 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01234
2025-08-14 15:30:18,415 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01235
2025-08-14 15:30:18,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01236
2025-08-14 15:30:18,635 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01237
2025-08-14 15:30:19,080 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01238
2025-08-14 15:30:22,068 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01239
2025-08-14 15:30:22,068 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01240
2025-08-14 15:30:22,068 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01241
2025-08-14 15:30:22,068 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01242
2025-08-14 15:30:22,068 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01243
2025-08-14 15:30:26,061 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01244
2025-08-14 15:30:26,061 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01245
2025-08-14 15:30:27,024 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01246
2025-08-14 15:30:27,024 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01247
2025-08-14 15:30:27,024 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01248
2025-08-14 15:30:27,024 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01249
2025-08-14 15:30:29,000 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01250
2025-08-14 15:30:29,000 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01251
2025-08-14 15:30:29,000 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01252
2025-08-14 15:30:34,563 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01253
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01254
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01255
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01256
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01257
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01258
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01259
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01260
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01261
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01262
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01263
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01264
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01265
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01266
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01267
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01268
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01269
2025-08-14 15:30:34,564 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01270
2025-08-14 15:30:35,471 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01271
2025-08-14 15:30:35,471 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01272
2025-08-14 15:30:35,471 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01273
2025-08-14 15:30:35,627 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01274
2025-08-14 15:30:35,627 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01275
2025-08-14 15:30:36,249 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01276
2025-08-14 15:30:38,904 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01277
2025-08-14 15:30:39,118 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01278
2025-08-14 15:30:39,118 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01279
2025-08-14 15:30:40,097 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01280
2025-08-14 15:30:40,097 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01281
2025-08-14 15:30:41,509 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01282
2025-08-14 15:30:41,510 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01283
2025-08-14 15:30:41,510 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01284
2025-08-14 15:30:41,510 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01285
2025-08-14 15:30:41,993 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01286
2025-08-14 15:30:43,707 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01287
2025-08-14 15:30:43,707 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01288
2025-08-14 15:30:44,305 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01289
2025-08-14 15:30:44,841 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01290
2025-08-14 15:30:44,856 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01291
2025-08-14 15:30:45,345 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01292
2025-08-14 15:30:45,345 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01293
2025-08-14 15:30:48,579 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01294
2025-08-14 15:30:48,579 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01295
2025-08-14 15:30:59,862 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01296
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01297
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01298
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01299
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01300
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01301
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01302
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01303
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01304
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01305
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01306
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01307
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01308
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01309
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01310
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01311
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01312
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01313
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01314
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01315
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01316
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01317
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01318
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01319
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01320
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01321
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01322
2025-08-14 15:30:59,863 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01323
2025-08-14 15:31:00,547 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01324
2025-08-14 15:31:00,547 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01325
2025-08-14 15:31:00,548 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01326
2025-08-14 15:31:00,548 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01327
2025-08-14 15:31:01,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01328
2025-08-14 15:31:01,900 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01329
2025-08-14 15:31:01,900 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01330
2025-08-14 15:31:02,173 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01331
2025-08-14 15:31:02,905 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01332
2025-08-14 15:31:05,185 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01333
2025-08-14 15:31:06,857 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01334
2025-08-14 15:31:06,858 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01335
2025-08-14 15:31:06,858 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01336
2025-08-14 15:31:14,540 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01337
2025-08-14 15:31:14,540 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01338
2025-08-14 15:31:14,540 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01339
2025-08-14 15:31:14,540 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01340
2025-08-14 15:31:14,540 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01341
2025-08-14 15:31:14,540 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01342
2025-08-14 15:31:14,540 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01343
2025-08-14 15:31:14,540 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01344
2025-08-14 15:31:14,540 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01345
2025-08-14 15:31:14,540 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01346
2025-08-14 15:31:14,540 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01347
2025-08-14 15:31:14,540 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01348
2025-08-14 15:31:14,541 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01349
2025-08-14 15:31:14,541 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01350
2025-08-14 15:31:14,541 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01351
2025-08-14 15:31:14,541 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01352
2025-08-14 15:31:14,541 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01353
2025-08-14 15:31:14,541 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01354
2025-08-14 15:31:16,314 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01355
2025-08-14 15:31:16,314 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01356
2025-08-14 15:31:16,314 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01357
2025-08-14 15:31:16,314 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01358
2025-08-14 15:31:19,957 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01359
2025-08-14 15:31:19,957 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01360
2025-08-14 15:31:19,957 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01361
2025-08-14 15:31:19,957 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01362
2025-08-14 15:31:19,957 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01363
2025-08-14 15:31:19,957 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01364
2025-08-14 15:31:19,957 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01365
2025-08-14 15:31:19,957 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01366
2025-08-14 15:31:19,957 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01367
2025-08-14 15:31:19,957 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01368
2025-08-14 15:31:22,640 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01369
2025-08-14 15:31:22,958 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01370
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01371
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01372
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01373
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01374
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01375
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01376
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01377
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01378
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01379
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01380
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01381
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01382
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01383
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01384
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01385
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01386
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01387
2025-08-14 15:31:30,883 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01388
2025-08-14 15:31:32,939 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01389
2025-08-14 15:31:32,939 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01390
2025-08-14 15:31:32,940 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01391
2025-08-14 15:31:32,940 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01392
2025-08-14 15:31:33,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01393
2025-08-14 15:31:33,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01394
2025-08-14 15:31:33,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01395
2025-08-14 15:31:33,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01396
2025-08-14 15:31:33,876 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01397
2025-08-14 15:31:34,580 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01398
2025-08-14 15:31:37,919 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01399
2025-08-14 15:31:39,822 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01400
2025-08-14 15:31:39,822 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01401
2025-08-14 15:31:39,822 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01402
2025-08-14 15:31:39,822 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01403
2025-08-14 15:31:39,822 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01404
2025-08-14 15:31:39,822 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01405
2025-08-14 15:31:39,822 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01406
2025-08-14 15:31:39,822 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01407
2025-08-14 15:31:39,822 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01408
2025-08-14 15:31:39,822 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01409
2025-08-14 15:31:41,270 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01410
2025-08-14 15:31:43,050 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01411
2025-08-14 15:31:43,050 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01412
2025-08-14 15:31:44,673 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01413
2025-08-14 15:31:44,673 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01414
2025-08-14 15:31:44,673 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01415
2025-08-14 15:31:45,752 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01416
2025-08-14 15:31:45,752 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01417
2025-08-14 15:31:46,153 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01418
2025-08-14 15:31:46,153 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01419
2025-08-14 15:31:46,153 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01420
2025-08-14 15:31:46,154 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01421
2025-08-14 15:31:46,154 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01422
2025-08-14 15:31:46,154 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01423
2025-08-14 15:31:47,715 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01424
2025-08-14 15:31:47,715 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01425
2025-08-14 15:31:47,715 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01426
2025-08-14 15:31:48,347 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01427
2025-08-14 15:31:49,147 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01428
2025-08-14 15:31:49,214 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01429
2025-08-14 15:31:51,720 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01430
2025-08-14 15:31:51,721 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01431
2025-08-14 15:31:51,721 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01432
2025-08-14 15:31:51,721 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01433
2025-08-14 15:31:51,721 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01434
2025-08-14 15:31:51,721 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01435
2025-08-14 15:31:58,909 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01436
2025-08-14 15:31:58,909 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01437
2025-08-14 15:31:58,909 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01438
2025-08-14 15:31:58,909 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01439
2025-08-14 15:31:58,909 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01440
2025-08-14 15:31:58,909 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01441
2025-08-14 15:31:58,909 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01442
2025-08-14 15:31:58,909 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01443
2025-08-14 15:31:58,909 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01444
2025-08-14 15:31:58,909 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01445
2025-08-14 15:31:58,909 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01446
2025-08-14 15:31:58,909 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01447
2025-08-14 15:31:58,909 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01448
2025-08-14 15:31:59,458 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01449
2025-08-14 15:31:59,681 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01450
2025-08-14 15:31:59,749 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01451
2025-08-14 15:32:00,371 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01452
2025-08-14 15:32:00,371 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01453
2025-08-14 15:32:00,371 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01454
2025-08-14 15:32:01,815 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01455
2025-08-14 15:32:02,853 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01456
2025-08-14 15:32:02,853 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01457
2025-08-14 15:32:07,343 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01458
2025-08-14 15:32:07,344 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01459
2025-08-14 15:32:07,344 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01460
2025-08-14 15:32:07,344 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01461
2025-08-14 15:32:07,344 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01462
2025-08-14 15:32:07,344 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01463
2025-08-14 15:32:07,344 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01464
2025-08-14 15:32:07,344 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01465
2025-08-14 15:32:07,344 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01466
2025-08-14 15:32:07,344 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01467
2025-08-14 15:32:08,705 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01468
2025-08-14 15:32:08,705 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01469
2025-08-14 15:32:08,705 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01470
2025-08-14 15:32:08,705 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01471
2025-08-14 15:32:10,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01472
2025-08-14 15:32:10,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01473
2025-08-14 15:32:10,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01474
2025-08-14 15:32:10,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01475
2025-08-14 15:32:10,604 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01476
2025-08-14 15:32:10,930 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01477
2025-08-14 15:32:11,578 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01478
2025-08-14 15:32:11,760 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01479
2025-08-14 15:32:13,063 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01480
2025-08-14 15:32:14,880 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01481
2025-08-14 15:32:14,880 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01482
2025-08-14 15:32:15,134 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01483
2025-08-14 15:32:15,134 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01484
2025-08-14 15:32:17,232 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01485
2025-08-14 15:32:17,233 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01486
2025-08-14 15:32:17,233 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01487
2025-08-14 15:32:17,233 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01488
2025-08-14 15:32:17,233 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01489
2025-08-14 15:32:17,233 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01490
2025-08-14 15:32:18,348 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01491
2025-08-14 15:32:18,348 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01492
2025-08-14 15:32:18,348 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01493
2025-08-14 15:32:18,723 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01494
2025-08-14 15:32:18,753 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01495
2025-08-14 15:32:18,753 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01496
2025-08-14 15:32:20,190 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01497
2025-08-14 15:32:21,198 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01498
2025-08-14 15:32:21,198 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01499
2025-08-14 15:32:21,198 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01500
2025-08-14 15:32:21,198 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01501
2025-08-14 15:32:21,198 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01502
2025-08-14 15:32:26,108 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01503
2025-08-14 15:32:26,108 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01504
2025-08-14 15:32:26,108 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01505
2025-08-14 15:32:26,108 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01506
2025-08-14 15:32:32,215 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01507
2025-08-14 15:32:32,215 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01508
2025-08-14 15:32:32,215 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01509
2025-08-14 15:32:32,215 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01510
2025-08-14 15:32:32,215 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01511
2025-08-14 15:32:32,433 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01512
2025-08-14 15:32:32,433 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01513
2025-08-14 15:32:32,433 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01514
2025-08-14 15:32:32,433 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01515
2025-08-14 15:32:32,433 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01516
2025-08-14 15:32:32,433 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01517
2025-08-14 15:32:32,433 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01518
2025-08-14 15:32:32,433 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01519
2025-08-14 15:32:32,433 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01520
2025-08-14 15:32:32,433 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01521
2025-08-14 15:32:37,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01522
2025-08-14 15:32:37,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01523
2025-08-14 15:32:37,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01524
2025-08-14 15:32:37,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01525
2025-08-14 15:32:37,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01526
2025-08-14 15:32:37,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01527
2025-08-14 15:32:37,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01528
2025-08-14 15:32:37,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01529
2025-08-14 15:32:37,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01530
2025-08-14 15:32:37,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01531
2025-08-14 15:32:37,903 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01532
2025-08-14 15:32:37,903 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01533
2025-08-14 15:32:38,116 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01534
2025-08-14 15:32:41,374 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01535
2025-08-14 15:32:41,374 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01536
2025-08-14 15:32:41,374 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01537
2025-08-14 15:32:41,374 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01538
2025-08-14 15:32:41,374 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01539
2025-08-14 15:32:44,116 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01540
2025-08-14 15:32:44,116 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01541
2025-08-14 15:32:47,218 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01542
2025-08-14 15:32:47,219 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01543
2025-08-14 15:32:47,219 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01544
2025-08-14 15:32:47,219 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01545
2025-08-14 15:32:47,219 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01546
2025-08-14 15:32:47,219 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01547
2025-08-14 15:32:47,219 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01548
2025-08-14 15:32:47,219 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01549
2025-08-14 15:32:47,219 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01550
2025-08-14 15:32:47,219 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01551
2025-08-14 15:32:47,219 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01552
2025-08-14 15:32:47,219 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01553
2025-08-14 15:32:47,219 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01554
2025-08-14 15:32:47,587 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01555
2025-08-14 15:32:48,342 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01556
2025-08-14 15:32:48,343 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01557
2025-08-14 15:32:48,343 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01558
2025-08-14 15:32:48,343 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01559
2025-08-14 15:32:48,343 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01560
2025-08-14 15:32:49,100 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01561
2025-08-14 15:32:49,332 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01562
2025-08-14 15:32:52,198 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01563
2025-08-14 15:32:52,198 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01564
2025-08-14 15:32:52,198 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01565
2025-08-14 15:32:55,898 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01566
2025-08-14 15:32:55,898 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01567
2025-08-14 15:32:55,898 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01568
2025-08-14 15:32:55,898 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01569
2025-08-14 15:32:55,898 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01570
2025-08-14 15:33:01,809 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01571
2025-08-14 15:33:01,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01572
2025-08-14 15:33:01,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01573
2025-08-14 15:33:01,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01574
2025-08-14 15:33:01,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01575
2025-08-14 15:33:01,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01576
2025-08-14 15:33:01,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01577
2025-08-14 15:33:01,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01578
2025-08-14 15:33:01,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01579
2025-08-14 15:33:01,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01580
2025-08-14 15:33:01,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01581
2025-08-14 15:33:01,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01582
2025-08-14 15:33:01,810 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01583
2025-08-14 15:33:04,191 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01584
2025-08-14 15:33:04,191 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01585
2025-08-14 15:33:04,191 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01586
2025-08-14 15:33:04,191 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01587
2025-08-14 15:33:04,191 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01588
2025-08-14 15:33:04,191 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01589
2025-08-14 15:33:04,191 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01590
2025-08-14 15:33:04,824 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01591
2025-08-14 15:33:04,824 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01592
2025-08-14 15:33:04,825 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01593
2025-08-14 15:33:04,825 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01594
2025-08-14 15:33:05,650 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01595
2025-08-14 15:33:06,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01596
2025-08-14 15:33:06,054 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01597
2025-08-14 15:33:06,126 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01598
2025-08-14 15:33:06,126 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01599
2025-08-14 15:33:07,514 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01600
2025-08-14 15:33:07,514 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01601
2025-08-14 15:33:07,514 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01602
2025-08-14 15:33:07,514 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01603
2025-08-14 15:33:07,514 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01604
2025-08-14 15:33:09,288 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01605
2025-08-14 15:33:11,132 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01606
2025-08-14 15:33:11,132 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01607
2025-08-14 15:33:11,132 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01608
2025-08-14 15:33:11,132 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01609
2025-08-14 15:33:11,132 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01610
2025-08-14 15:33:12,068 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01611
2025-08-14 15:33:14,877 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01612
2025-08-14 15:33:14,878 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01613
2025-08-14 15:33:15,690 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01614
2025-08-14 15:33:15,691 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01615
2025-08-14 15:33:15,691 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01616
2025-08-14 15:33:23,487 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01617
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01618
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01619
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01620
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01621
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01622
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01623
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01624
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01625
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01626
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01627
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01628
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01629
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01630
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01631
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01632
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01633
2025-08-14 15:33:23,488 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01634
2025-08-14 15:33:24,400 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01635
2025-08-14 15:33:24,469 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01636
2025-08-14 15:33:24,469 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01637
2025-08-14 15:33:24,469 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01638
2025-08-14 15:33:25,159 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01639
2025-08-14 15:33:25,159 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01640
2025-08-14 15:33:27,683 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01641
2025-08-14 15:33:27,683 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01642
2025-08-14 15:33:27,683 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01643
2025-08-14 15:33:27,683 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01644
2025-08-14 15:33:27,683 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01645
2025-08-14 15:33:27,683 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01646
2025-08-14 15:33:28,647 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01647
2025-08-14 15:33:28,648 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01648
2025-08-14 15:33:33,498 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01649
2025-08-14 15:33:33,957 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01650
2025-08-14 15:33:33,958 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01651
2025-08-14 15:33:33,958 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01652
2025-08-14 15:33:36,015 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01653
2025-08-14 15:33:36,015 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01654
2025-08-14 15:33:36,016 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01655
2025-08-14 15:33:36,016 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01656
2025-08-14 15:33:36,016 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01657
2025-08-14 15:33:36,016 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01658
2025-08-14 15:33:36,016 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01659
2025-08-14 15:33:36,016 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01660
2025-08-14 15:33:36,016 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01661
2025-08-14 15:33:37,379 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01662
2025-08-14 15:33:38,144 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01663
2025-08-14 15:33:38,144 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01664
2025-08-14 15:33:38,516 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01665
2025-08-14 15:33:38,958 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01666
2025-08-14 15:33:38,958 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01667
2025-08-14 15:33:38,958 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01668
2025-08-14 15:33:39,946 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01669
2025-08-14 15:33:39,947 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01670
2025-08-14 15:33:39,947 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01671
2025-08-14 15:33:41,077 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01672
2025-08-14 15:33:41,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01673
2025-08-14 15:33:42,591 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01674
2025-08-14 15:33:46,660 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01675
2025-08-14 15:33:46,661 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01676
2025-08-14 15:33:46,661 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01677
2025-08-14 15:33:46,661 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01678
2025-08-14 15:33:46,661 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01679
2025-08-14 15:33:46,661 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01680
2025-08-14 15:33:46,661 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01681
2025-08-14 15:33:46,661 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01682
2025-08-14 15:33:47,044 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01683
2025-08-14 15:33:51,761 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01684
2025-08-14 15:33:51,761 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01685
2025-08-14 15:33:51,761 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01686
2025-08-14 15:33:51,761 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01687
2025-08-14 15:33:51,761 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01688
2025-08-14 15:33:51,761 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01689
2025-08-14 15:33:51,761 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01690
2025-08-14 15:33:52,047 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01691
2025-08-14 15:33:52,047 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01692
2025-08-14 15:33:52,047 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01693
2025-08-14 15:33:53,298 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01694
2025-08-14 15:33:53,298 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01695
2025-08-14 15:33:55,468 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01696
2025-08-14 15:33:55,468 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01697
2025-08-14 15:33:55,468 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01698
2025-08-14 15:34:06,467 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01699
2025-08-14 15:34:06,467 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01700
2025-08-14 15:34:06,467 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01701
2025-08-14 15:34:07,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01702
2025-08-14 15:34:07,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01703
2025-08-14 15:34:07,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01704
2025-08-14 15:34:07,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01705
2025-08-14 15:34:07,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01706
2025-08-14 15:34:07,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01707
2025-08-14 15:34:07,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01708
2025-08-14 15:34:07,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01709
2025-08-14 15:34:07,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01710
2025-08-14 15:34:07,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01711
2025-08-14 15:34:07,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01712
2025-08-14 15:34:07,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01713
2025-08-14 15:34:07,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01714
2025-08-14 15:34:07,899 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01715
2025-08-14 15:34:08,256 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01716
2025-08-14 15:34:09,197 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01717
2025-08-14 15:34:09,197 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01718
2025-08-14 15:34:11,077 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01719
2025-08-14 15:34:11,077 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01720
2025-08-14 15:34:11,077 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01721
2025-08-14 15:34:11,077 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01722
2025-08-14 15:34:11,077 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01723
2025-08-14 15:34:11,077 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01724
2025-08-14 15:34:11,077 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01725
2025-08-14 15:34:11,077 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01726
2025-08-14 15:34:11,077 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01727
2025-08-14 15:34:11,077 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01728
2025-08-14 15:34:12,384 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01729
2025-08-14 15:34:12,384 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01730
2025-08-14 15:34:13,397 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01731
2025-08-14 15:34:17,642 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01732
2025-08-14 15:34:17,642 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01733
2025-08-14 15:34:17,642 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01734
2025-08-14 15:34:17,642 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01735
2025-08-14 15:34:17,642 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01736
2025-08-14 15:34:17,642 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01737
2025-08-14 15:34:17,642 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01738
2025-08-14 15:34:21,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01739
2025-08-14 15:34:21,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01740
2025-08-14 15:34:21,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01741
2025-08-14 15:34:21,430 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01742
2025-08-14 15:34:21,430 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01743
2025-08-14 15:34:21,430 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01744
2025-08-14 15:34:21,430 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01745
2025-08-14 15:34:21,430 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01746
2025-08-14 15:34:21,430 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01747
2025-08-14 15:34:23,425 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01748
2025-08-14 15:34:23,425 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01749
2025-08-14 15:34:23,425 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01750
2025-08-14 15:34:23,425 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01751
2025-08-14 15:34:23,425 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01752
2025-08-14 15:34:23,425 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01753
2025-08-14 15:34:23,542 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01754
2025-08-14 15:34:23,542 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01755
2025-08-14 15:34:26,832 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01756
2025-08-14 15:34:26,832 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01757
2025-08-14 15:34:28,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01758
2025-08-14 15:34:28,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01759
2025-08-14 15:34:28,235 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01760
2025-08-14 15:34:29,998 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01761
2025-08-14 15:34:29,998 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01762
2025-08-14 15:34:29,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01763
2025-08-14 15:34:29,999 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01764
2025-08-14 15:34:30,370 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01765
2025-08-14 15:34:30,376 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01766
2025-08-14 15:34:30,542 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01767
2025-08-14 15:34:30,543 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01768
2025-08-14 15:34:31,177 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01769
2025-08-14 15:34:31,177 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01770
2025-08-14 15:34:33,204 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01771
2025-08-14 15:34:33,204 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01772
2025-08-14 15:34:33,204 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01773
2025-08-14 15:34:33,204 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01774
2025-08-14 15:34:33,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01775
2025-08-14 15:34:33,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01776
2025-08-14 15:34:33,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01777
2025-08-14 15:34:33,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01778
2025-08-14 15:34:35,706 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01779
2025-08-14 15:34:35,706 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01780
2025-08-14 15:34:35,706 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01781
2025-08-14 15:34:36,104 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01782
2025-08-14 15:34:36,104 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01783
2025-08-14 15:34:36,104 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01784
2025-08-14 15:34:37,100 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01785
2025-08-14 15:34:38,132 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01786
2025-08-14 15:34:38,132 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01787
2025-08-14 15:34:38,132 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01788
2025-08-14 15:34:39,935 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01789
2025-08-14 15:34:39,935 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01790
2025-08-14 15:34:39,935 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01791
2025-08-14 15:34:39,935 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01792
2025-08-14 15:34:45,128 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01793
2025-08-14 15:34:45,129 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01794
2025-08-14 15:34:45,129 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01795
2025-08-14 15:34:45,129 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01796
2025-08-14 15:34:45,129 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01797
2025-08-14 15:34:45,129 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01798
2025-08-14 15:34:45,129 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01799
2025-08-14 15:34:45,359 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01800
2025-08-14 15:34:45,359 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01801
2025-08-14 15:34:46,526 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01802
2025-08-14 15:34:46,526 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01803
2025-08-14 15:34:46,526 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01804
2025-08-14 15:34:46,526 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01805
2025-08-14 15:34:49,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01806
2025-08-14 15:34:49,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01807
2025-08-14 15:34:49,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01808
2025-08-14 15:34:49,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01809
2025-08-14 15:34:49,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01810
2025-08-14 15:34:49,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01811
2025-08-14 15:34:49,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01812
2025-08-14 15:34:49,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01813
2025-08-14 15:34:49,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01814
2025-08-14 15:34:49,429 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01815
2025-08-14 15:34:50,323 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01816
2025-08-14 15:34:50,324 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01817
2025-08-14 15:34:50,324 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01818
2025-08-14 15:34:50,324 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01819
2025-08-14 15:34:53,647 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01820
2025-08-14 15:34:53,647 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01821
2025-08-14 15:34:53,647 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01822
2025-08-14 15:34:53,647 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01823
2025-08-14 15:34:54,300 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01824
2025-08-14 15:34:57,327 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01825
2025-08-14 15:34:57,327 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01826
2025-08-14 15:34:57,328 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01827
2025-08-14 15:34:57,328 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01828
2025-08-14 15:34:57,727 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01829
2025-08-14 15:35:00,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01830
2025-08-14 15:35:00,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01831
2025-08-14 15:35:00,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01832
2025-08-14 15:35:00,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01833
2025-08-14 15:35:00,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01834
2025-08-14 15:35:00,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01835
2025-08-14 15:35:00,573 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01836
2025-08-14 15:35:00,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01837
2025-08-14 15:35:01,579 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01838
2025-08-14 15:35:01,579 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01839
2025-08-14 15:35:02,983 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01840
2025-08-14 15:35:02,983 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01841
2025-08-14 15:35:02,983 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01842
2025-08-14 15:35:02,983 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01843
2025-08-14 15:35:14,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01844
2025-08-14 15:35:14,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01845
2025-08-14 15:35:14,758 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01846
2025-08-14 15:35:16,520 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01847
2025-08-14 15:35:16,520 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01848
2025-08-14 15:35:16,520 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01849
2025-08-14 15:35:16,520 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01850
2025-08-14 15:35:16,521 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01851
2025-08-14 15:35:16,521 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01852
2025-08-14 15:35:16,521 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01853
2025-08-14 15:35:16,521 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01854
2025-08-14 15:35:16,521 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01855
2025-08-14 15:35:16,521 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01856
2025-08-14 15:35:16,521 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01857
2025-08-14 15:35:16,521 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01858
2025-08-14 15:35:16,521 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01859
2025-08-14 15:35:16,521 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01860
2025-08-14 15:35:18,681 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01861
2025-08-14 15:35:19,071 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01862
2025-08-14 15:35:23,185 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01863
2025-08-14 15:35:23,185 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01864
2025-08-14 15:35:23,185 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01865
2025-08-14 15:35:23,185 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01866
2025-08-14 15:35:23,185 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01867
2025-08-14 15:35:25,764 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01868
2025-08-14 15:35:25,764 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01869
2025-08-14 15:35:25,764 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01870
2025-08-14 15:35:25,764 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01871
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01872
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01873
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01874
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01875
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01876
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01877
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01878
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01879
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01880
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01881
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01882
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01883
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01884
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01885
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01886
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01887
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01888
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01889
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01890
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01891
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01892
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01893
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01894
2025-08-14 15:35:37,634 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01895
2025-08-14 15:35:39,733 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01896
2025-08-14 15:35:39,733 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01897
2025-08-14 15:35:39,733 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01898
2025-08-14 15:35:39,733 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01899
2025-08-14 15:35:39,761 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01900
2025-08-14 15:35:39,761 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01901
2025-08-14 15:35:39,761 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01902
2025-08-14 15:35:39,761 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01903
2025-08-14 15:35:39,761 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01904
2025-08-14 15:35:39,762 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01905
2025-08-14 15:35:39,762 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01906
2025-08-14 15:35:39,762 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01907
2025-08-14 15:35:40,361 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01908
2025-08-14 15:35:40,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01909
2025-08-14 15:35:41,633 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01910
2025-08-14 15:35:44,073 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01911
2025-08-14 15:35:45,296 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01912
2025-08-14 15:35:45,297 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01913
2025-08-14 15:35:45,297 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01914
2025-08-14 15:35:45,297 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01915
2025-08-14 15:35:45,297 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01916
2025-08-14 15:35:45,297 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01917
2025-08-14 15:35:45,297 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01918
2025-08-14 15:35:45,297 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01919
2025-08-14 15:35:45,462 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01920
2025-08-14 15:35:45,462 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01921
2025-08-14 15:35:48,249 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01922
2025-08-14 15:35:48,249 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01923
2025-08-14 15:35:48,249 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01924
2025-08-14 15:35:48,249 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01925
2025-08-14 15:35:48,895 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01926
2025-08-14 15:35:48,895 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01927
2025-08-14 15:35:50,027 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01928
2025-08-14 15:35:50,027 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01929
2025-08-14 15:35:50,027 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01930
2025-08-14 15:35:50,447 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01931
2025-08-14 15:35:50,447 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01932
2025-08-14 15:35:50,447 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01933
2025-08-14 15:35:52,242 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01934
2025-08-14 15:35:57,864 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01935
2025-08-14 15:35:57,864 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01936
2025-08-14 15:35:57,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01937
2025-08-14 15:35:57,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01938
2025-08-14 15:35:57,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01939
2025-08-14 15:35:57,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01940
2025-08-14 15:35:58,708 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01941
2025-08-14 15:35:58,709 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01942
2025-08-14 15:35:58,709 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01943
2025-08-14 15:35:58,709 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01944
2025-08-14 15:35:58,734 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01945
2025-08-14 15:35:59,906 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01946
2025-08-14 15:35:59,906 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01947
2025-08-14 15:35:59,906 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01948
2025-08-14 15:36:03,970 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01949
2025-08-14 15:36:08,440 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01950
2025-08-14 15:36:08,838 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01951
2025-08-14 15:36:08,839 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01952
2025-08-14 15:36:08,839 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01953
2025-08-14 15:36:08,839 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01954
2025-08-14 15:36:08,839 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01955
2025-08-14 15:36:08,839 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01956
2025-08-14 15:36:08,839 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01957
2025-08-14 15:36:08,839 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01958
2025-08-14 15:36:08,839 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01959
2025-08-14 15:36:08,839 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01960
2025-08-14 15:36:08,954 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01961
2025-08-14 15:36:08,954 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01962
2025-08-14 15:36:08,954 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01963
2025-08-14 15:36:08,954 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01964
2025-08-14 15:36:08,954 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01965
2025-08-14 15:36:10,242 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01966
2025-08-14 15:36:10,242 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01967
2025-08-14 15:36:10,242 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01968
2025-08-14 15:36:10,242 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01969
2025-08-14 15:36:11,257 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01970
2025-08-14 15:36:11,257 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01971
2025-08-14 15:36:11,257 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01972
2025-08-14 15:36:11,453 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01973
2025-08-14 15:36:12,263 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01974
2025-08-14 15:36:14,215 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01975
2025-08-14 15:36:17,881 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01976
2025-08-14 15:36:19,306 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01977
2025-08-14 15:36:19,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01978
2025-08-14 15:36:19,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01979
2025-08-14 15:36:19,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01980
2025-08-14 15:36:19,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01981
2025-08-14 15:36:19,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01982
2025-08-14 15:36:19,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01983
2025-08-14 15:36:19,307 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01984
2025-08-14 15:36:20,885 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01985
2025-08-14 15:36:20,885 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01986
2025-08-14 15:36:20,885 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01987
2025-08-14 15:36:20,885 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01988
2025-08-14 15:36:20,885 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01989
2025-08-14 15:36:20,885 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01990
2025-08-14 15:36:22,155 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01991
2025-08-14 15:36:22,155 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01992
2025-08-14 15:36:23,150 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01993
2025-08-14 15:36:24,403 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01994
2025-08-14 15:36:27,287 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01995
2025-08-14 15:36:28,783 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01996
2025-08-14 15:36:31,781 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01997
2025-08-14 15:36:31,781 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01998
2025-08-14 15:36:31,781 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest01999
2025-08-14 15:36:31,781 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02000
2025-08-14 15:36:31,781 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02001
2025-08-14 15:36:31,781 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02002
2025-08-14 15:36:31,781 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02003
2025-08-14 15:36:31,781 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02004
2025-08-14 15:36:31,781 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02005
2025-08-14 15:36:31,959 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02006
2025-08-14 15:36:31,959 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02007
2025-08-14 15:36:37,823 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02008
2025-08-14 15:36:37,823 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02009
2025-08-14 15:36:41,905 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02010
2025-08-14 15:36:41,947 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02011
2025-08-14 15:36:41,948 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02012
2025-08-14 15:36:41,948 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02013
2025-08-14 15:36:41,948 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02014
2025-08-14 15:36:41,948 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02015
2025-08-14 15:36:41,948 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02016
2025-08-14 15:36:41,948 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02017
2025-08-14 15:36:41,948 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02018
2025-08-14 15:36:41,948 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02019
2025-08-14 15:36:41,948 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02020
2025-08-14 15:36:41,948 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02021
2025-08-14 15:36:42,018 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02022
2025-08-14 15:36:42,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02023
2025-08-14 15:36:42,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02024
2025-08-14 15:36:42,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02025
2025-08-14 15:36:42,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02026
2025-08-14 15:36:42,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02027
2025-08-14 15:36:44,885 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02028
2025-08-14 15:36:44,885 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02029
2025-08-14 15:36:46,413 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02030
2025-08-14 15:36:46,413 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02031
2025-08-14 15:36:46,413 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02032
2025-08-14 15:36:46,413 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02033
2025-08-14 15:36:46,413 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02034
2025-08-14 15:36:46,413 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02035
2025-08-14 15:36:46,413 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02036
2025-08-14 15:36:46,454 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02037
2025-08-14 15:36:46,454 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02038
2025-08-14 15:36:47,364 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02039
2025-08-14 15:36:48,186 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02040
2025-08-14 15:36:50,195 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02041
2025-08-14 15:36:50,195 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02042
2025-08-14 15:36:50,195 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02043
2025-08-14 15:36:53,659 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02044
2025-08-14 15:36:53,659 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02045
2025-08-14 15:36:53,659 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02046
2025-08-14 15:36:53,659 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02047
2025-08-14 15:36:53,659 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02048
2025-08-14 15:36:53,659 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02049
2025-08-14 15:36:53,659 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02050
2025-08-14 15:36:53,659 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02051
2025-08-14 15:36:54,034 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02052
2025-08-14 15:36:55,508 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02053
2025-08-14 15:36:55,698 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02054
2025-08-14 15:36:55,699 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02055
2025-08-14 15:36:55,699 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02056
2025-08-14 15:36:55,699 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02057
2025-08-14 15:36:56,886 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02058
2025-08-14 15:36:56,886 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02059
2025-08-14 15:36:56,887 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02060
2025-08-14 15:36:57,632 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02061
2025-08-14 15:36:58,226 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02062
2025-08-14 15:36:58,701 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02063
2025-08-14 15:37:02,997 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02064
2025-08-14 15:37:04,469 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02065
2025-08-14 15:37:07,644 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02066
2025-08-14 15:37:07,644 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02067
2025-08-14 15:37:07,644 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02068
2025-08-14 15:37:07,644 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02069
2025-08-14 15:37:07,644 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02070
2025-08-14 15:37:07,644 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02071
2025-08-14 15:49:23,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02072
2025-08-14 15:49:23,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02073
2025-08-14 15:49:23,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02074
2025-08-14 15:49:23,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02075
2025-08-14 15:49:23,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02076
2025-08-14 15:49:23,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02077
2025-08-14 15:49:23,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02078
2025-08-14 15:49:23,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02079
2025-08-14 15:49:23,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02080
2025-08-14 15:49:23,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02081
2025-08-14 15:49:23,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02082
2025-08-14 15:49:23,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02083
2025-08-14 15:49:23,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02084
2025-08-14 15:49:23,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02085
2025-08-14 15:49:23,865 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02086
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02087
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02088
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02089
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02090
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02091
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02092
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02093
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02094
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02095
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02096
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02097
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02098
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02099
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02100
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02101
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02102
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02103
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02104
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02105
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02106
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02107
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02108
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02109
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02110
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02111
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02112
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02113
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02114
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02115
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02116
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02117
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02118
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02119
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02120
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02121
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02122
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02123
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02124
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02125
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02126
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02127
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02128
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02129
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02130
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02131
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02132
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02133
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02134
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02135
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02136
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02137
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02138
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02139
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02140
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02141
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02142
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02143
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02144
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02145
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02146
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02147
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02148
2025-08-14 15:49:23,866 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02149
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02150
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02151
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02152
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02153
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02154
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02155
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02156
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02157
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02158
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02159
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02160
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02161
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02162
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02163
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02164
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02165
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02166
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02167
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02168
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02169
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02170
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02171
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02172
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02173
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02174
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02175
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02176
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02177
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02178
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02179
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02180
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02181
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02182
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02183
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02184
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02185
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02186
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02187
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02188
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02189
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02190
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02191
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02192
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02193
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02194
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02195
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02196
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02197
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02198
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02199
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02200
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02201
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02202
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02203
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02204
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02205
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02206
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02207
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02208
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02209
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02210
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02211
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02212
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02213
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02214
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02215
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02216
2025-08-14 15:49:23,867 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02217
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02218
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02219
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02220
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02221
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02222
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02223
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02224
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02225
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02226
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02227
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02228
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02229
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02230
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02231
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02232
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02233
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02234
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02235
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02236
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02237
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02238
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02239
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02240
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02241
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02242
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02243
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02244
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02245
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02246
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02247
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02248
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02249
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02250
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02251
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02252
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02253
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02254
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02255
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02256
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02257
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02258
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02259
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02260
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02261
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02262
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02263
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02264
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02265
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02266
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02267
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02268
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02269
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02270
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02271
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02272
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02273
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02274
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02275
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02276
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02277
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02278
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02279
2025-08-14 15:49:23,868 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02280
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02281
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02282
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02283
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02284
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02285
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02286
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02287
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02288
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02289
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02290
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02291
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02292
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02293
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02294
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02295
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02296
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02297
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02298
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02299
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02300
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02301
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02302
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02303
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02304
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02305
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02306
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02307
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02308
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02309
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02310
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02311
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02312
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02313
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02314
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02315
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02316
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02317
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02318
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02319
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02320
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02321
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02322
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02323
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02324
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02325
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02326
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02327
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02328
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02329
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02330
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02331
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02332
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02333
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02334
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02335
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02336
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02337
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02338
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02339
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02340
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02341
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02342
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02343
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02344
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02345
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02346
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02347
2025-08-14 15:49:23,869 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02348
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02349
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02350
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02351
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02352
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02353
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02354
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02355
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02356
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02357
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02358
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02359
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02360
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02361
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02362
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02363
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02364
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02365
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02366
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02367
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02368
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02369
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02370
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02371
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02372
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02373
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02374
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02375
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02376
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02377
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02378
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02379
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02380
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02381
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02382
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02383
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02384
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02385
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02386
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02387
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02388
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02389
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02390
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02391
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02392
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02393
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02394
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02395
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02396
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02397
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02398
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02399
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02400
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02401
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02402
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02403
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02404
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02405
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02406
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02407
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02408
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02409
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02410
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02411
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02412
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02413
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02414
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02415
2025-08-14 15:49:23,870 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02416
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02417
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02418
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02419
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02420
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02421
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02422
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02423
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02424
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02425
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02426
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02427
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02428
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02429
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02430
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02431
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02432
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02433
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02434
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02435
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02436
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02437
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02438
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02439
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02440
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02441
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02442
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02443
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02444
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02445
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02446
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02447
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02448
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02449
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02450
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02451
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02452
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02453
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02454
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02455
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02456
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02457
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02458
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02459
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02460
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02461
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02462
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02463
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02464
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02465
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02466
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02467
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02468
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02469
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02470
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02471
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02472
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02473
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02474
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02475
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02476
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02477
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02478
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02479
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02480
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02481
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02482
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02483
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02484
2025-08-14 15:49:23,871 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02485
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02486
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02487
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02488
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02489
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02490
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02491
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02492
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02493
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02494
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02495
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02496
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02497
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02498
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02499
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02500
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02501
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02502
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02503
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02504
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02505
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02506
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02507
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02508
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02509
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02510
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02511
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02512
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02513
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02514
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02515
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02516
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02517
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02518
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02519
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02520
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02521
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02522
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02523
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02524
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02525
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02526
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02527
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02528
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02529
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02530
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02531
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02532
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02533
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02534
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02535
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02536
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02537
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02538
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02539
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02540
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02541
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02542
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02543
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02544
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02545
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02546
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02547
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02548
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02549
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02550
2025-08-14 15:49:23,872 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02551
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02552
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02553
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02554
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02555
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02556
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02557
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02558
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02559
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02560
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02561
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02562
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02563
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02564
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02565
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02566
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02567
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02568
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02569
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02570
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02571
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02572
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02573
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02574
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02575
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02576
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02577
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02578
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02579
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02580
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02581
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02582
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02583
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02584
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02585
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02586
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02587
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02588
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02589
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02590
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02591
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02592
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02593
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02594
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02595
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02596
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02597
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02598
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02599
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02600
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02601
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02602
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02603
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02604
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02605
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02606
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02607
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02608
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02609
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02610
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02611
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02612
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02613
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02614
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02615
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02616
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02617
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02618
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02619
2025-08-14 15:49:23,873 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02620
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02621
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02622
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02623
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02624
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02625
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02626
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02627
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02628
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02629
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02630
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02631
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02632
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02633
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02634
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02635
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02636
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02637
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02638
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02639
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02640
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02641
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02642
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02643
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02644
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02645
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02646
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02647
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02648
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02649
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02650
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02651
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02652
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02653
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02654
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02655
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02656
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02657
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02658
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02659
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02660
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02661
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02662
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02663
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02664
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02665
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02666
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02667
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02668
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02669
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02670
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02671
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02672
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02673
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02674
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02675
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02676
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02677
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02678
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02679
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02680
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02681
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02682
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02683
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02684
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02685
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02686
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02687
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02688
2025-08-14 15:49:23,874 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02689
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02690
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02691
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02692
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02693
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02694
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02695
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02696
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02697
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02698
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02699
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02700
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02701
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02702
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02703
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02704
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02705
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02706
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02707
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02708
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02709
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02710
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02711
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02712
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02713
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02714
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02715
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02716
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02717
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02718
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02719
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02720
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02721
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02722
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02723
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02724
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02725
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02726
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02727
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02728
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02729
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02730
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02731
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02732
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02733
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02734
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02735
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02736
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02737
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02738
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02739
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Got response from o3-mini-2025-01-31 at index BenchmarkTest02740
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Model o3-mini-2025-01-31 executed 2740 prompts in 00:28:47
2025-08-14 15:49:23,875 - LLMsInterface - INFO - Total cost: 9.790731500000025 USD, Total tokens: 3961321, Prompt tokens: 2314873, Completion tokens: 1646448
2025-08-14 15:49:23,881 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00001 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,884 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00002 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,888 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00003 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,891 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00004 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,894 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00005 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,897 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00006 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,900 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00007 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,902 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00008 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,905 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00009 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,908 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00010 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,911 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00011 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,914 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00012 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,917 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00013 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,919 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00014 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,922 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00015 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,925 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00016 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,928 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00017 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,931 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00018 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,935 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00019 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,938 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00020 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,940 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00021 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,943 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00022 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,946 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00023 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,949 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00024 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,952 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00025 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,955 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00026 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,958 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00027 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,960 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00028 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,963 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00029 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,966 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00030 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,969 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00031 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,972 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00032 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,975 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00033 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,978 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00034 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,981 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00035 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,983 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00036 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,986 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00037 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,989 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00038 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,992 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00039 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,995 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00040 with 'simple' prompt is stored in the database.
2025-08-14 15:49:23,998 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00041 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,001 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00042 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,004 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00043 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,006 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00044 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,009 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00045 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,012 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00046 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,015 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00047 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,018 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00048 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,021 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00049 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,024 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00050 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,026 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00051 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,029 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00052 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,033 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00053 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,036 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00054 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,039 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00055 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,042 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00056 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,045 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00057 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,048 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00058 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,051 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00059 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,054 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00060 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,056 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00061 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,059 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00062 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,062 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00063 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,065 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00064 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,068 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00065 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,070 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00066 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,074 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00067 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,077 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00068 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,080 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00069 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,083 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00070 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,086 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00071 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,089 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00072 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,092 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00073 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,095 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00074 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,098 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00075 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,101 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00076 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,104 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00077 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,107 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00078 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,110 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00079 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,113 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00080 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,116 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00081 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,119 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00082 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,122 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00083 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,125 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00084 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,129 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00085 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,132 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00086 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,134 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00087 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,137 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00088 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,140 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00089 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,143 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00090 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,146 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00091 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,149 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00092 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,152 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00093 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,155 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00094 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,157 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00095 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,160 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00096 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,163 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00097 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,166 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00098 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,169 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00099 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,171 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00100 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,174 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00101 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,177 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00102 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,180 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00103 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,183 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00104 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,185 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00105 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,188 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00106 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,191 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00107 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,194 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00108 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,197 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00109 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,200 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00110 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,203 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00111 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,206 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00112 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,210 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00113 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,212 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00114 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,215 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00115 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,218 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00116 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,221 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00117 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,223 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00118 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,227 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00119 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,230 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00120 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,233 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00121 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,236 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00122 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,238 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00123 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,241 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00124 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,244 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00125 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,247 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00126 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,249 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00127 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,252 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00128 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,255 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00129 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,257 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00130 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,260 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00131 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,263 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00132 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,266 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00133 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,269 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00134 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,271 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00135 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,274 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00136 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,277 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00137 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,280 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00138 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,283 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00139 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,286 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00140 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,288 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00141 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,291 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00142 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,294 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00143 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,297 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00144 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,299 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00145 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,302 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00146 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,305 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00147 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,308 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00148 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,310 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00149 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,313 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00150 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,316 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00151 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,318 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00152 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,321 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00153 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,324 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00154 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,326 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00155 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,329 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00156 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,332 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00157 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,335 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00158 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,337 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00159 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,341 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00160 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,344 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00161 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,347 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00162 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,350 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00163 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,353 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00164 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,355 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00165 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,358 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00166 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,361 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00167 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,364 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00168 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,367 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00169 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,370 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00170 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,373 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00171 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,376 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00172 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,379 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00173 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,381 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00174 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,384 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00175 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,387 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00176 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,390 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00177 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,392 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00178 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,395 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00179 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,398 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00180 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,401 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00181 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,404 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00182 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,407 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00183 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,410 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00184 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,413 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00185 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,416 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00186 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,419 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00187 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,421 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00188 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,424 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00189 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,427 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00190 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,430 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00191 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,433 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00192 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,436 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00193 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,439 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00194 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,441 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00195 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,444 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00196 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,447 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00197 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,450 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00198 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,453 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00199 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,455 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00200 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,459 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00201 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,462 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00202 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,465 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00203 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,467 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00204 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,470 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00205 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,473 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00206 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,476 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00207 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,480 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00208 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,482 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00209 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,485 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00210 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,488 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00211 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,490 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00212 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,493 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00213 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,496 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00214 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,499 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00215 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,501 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00216 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,504 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00217 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,507 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00218 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,510 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00219 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,512 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00220 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,515 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00221 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,518 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00222 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,521 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00223 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,523 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00224 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,526 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00225 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,529 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00226 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,532 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00227 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,535 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00228 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,538 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00229 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,540 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00230 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,543 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00231 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,546 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00232 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,549 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00233 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,551 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00234 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,554 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00235 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,557 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00236 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,560 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00237 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,563 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00238 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,565 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00239 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,569 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00240 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,572 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00241 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,575 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00242 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,577 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00243 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,580 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00244 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,583 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00245 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,586 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00246 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,589 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00247 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,592 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00248 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,595 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00249 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,597 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00250 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,601 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00251 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,604 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00252 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,607 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00253 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,610 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00254 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,613 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00255 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,617 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00256 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,620 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00257 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,624 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00258 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,627 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00259 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,629 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00260 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,632 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00261 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,635 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00262 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,638 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00263 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,641 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00264 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,644 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00265 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,647 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00266 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,649 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00267 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,652 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00268 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,655 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00269 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,658 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00270 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,661 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00271 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,664 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00272 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,666 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00273 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,669 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00274 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,672 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00275 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,675 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00276 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,678 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00277 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,680 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00278 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,683 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00279 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,686 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00280 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,689 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00281 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,691 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00282 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,694 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00283 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,697 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00284 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,699 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00285 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,702 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00286 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,705 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00287 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,708 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00288 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,710 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00289 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,713 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00290 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,716 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00291 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,719 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00292 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,721 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00293 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,724 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00294 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,727 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00295 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,730 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00296 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,732 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00297 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,735 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00298 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,738 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00299 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,741 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00300 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,743 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00301 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,746 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00302 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,749 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00303 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,751 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00304 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,755 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00305 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,758 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00306 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,761 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00307 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,763 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00308 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,766 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00309 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,769 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00310 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,772 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00311 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,775 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00312 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,778 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00313 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,781 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00314 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,784 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00315 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,788 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00316 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,791 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00317 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,793 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00318 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,796 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00319 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,799 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00320 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,802 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00321 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,804 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00322 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,807 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00323 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,810 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00324 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,813 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00325 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,816 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00326 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,818 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00327 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,821 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00328 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,824 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00329 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,827 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00330 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,829 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00331 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,832 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00332 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,835 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00333 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,838 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00334 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,841 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00335 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,843 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00336 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,846 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00337 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,849 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00338 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,853 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00339 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,856 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00340 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,858 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00341 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,861 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00342 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,864 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00343 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,867 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00344 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,869 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00345 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,872 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00346 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,875 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00347 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,878 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00348 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,880 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00349 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,883 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00350 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,886 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00351 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,889 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00352 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,892 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00353 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,895 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00354 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,898 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00355 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,900 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00356 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,903 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00357 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,906 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00358 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,909 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00359 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,911 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00360 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,914 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00361 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,917 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00362 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,919 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00363 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,922 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00364 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,926 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00365 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,929 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00366 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,932 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00367 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,935 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00368 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,939 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00369 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,943 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00370 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,947 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00371 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,951 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00372 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,954 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00373 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,958 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00374 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,961 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00375 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,965 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00376 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,968 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00377 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,972 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00378 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,976 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00379 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,979 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00380 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,983 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00381 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,987 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00382 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,991 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00383 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,995 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00384 with 'simple' prompt is stored in the database.
2025-08-14 15:49:24,998 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00385 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,002 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00386 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,006 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00387 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,010 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00388 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,014 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00389 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,018 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00390 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,021 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00391 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,025 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00392 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,029 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00393 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,033 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00394 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,037 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00395 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,041 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00396 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,045 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00397 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,048 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00398 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,052 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00399 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,056 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00400 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,060 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00401 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,064 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00402 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,068 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00403 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,071 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00404 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,075 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00405 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,079 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00406 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,083 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00407 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,087 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00408 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,091 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00409 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,095 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00410 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,099 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00411 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,103 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00412 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,107 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00413 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,111 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00414 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,114 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00415 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,118 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00416 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,122 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00417 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,126 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00418 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,130 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00419 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,133 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00420 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,137 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00421 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,141 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00422 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,145 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00423 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,148 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00424 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,152 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00425 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,156 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00426 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,160 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00427 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,163 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00428 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,167 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00429 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,171 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00430 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,175 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00431 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,178 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00432 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,182 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00433 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,186 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00434 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,190 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00435 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,193 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00436 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,197 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00437 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,201 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00438 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,205 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00439 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,208 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00440 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,212 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00441 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,216 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00442 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,219 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00443 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,223 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00444 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,227 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00445 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,231 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00446 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,235 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00447 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,238 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00448 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,242 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00449 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,246 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00450 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,250 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00451 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,253 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00452 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,257 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00453 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,261 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00454 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,265 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00455 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,268 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00456 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,272 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00457 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,276 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00458 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,280 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00459 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,283 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00460 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,287 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00461 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,291 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00462 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,294 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00463 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,298 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00464 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,302 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00465 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,306 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00466 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,309 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00467 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,313 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00468 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,317 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00469 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,321 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00470 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,324 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00471 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,328 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00472 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,332 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00473 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,336 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00474 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,339 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00475 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,343 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00476 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,347 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00477 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,350 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00478 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,354 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00479 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,358 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00480 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,361 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00481 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,365 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00482 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,369 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00483 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,373 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00484 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,376 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00485 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,380 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00486 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,384 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00487 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,388 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00488 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,391 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00489 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,395 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00490 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,399 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00491 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,403 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00492 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,407 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00493 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,410 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00494 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,414 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00495 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,418 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00496 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,422 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00497 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,426 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00498 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,429 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00499 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,433 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00500 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,437 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00501 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,441 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00502 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,445 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00503 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,448 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00504 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,452 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00505 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,456 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00506 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,460 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00507 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,464 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00508 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,467 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00509 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,471 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00510 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,475 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00511 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,479 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00512 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,482 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00513 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,486 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00514 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,490 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00515 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,493 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00516 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,497 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00517 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,501 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00518 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,505 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00519 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,508 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00520 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,512 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00521 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,516 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00522 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,520 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00523 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,524 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00524 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,527 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00525 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,531 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00526 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,536 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00527 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,539 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00528 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,543 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00529 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,547 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00530 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,551 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00531 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,555 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00532 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,558 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00533 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,562 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00534 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,566 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00535 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,570 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00536 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,573 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00537 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,577 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00538 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,581 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00539 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,585 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00540 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,589 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00541 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,593 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00542 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,596 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00543 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,600 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00544 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,605 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00545 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,609 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00546 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,612 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00547 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,616 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00548 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,620 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00549 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,624 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00550 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,627 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00551 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,631 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00552 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,635 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00553 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,639 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00554 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,642 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00555 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,646 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00556 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,650 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00557 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,654 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00558 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,658 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00559 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,662 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00560 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,666 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00561 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,669 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00562 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,673 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00563 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,677 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00564 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,681 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00565 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,685 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00566 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,689 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00567 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,692 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00568 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,696 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00569 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,700 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00570 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,704 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00571 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,708 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00572 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,712 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00573 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,716 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00574 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,720 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00575 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,723 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00576 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,727 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00577 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,731 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00578 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,735 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00579 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,739 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00580 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,743 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00581 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,747 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00582 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,750 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00583 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,754 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00584 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,758 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00585 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,762 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00586 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,765 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00587 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,769 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00588 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,773 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00589 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,777 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00590 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,780 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00591 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,784 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00592 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,788 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00593 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,792 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00594 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,796 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00595 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,800 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00596 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,803 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00597 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,807 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00598 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,811 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00599 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,815 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00600 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,818 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00601 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,822 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00602 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,826 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00603 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,829 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00604 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,833 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00605 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,837 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00606 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,841 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00607 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,845 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00608 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,848 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00609 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,852 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00610 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,856 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00611 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,860 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00612 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,864 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00613 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,867 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00614 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,871 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00615 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,875 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00616 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,879 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00617 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,882 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00618 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,886 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00619 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,890 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00620 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,894 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00621 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,898 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00622 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,901 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00623 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,905 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00624 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,909 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00625 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,913 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00626 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,917 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00627 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,920 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00628 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,924 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00629 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,928 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00630 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,931 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00631 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,935 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00632 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,939 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00633 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,943 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00634 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,947 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00635 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,950 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00636 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,954 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00637 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,958 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00638 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,961 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00639 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,965 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00640 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,969 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00641 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,973 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00642 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,976 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00643 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,980 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00644 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,984 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00645 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,988 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00646 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,991 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00647 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,995 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00648 with 'simple' prompt is stored in the database.
2025-08-14 15:49:25,999 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00649 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,003 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00650 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,006 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00651 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,010 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00652 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,014 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00653 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,018 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00654 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,021 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00655 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,025 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00656 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,029 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00657 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,032 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00658 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,036 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00659 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,040 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00660 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,044 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00661 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,048 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00662 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,051 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00663 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,055 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00664 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,059 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00665 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,063 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00666 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,066 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00667 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,070 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00668 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,074 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00669 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,078 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00670 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,082 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00671 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,086 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00672 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,090 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00673 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,094 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00674 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,098 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00675 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,102 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00676 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,106 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00677 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,109 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00678 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,113 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00679 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,117 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00680 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,121 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00681 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,125 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00682 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,128 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00683 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,132 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00684 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,136 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00685 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,140 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00686 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,144 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00687 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,148 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00688 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,151 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00689 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,155 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00690 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,159 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00691 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,163 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00692 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,166 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00693 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,170 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00694 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,174 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00695 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,178 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00696 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,182 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00697 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,186 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00698 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,190 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00699 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,193 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00700 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,197 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00701 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,201 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00702 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,205 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00703 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,209 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00704 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,213 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00705 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,217 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00706 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,220 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00707 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,224 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00708 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,228 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00709 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,232 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00710 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,236 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00711 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,239 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00712 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,243 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00713 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,247 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00714 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,251 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00715 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,255 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00716 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,259 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00717 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,262 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00718 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,266 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00719 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,270 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00720 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,274 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00721 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,278 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00722 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,282 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00723 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,286 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00724 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,289 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00725 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,293 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00726 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,297 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00727 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,301 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00728 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,304 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00729 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,308 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00730 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,312 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00731 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,316 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00732 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,319 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00733 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,323 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00734 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,327 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00735 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,331 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00736 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,335 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00737 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,340 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00738 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,343 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00739 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,347 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00740 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,351 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00741 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,355 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00742 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,359 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00743 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,363 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00744 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,366 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00745 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,370 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00746 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,374 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00747 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,378 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00748 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,382 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00749 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,386 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00750 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,389 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00751 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,393 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00752 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,397 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00753 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,399 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00754 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,403 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00755 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,407 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00756 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,411 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00757 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,414 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00758 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,418 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00759 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,422 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00760 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,426 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00761 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,430 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00762 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,434 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00763 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,438 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00764 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,441 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00765 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,445 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00766 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,449 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00767 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,453 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00768 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,457 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00769 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,461 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00770 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,465 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00771 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,468 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00772 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,472 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00773 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,476 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00774 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,480 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00775 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,484 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00776 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,488 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00777 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,492 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00778 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,496 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00779 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,499 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00780 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,503 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00781 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,507 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00782 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,511 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00783 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,515 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00784 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,518 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00785 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,522 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00786 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,526 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00787 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,530 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00788 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,534 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00789 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,537 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00790 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,541 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00791 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,545 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00792 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,549 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00793 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,553 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00794 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,557 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00795 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,561 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00796 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,565 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00797 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,568 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00798 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,572 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00799 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,576 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00800 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,580 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00801 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,584 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00802 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,588 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00803 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,592 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00804 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,596 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00805 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,600 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00806 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,604 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00807 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,608 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00808 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,612 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00809 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,616 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00810 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,620 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00811 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,624 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00812 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,627 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00813 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,631 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00814 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,635 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00815 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,639 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00816 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,643 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00817 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,646 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00818 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,650 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00819 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,654 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00820 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,658 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00821 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,663 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00822 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,666 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00823 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,672 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00824 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,676 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00825 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,681 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00826 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,684 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00827 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,688 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00828 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,692 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00829 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,696 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00830 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,700 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00831 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,704 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00832 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,708 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00833 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,712 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00834 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,716 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00835 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,719 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00836 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,723 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00837 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,727 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00838 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,731 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00839 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,735 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00840 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,739 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00841 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,743 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00842 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,747 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00843 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,750 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00844 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,754 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00845 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,758 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00846 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,762 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00847 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,766 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00848 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,769 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00849 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,773 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00850 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,777 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00851 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,781 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00852 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,785 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00853 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,789 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00854 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,793 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00855 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,797 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00856 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,800 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00857 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,804 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00858 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,808 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00859 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,812 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00860 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,816 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00861 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,820 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00862 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,824 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00863 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,828 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00864 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,832 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00865 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,835 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00866 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,839 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00867 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,843 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00868 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,847 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00869 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,851 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00870 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,854 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00871 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,858 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00872 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,862 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00873 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,866 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00874 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,870 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00875 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,874 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00876 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,878 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00877 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,882 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00878 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,885 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00879 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,891 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00880 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,895 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00881 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,899 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00882 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,903 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00883 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,907 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00884 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,911 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00885 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,915 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00886 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,919 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00887 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,923 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00888 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,926 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00889 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,930 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00890 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,934 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00891 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,938 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00892 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,942 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00893 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,945 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00894 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,949 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00895 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,953 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00896 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,957 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00897 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,961 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00898 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,965 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00899 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,969 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00900 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,972 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00901 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,976 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00902 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,980 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00903 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,983 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00904 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,987 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00905 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,991 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00906 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,995 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00907 with 'simple' prompt is stored in the database.
2025-08-14 15:49:26,999 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00908 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,002 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00909 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,006 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00910 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,010 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00911 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,014 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00912 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,018 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00913 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,021 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00914 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,025 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00915 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,029 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00916 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,033 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00917 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,037 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00918 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,040 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00919 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,044 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00920 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,048 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00921 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,052 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00922 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,055 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00923 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,059 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00924 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,063 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00925 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,067 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00926 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,071 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00927 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,075 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00928 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,078 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00929 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,082 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00930 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,086 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00931 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,090 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00932 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,094 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00933 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,098 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00934 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,102 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00935 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,106 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00936 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,109 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00937 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,113 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00938 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,117 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00939 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,121 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00940 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,125 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00941 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,129 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00942 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,133 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00943 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,136 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00944 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,140 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00945 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,144 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00946 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,148 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00947 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,152 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00948 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,156 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00949 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,160 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00950 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,164 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00951 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,168 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00952 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,172 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00953 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,175 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00954 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,179 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00955 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,183 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00956 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,187 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00957 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,191 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00958 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,194 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00959 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,198 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00960 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,202 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00961 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,206 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00962 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,210 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00963 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,214 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00964 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,218 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00965 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,222 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00966 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,226 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00967 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,230 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00968 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,234 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00969 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,238 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00970 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,242 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00971 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,246 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00972 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,249 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00973 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,253 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00974 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,257 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00975 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,261 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00976 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,265 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00977 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,269 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00978 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,273 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00979 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,277 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00980 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,281 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00981 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,284 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00982 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,288 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00983 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,292 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00984 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,296 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00985 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,300 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00986 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,304 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00987 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,308 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00988 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,311 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00989 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,315 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00990 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,319 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00991 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,323 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00992 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,327 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00993 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,331 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00994 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,335 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00995 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,338 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00996 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,342 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00997 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,346 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00998 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,350 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest00999 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,354 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01000 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,358 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01001 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,361 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01002 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,365 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01003 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,369 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01004 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,373 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01005 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,377 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01006 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,381 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01007 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,384 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01008 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,388 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01009 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,392 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01010 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,396 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01011 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,400 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01012 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,403 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01013 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,407 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01014 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,411 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01015 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,414 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01016 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,418 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01017 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,422 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01018 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,426 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01019 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,430 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01020 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,434 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01021 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,438 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01022 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,441 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01023 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,445 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01024 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,449 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01025 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,453 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01026 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,457 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01027 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,461 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01028 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,464 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01029 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,468 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01030 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,472 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01031 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,476 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01032 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,480 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01033 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,484 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01034 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,487 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01035 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,491 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01036 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,495 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01037 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,499 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01038 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,503 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01039 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,507 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01040 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,511 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01041 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,515 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01042 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,519 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01043 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,523 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01044 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,527 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01045 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,531 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01046 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,535 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01047 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,538 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01048 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,542 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01049 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,546 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01050 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,550 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01051 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,554 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01052 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,557 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01053 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,561 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01054 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,565 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01055 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,569 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01056 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,573 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01057 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,576 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01058 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,580 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01059 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,584 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01060 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,588 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01061 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,592 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01062 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,595 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01063 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,599 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01064 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,603 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01065 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,607 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01066 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,611 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01067 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,615 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01068 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,619 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01069 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,623 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01070 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,626 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01071 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,630 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01072 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,634 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01073 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,638 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01074 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,642 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01075 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,645 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01076 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,649 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01077 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,653 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01078 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,657 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01079 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,661 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01080 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,665 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01081 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,668 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01082 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,672 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01083 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,676 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01084 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,680 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01085 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,684 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01086 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,688 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01087 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,692 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01088 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,696 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01089 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,700 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01090 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,703 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01091 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,707 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01092 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,711 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01093 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,715 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01094 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,719 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01095 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,723 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01096 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,727 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01097 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,731 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01098 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,734 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01099 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,738 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01100 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,742 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01101 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,746 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01102 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,750 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01103 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,754 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01104 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,757 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01105 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,761 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01106 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,765 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01107 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,769 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01108 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,773 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01109 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,777 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01110 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,781 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01111 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,784 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01112 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,788 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01113 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,792 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01114 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,796 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01115 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,800 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01116 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,803 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01117 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,807 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01118 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,811 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01119 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,815 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01120 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,819 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01121 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,822 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01122 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,826 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01123 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,830 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01124 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,834 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01125 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,838 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01126 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,842 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01127 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,845 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01128 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,849 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01129 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,853 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01130 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,857 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01131 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,861 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01132 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,864 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01133 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,868 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01134 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,872 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01135 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,876 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01136 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,879 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01137 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,883 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01138 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,887 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01139 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,891 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01140 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,895 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01141 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,898 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01142 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,902 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01143 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,906 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01144 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,910 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01145 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,914 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01146 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,917 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01147 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,921 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01148 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,925 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01149 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,929 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01150 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,933 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01151 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,937 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01152 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,941 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01153 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,944 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01154 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,948 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01155 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,952 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01156 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,956 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01157 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,960 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01158 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,963 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01159 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,967 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01160 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,971 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01161 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,975 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01162 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,979 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01163 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,982 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01164 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,986 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01165 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,990 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01166 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,994 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01167 with 'simple' prompt is stored in the database.
2025-08-14 15:49:27,997 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01168 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,001 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01169 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,005 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01170 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,009 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01171 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,012 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01172 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,016 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01173 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,020 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01174 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,024 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01175 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,028 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01176 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,031 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01177 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,035 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01178 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,039 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01179 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,043 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01180 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,047 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01181 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,051 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01182 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,055 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01183 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,058 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01184 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,062 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01185 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,066 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01186 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,070 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01187 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,072 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01188 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,076 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01189 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,080 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01190 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,084 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01191 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,088 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01192 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,091 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01193 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,095 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01194 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,099 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01195 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,103 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01196 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,107 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01197 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,111 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01198 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,115 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01199 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,118 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01200 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,122 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01201 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,126 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01202 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,130 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01203 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,133 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01204 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,136 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01205 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,140 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01206 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,144 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01207 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,147 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01208 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,151 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01209 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,155 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01210 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,159 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01211 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,162 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01212 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,166 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01213 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,170 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01214 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,174 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01215 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,177 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01216 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,181 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01217 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,185 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01218 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,189 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01219 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,193 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01220 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,196 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01221 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,200 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01222 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,204 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01223 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,208 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01224 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,211 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01225 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,215 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01226 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,219 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01227 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,223 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01228 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,227 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01229 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,231 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01230 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,234 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01231 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,238 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01232 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,242 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01233 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,246 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01234 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,250 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01235 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,254 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01236 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,258 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01237 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,262 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01238 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,265 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01239 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,269 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01240 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,273 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01241 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,277 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01242 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,281 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01243 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,285 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01244 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,289 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01245 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,294 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01246 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,298 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01247 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,302 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01248 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,306 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01249 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,310 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01250 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,314 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01251 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,318 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01252 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,322 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01253 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,325 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01254 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,329 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01255 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,333 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01256 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,337 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01257 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,341 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01258 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,344 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01259 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,348 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01260 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,352 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01261 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,356 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01262 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,360 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01263 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,364 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01264 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,368 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01265 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,372 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01266 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,376 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01267 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,379 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01268 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,383 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01269 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,387 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01270 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,391 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01271 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,395 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01272 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,399 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01273 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,403 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01274 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,406 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01275 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,410 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01276 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,414 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01277 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,418 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01278 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,422 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01279 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,428 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01280 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,432 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01281 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,436 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01282 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,440 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01283 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,444 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01284 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,448 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01285 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,451 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01286 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,455 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01287 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,459 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01288 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,463 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01289 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,466 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01290 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,470 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01291 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,474 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01292 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,478 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01293 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,482 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01294 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,486 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01295 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,489 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01296 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,493 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01297 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,497 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01298 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,501 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01299 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,504 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01300 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,508 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01301 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,512 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01302 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,516 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01303 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,520 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01304 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,524 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01305 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,528 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01306 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,532 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01307 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,535 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01308 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,539 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01309 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,543 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01310 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,547 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01311 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,551 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01312 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,555 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01313 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,558 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01314 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,562 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01315 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,566 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01316 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,570 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01317 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,574 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01318 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,577 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01319 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,581 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01320 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,586 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01321 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,589 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01322 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,593 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01323 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,597 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01324 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,601 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01325 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,605 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01326 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,609 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01327 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,613 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01328 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,617 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01329 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,621 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01330 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,625 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01331 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,629 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01332 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,632 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01333 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,636 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01334 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,640 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01335 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,644 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01336 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,648 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01337 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,652 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01338 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,655 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01339 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,659 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01340 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,663 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01341 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,667 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01342 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,671 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01343 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,674 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01344 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,678 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01345 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,682 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01346 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,686 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01347 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,690 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01348 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,694 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01349 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,698 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01350 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,702 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01351 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,706 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01352 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,710 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01353 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,713 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01354 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,717 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01355 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,721 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01356 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,725 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01357 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,729 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01358 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,733 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01359 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,737 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01360 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,740 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01361 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,744 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01362 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,748 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01363 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,752 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01364 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,756 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01365 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,759 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01366 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,763 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01367 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,767 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01368 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,771 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01369 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,775 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01370 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,779 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01371 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,782 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01372 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,786 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01373 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,790 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01374 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,794 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01375 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,798 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01376 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,801 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01377 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,805 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01378 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,809 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01379 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,813 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01380 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,816 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01381 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,820 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01382 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,824 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01383 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,828 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01384 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,831 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01385 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,835 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01386 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,839 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01387 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,843 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01388 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,847 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01389 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,851 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01390 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,855 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01391 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,858 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01392 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,862 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01393 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,866 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01394 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,870 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01395 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,874 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01396 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,878 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01397 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,882 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01398 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,886 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01399 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,889 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01400 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,893 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01401 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,897 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01402 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,901 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01403 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,905 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01404 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,911 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01405 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,915 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01406 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,919 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01407 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,922 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01408 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,926 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01409 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,930 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01410 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,933 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01411 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,937 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01412 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,941 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01413 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,945 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01414 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,949 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01415 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,952 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01416 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,956 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01417 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,960 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01418 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,964 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01419 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,967 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01420 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,971 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01421 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,975 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01422 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,979 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01423 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,983 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01424 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,986 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01425 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,990 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01426 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,994 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01427 with 'simple' prompt is stored in the database.
2025-08-14 15:49:28,998 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01428 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,002 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01429 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,005 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01430 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,009 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01431 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,013 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01432 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,017 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01433 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,021 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01434 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,024 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01435 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,028 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01436 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,032 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01437 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,036 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01438 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,040 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01439 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,044 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01440 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,047 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01441 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,051 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01442 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,055 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01443 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,059 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01444 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,063 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01445 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,066 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01446 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,070 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01447 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,074 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01448 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,078 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01449 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,082 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01450 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,086 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01451 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,090 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01452 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,094 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01453 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,098 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01454 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,101 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01455 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,105 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01456 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,109 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01457 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,113 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01458 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,117 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01459 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,121 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01460 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,125 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01461 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,128 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01462 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,132 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01463 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,136 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01464 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,140 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01465 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,144 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01466 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,147 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01467 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,151 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01468 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,155 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01469 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,159 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01470 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,163 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01471 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,166 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01472 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,170 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01473 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,174 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01474 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,180 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01475 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,184 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01476 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,187 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01477 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,191 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01478 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,195 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01479 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,199 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01480 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,203 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01481 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,207 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01482 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,210 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01483 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,214 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01484 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,218 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01485 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,222 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01486 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,226 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01487 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,230 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01488 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,233 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01489 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,237 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01490 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,241 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01491 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,245 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01492 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,249 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01493 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,252 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01494 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,256 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01495 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,260 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01496 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,264 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01497 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,267 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01498 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,271 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01499 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,275 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01500 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,279 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01501 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,283 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01502 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,287 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01503 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,290 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01504 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,294 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01505 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,298 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01506 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,302 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01507 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,305 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01508 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,309 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01509 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,313 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01510 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,317 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01511 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,320 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01512 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,324 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01513 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,328 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01514 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,332 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01515 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,336 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01516 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,339 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01517 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,343 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01518 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,347 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01519 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,351 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01520 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,355 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01521 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,359 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01522 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,362 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01523 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,366 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01524 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,370 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01525 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,373 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01526 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,377 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01527 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,381 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01528 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,385 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01529 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,388 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01530 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,392 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01531 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,396 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01532 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,400 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01533 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,403 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01534 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,407 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01535 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,411 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01536 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,415 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01537 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,419 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01538 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,422 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01539 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,426 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01540 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,430 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01541 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,434 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01542 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,437 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01543 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,441 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01544 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,445 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01545 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,449 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01546 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,452 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01547 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,456 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01548 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,460 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01549 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,463 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01550 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,467 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01551 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,471 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01552 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,475 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01553 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,479 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01554 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,482 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01555 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,486 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01556 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,490 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01557 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,493 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01558 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,497 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01559 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,501 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01560 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,505 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01561 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,508 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01562 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,512 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01563 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,516 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01564 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,519 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01565 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,523 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01566 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,527 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01567 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,531 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01568 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,534 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01569 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,538 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01570 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,542 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01571 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,546 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01572 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,550 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01573 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,553 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01574 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,557 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01575 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,561 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01576 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,565 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01577 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,568 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01578 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,572 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01579 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,576 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01580 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,580 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01581 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,584 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01582 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,587 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01583 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,591 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01584 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,595 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01585 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,599 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01586 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,603 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01587 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,607 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01588 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,610 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01589 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,614 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01590 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,618 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01591 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,622 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01592 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,626 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01593 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,630 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01594 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,633 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01595 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,637 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01596 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,641 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01597 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,645 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01598 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,648 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01599 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,652 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01600 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,656 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01601 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,660 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01602 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,664 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01603 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,668 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01604 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,671 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01605 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,674 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01606 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,678 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01607 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,682 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01608 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,685 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01609 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,689 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01610 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,693 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01611 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,697 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01612 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,701 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01613 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,705 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01614 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,708 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01615 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,712 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01616 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,716 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01617 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,720 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01618 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,724 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01619 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,728 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01620 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,731 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01621 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,735 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01622 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,739 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01623 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,743 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01624 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,747 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01625 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,750 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01626 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,754 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01627 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,758 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01628 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,762 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01629 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,766 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01630 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,769 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01631 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,773 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01632 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,777 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01633 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,781 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01634 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,785 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01635 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,788 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01636 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,792 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01637 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,796 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01638 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,800 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01639 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,804 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01640 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,807 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01641 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,811 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01642 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,815 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01643 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,819 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01644 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,823 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01645 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,826 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01646 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,830 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01647 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,834 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01648 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,838 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01649 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,842 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01650 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,845 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01651 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,849 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01652 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,853 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01653 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,857 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01654 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,861 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01655 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,864 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01656 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,868 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01657 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,872 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01658 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,876 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01659 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,879 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01660 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,883 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01661 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,887 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01662 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,891 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01663 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,895 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01664 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,898 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01665 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,902 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01666 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,906 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01667 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,910 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01668 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,913 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01669 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,917 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01670 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,921 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01671 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,925 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01672 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,928 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01673 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,932 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01674 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,936 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01675 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,940 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01676 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,944 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01677 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,948 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01678 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,952 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01679 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,955 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01680 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,959 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01681 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,963 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01682 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,967 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01683 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,970 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01684 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,974 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01685 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,978 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01686 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,982 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01687 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,986 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01688 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,990 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01689 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,993 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01690 with 'simple' prompt is stored in the database.
2025-08-14 15:49:29,997 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01691 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,001 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01692 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,005 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01693 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,009 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01694 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,012 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01695 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,016 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01696 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,020 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01697 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,024 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01698 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,028 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01699 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,031 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01700 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,036 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01701 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,039 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01702 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,043 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01703 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,047 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01704 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,051 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01705 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,055 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01706 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,059 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01707 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,062 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01708 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,066 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01709 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,070 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01710 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,074 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01711 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,078 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01712 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,082 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01713 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,086 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01714 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,090 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01715 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,094 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01716 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,097 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01717 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,101 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01718 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,105 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01719 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,109 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01720 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,113 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01721 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,117 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01722 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,121 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01723 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,124 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01724 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,128 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01725 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,132 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01726 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,136 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01727 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,140 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01728 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,144 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01729 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,147 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01730 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,151 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01731 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,155 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01732 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,159 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01733 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,163 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01734 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,166 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01735 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,170 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01736 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,174 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01737 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,178 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01738 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,182 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01739 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,185 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01740 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,189 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01741 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,193 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01742 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,197 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01743 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,201 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01744 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,204 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01745 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,208 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01746 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,212 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01747 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,216 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01748 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,219 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01749 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,223 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01750 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,227 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01751 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,231 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01752 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,235 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01753 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,238 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01754 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,242 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01755 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,246 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01756 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,250 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01757 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,254 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01758 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,258 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01759 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,262 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01760 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,265 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01761 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,269 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01762 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,273 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01763 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,277 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01764 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,281 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01765 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,284 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01766 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,288 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01767 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,292 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01768 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,296 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01769 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,300 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01770 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,304 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01771 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,307 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01772 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,311 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01773 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,315 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01774 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,319 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01775 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,322 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01776 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,326 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01777 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,330 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01778 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,334 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01779 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,337 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01780 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,341 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01781 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,345 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01782 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,349 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01783 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,353 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01784 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,356 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01785 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,360 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01786 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,364 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01787 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,368 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01788 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,372 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01789 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,375 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01790 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,379 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01791 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,383 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01792 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,387 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01793 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,391 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01794 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,394 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01795 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,398 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01796 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,402 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01797 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,406 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01798 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,409 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01799 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,413 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01800 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,417 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01801 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,421 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01802 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,429 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01803 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,432 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01804 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,436 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01805 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,440 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01806 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,444 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01807 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,448 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01808 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,451 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01809 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,455 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01810 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,459 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01811 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,463 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01812 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,467 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01813 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,471 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01814 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,475 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01815 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,479 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01816 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,482 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01817 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,486 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01818 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,490 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01819 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,494 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01820 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,498 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01821 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,501 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01822 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,505 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01823 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,509 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01824 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,513 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01825 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,517 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01826 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,520 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01827 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,524 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01828 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,528 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01829 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,532 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01830 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,536 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01831 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,540 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01832 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,544 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01833 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,548 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01834 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,551 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01835 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,555 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01836 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,559 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01837 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,563 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01838 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,566 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01839 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,570 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01840 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,574 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01841 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,578 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01842 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,582 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01843 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,586 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01844 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,590 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01845 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,593 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01846 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,597 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01847 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,601 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01848 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,605 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01849 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,609 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01850 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,613 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01851 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,617 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01852 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,621 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01853 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,625 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01854 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,629 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01855 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,633 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01856 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,636 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01857 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,640 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01858 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,644 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01859 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,648 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01860 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,652 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01861 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,655 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01862 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,659 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01863 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,663 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01864 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,667 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01865 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,671 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01866 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,675 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01867 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,679 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01868 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,683 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01869 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,687 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01870 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,690 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01871 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,694 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01872 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,698 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01873 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,702 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01874 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,706 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01875 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,710 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01876 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,714 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01877 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,718 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01878 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,722 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01879 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,726 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01880 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,729 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01881 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,733 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01882 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,737 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01883 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,741 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01884 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,745 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01885 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,749 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01886 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,752 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01887 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,756 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01888 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,760 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01889 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,764 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01890 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,768 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01891 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,772 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01892 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,776 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01893 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,779 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01894 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,783 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01895 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,787 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01896 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,791 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01897 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,795 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01898 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,798 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01899 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,802 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01900 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,806 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01901 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,809 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01902 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,813 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01903 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,817 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01904 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,821 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01905 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,825 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01906 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,828 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01907 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,832 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01908 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,836 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01909 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,840 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01910 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,844 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01911 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,847 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01912 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,851 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01913 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,854 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01914 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,858 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01915 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,862 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01916 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,865 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01917 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,869 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01918 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,873 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01919 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,877 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01920 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,881 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01921 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,884 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01922 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,888 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01923 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,892 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01924 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,895 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01925 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,899 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01926 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,903 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01927 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,907 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01928 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,911 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01929 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,915 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01930 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,918 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01931 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,922 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01932 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,926 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01933 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,930 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01934 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,934 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01935 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,938 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01936 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,942 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01937 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,946 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01938 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,949 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01939 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,952 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01940 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,956 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01941 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,959 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01942 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,963 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01943 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,967 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01944 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,971 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01945 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,975 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01946 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,978 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01947 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,982 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01948 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,986 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01949 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,990 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01950 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,994 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01951 with 'simple' prompt is stored in the database.
2025-08-14 15:49:30,998 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01952 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,001 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01953 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,005 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01954 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,009 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01955 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,013 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01956 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,017 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01957 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,020 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01958 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,024 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01959 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,028 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01960 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,032 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01961 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,036 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01962 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,040 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01963 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,044 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01964 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,048 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01965 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,052 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01966 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,056 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01967 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,060 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01968 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,064 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01969 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,068 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01970 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,071 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01971 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,075 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01972 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,079 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01973 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,083 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01974 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,087 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01975 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,091 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01976 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,095 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01977 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,099 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01978 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,103 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01979 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,107 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01980 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,111 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01981 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,115 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01982 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,119 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01983 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,123 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01984 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,126 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01985 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,130 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01986 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,134 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01987 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,138 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01988 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,142 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01989 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,146 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01990 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,150 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01991 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,154 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01992 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,157 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01993 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,161 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01994 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,165 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01995 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,169 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01996 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,173 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01997 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,176 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01998 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,180 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest01999 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,184 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02000 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,188 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02001 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,192 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02002 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,196 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02003 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,200 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02004 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,204 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02005 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,208 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02006 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,211 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02007 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,215 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02008 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,219 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02009 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,223 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02010 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,227 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02011 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,231 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02012 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,235 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02013 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,239 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02014 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,243 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02015 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,247 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02016 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,251 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02017 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,255 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02018 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,258 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02019 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,262 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02020 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,266 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02021 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,270 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02022 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,274 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02023 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,278 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02024 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,282 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02025 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,286 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02026 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,290 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02027 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,294 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02028 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,298 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02029 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,302 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02030 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,307 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02031 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,311 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02032 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,315 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02033 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,319 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02034 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,322 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02035 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,326 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02036 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,330 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02037 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,334 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02038 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,338 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02039 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,342 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02040 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,346 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02041 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,350 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02042 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,354 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02043 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,357 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02044 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,361 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02045 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,365 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02046 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,368 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02047 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,372 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02048 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,376 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02049 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,380 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02050 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,384 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02051 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,387 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02052 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,391 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02053 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,395 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02054 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,399 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02055 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,403 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02056 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,407 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02057 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,410 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02058 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,414 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02059 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,418 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02060 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,422 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02061 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,426 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02062 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,430 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02063 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,434 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02064 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,437 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02065 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,441 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02066 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,445 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02067 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,449 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02068 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,453 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02069 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,457 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02070 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,461 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02071 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,464 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02072 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,468 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02073 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,472 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02074 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,476 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02075 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,480 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02076 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,483 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02077 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,487 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02078 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,491 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02079 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,495 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02080 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,499 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02081 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,502 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02082 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,506 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02083 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,510 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02084 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,514 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02085 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,518 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02086 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,521 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02087 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,525 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02088 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,529 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02089 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,533 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02090 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,537 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02091 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,541 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02092 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,545 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02093 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,549 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02094 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,553 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02095 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,557 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02096 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,561 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02097 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,565 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02098 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,568 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02099 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,572 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02100 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,576 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02101 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,580 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02102 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,584 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02103 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,588 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02104 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,591 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02105 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,595 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02106 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,599 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02107 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,603 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02108 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,607 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02109 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,611 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02110 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,615 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02111 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,619 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02112 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,622 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02113 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,626 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02114 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,630 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02115 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,634 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02116 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,638 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02117 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,642 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02118 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,645 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02119 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,649 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02120 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,653 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02121 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,657 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02122 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,661 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02123 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,664 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02124 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,668 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02125 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,672 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02126 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,676 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02127 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,680 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02128 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,684 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02129 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,688 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02130 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,691 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02131 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,695 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02132 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,699 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02133 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,703 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02134 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,706 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02135 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,710 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02136 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,715 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02137 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,718 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02138 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,723 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02139 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,727 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02140 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,731 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02141 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,735 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02142 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,739 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02143 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,743 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02144 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,746 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02145 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,750 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02146 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,754 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02147 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,758 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02148 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,762 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02149 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,766 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02150 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,770 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02151 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,774 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02152 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,777 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02153 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,780 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02154 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,784 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02155 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,788 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02156 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,792 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02157 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,795 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02158 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,799 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02159 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,803 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02160 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,807 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02161 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,811 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02162 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,815 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02163 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,819 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02164 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,822 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02165 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,826 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02166 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,829 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02167 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,833 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02168 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,837 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02169 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,841 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02170 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,845 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02171 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,849 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02172 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,852 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02173 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,856 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02174 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,860 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02175 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,864 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02176 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,867 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02177 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,871 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02178 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,875 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02179 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,879 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02180 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,883 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02181 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,886 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02182 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,890 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02183 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,894 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02184 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,898 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02185 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,902 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02186 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,906 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02187 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,910 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02188 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,914 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02189 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,918 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02190 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,922 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02191 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,926 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02192 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,930 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02193 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,933 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02194 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,937 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02195 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,941 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02196 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,945 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02197 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,949 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02198 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,953 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02199 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,956 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02200 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,960 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02201 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,964 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02202 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,968 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02203 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,972 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02204 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,976 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02205 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,979 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02206 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,983 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02207 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,987 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02208 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,991 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02209 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,994 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02210 with 'simple' prompt is stored in the database.
2025-08-14 15:49:31,998 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02211 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,002 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02212 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,006 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02213 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,010 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02214 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,013 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02215 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,018 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02216 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,021 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02217 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,025 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02218 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,029 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02219 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,033 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02220 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,037 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02221 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,041 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02222 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,044 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02223 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,048 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02224 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,052 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02225 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,056 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02226 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,060 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02227 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,064 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02228 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,067 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02229 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,071 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02230 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,075 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02231 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,079 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02232 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,083 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02233 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,087 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02234 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,090 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02235 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,094 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02236 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,098 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02237 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,102 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02238 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,106 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02239 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,110 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02240 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,114 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02241 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,118 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02242 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,122 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02243 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,126 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02244 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,130 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02245 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,133 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02246 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,137 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02247 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,141 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02248 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,145 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02249 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,149 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02250 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,153 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02251 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,157 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02252 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,161 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02253 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,164 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02254 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,168 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02255 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,172 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02256 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,176 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02257 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,179 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02258 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,183 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02259 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,187 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02260 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,191 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02261 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,195 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02262 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,199 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02263 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,203 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02264 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,207 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02265 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,210 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02266 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,214 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02267 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,218 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02268 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,222 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02269 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,226 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02270 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,229 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02271 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,232 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02272 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,236 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02273 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,240 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02274 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,244 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02275 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,248 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02276 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,252 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02277 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,255 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02278 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,259 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02279 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,263 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02280 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,267 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02281 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,271 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02282 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,274 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02283 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,278 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02284 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,282 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02285 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,286 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02286 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,290 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02287 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,294 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02288 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,297 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02289 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,301 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02290 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,305 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02291 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,309 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02292 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,313 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02293 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,316 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02294 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,320 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02295 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,324 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02296 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,328 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02297 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,332 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02298 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,336 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02299 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,340 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02300 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,344 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02301 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,347 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02302 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,351 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02303 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,355 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02304 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,359 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02305 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,363 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02306 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,366 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02307 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,370 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02308 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,374 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02309 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,377 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02310 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,381 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02311 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,385 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02312 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,388 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02313 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,392 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02314 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,396 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02315 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,400 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02316 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,404 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02317 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,408 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02318 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,412 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02319 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,416 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02320 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,420 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02321 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,424 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02322 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,427 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02323 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,431 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02324 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,435 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02325 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,439 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02326 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,443 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02327 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,447 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02328 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,450 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02329 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,454 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02330 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,458 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02331 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,462 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02332 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,466 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02333 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,469 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02334 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,473 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02335 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,477 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02336 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,481 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02337 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,485 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02338 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,489 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02339 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,493 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02340 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,497 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02341 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,500 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02342 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,504 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02343 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,508 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02344 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,512 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02345 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,516 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02346 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,520 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02347 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,523 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02348 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,527 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02349 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,531 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02350 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,535 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02351 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,539 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02352 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,543 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02353 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,547 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02354 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,551 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02355 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,555 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02356 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,559 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02357 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,563 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02358 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,567 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02359 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,570 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02360 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,574 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02361 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,578 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02362 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,582 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02363 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,586 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02364 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,589 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02365 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,593 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02366 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,597 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02367 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,601 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02368 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,605 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02369 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,609 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02370 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,613 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02371 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,617 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02372 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,620 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02373 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,624 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02374 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,628 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02375 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,632 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02376 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,636 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02377 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,640 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02378 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,643 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02379 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,647 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02380 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,651 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02381 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,655 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02382 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,659 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02383 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,662 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02384 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,666 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02385 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,670 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02386 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,674 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02387 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,678 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02388 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,682 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02389 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,686 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02390 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,689 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02391 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,693 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02392 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,697 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02393 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,701 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02394 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,705 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02395 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,709 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02396 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,712 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02397 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,716 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02398 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,720 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02399 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,724 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02400 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,728 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02401 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,731 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02402 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,735 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02403 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,739 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02404 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,743 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02405 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,747 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02406 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,751 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02407 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,755 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02408 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,758 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02409 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,762 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02410 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,766 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02411 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,770 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02412 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,773 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02413 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,777 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02414 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,781 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02415 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,785 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02416 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,788 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02417 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,792 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02418 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,796 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02419 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,800 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02420 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,803 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02421 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,807 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02422 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,811 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02423 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,815 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02424 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,819 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02425 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,823 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02426 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,826 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02427 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,830 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02428 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,834 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02429 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,838 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02430 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,842 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02431 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,846 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02432 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,850 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02433 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,854 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02434 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,858 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02435 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,862 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02436 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,866 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02437 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,870 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02438 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,873 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02439 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,877 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02440 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,881 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02441 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,885 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02442 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,889 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02443 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,893 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02444 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,896 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02445 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,900 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02446 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,904 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02447 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,909 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02448 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,913 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02449 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,917 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02450 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,921 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02451 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,924 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02452 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,928 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02453 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,932 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02454 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,936 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02455 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,940 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02456 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,944 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02457 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,948 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02458 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,951 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02459 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,955 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02460 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,959 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02461 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,963 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02462 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,967 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02463 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,971 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02464 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,974 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02465 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,978 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02466 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,982 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02467 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,986 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02468 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,990 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02469 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,994 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02470 with 'simple' prompt is stored in the database.
2025-08-14 15:49:32,998 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02471 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,002 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02472 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,006 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02473 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,010 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02474 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,014 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02475 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,017 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02476 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,021 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02477 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,025 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02478 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,029 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02479 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,032 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02480 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,036 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02481 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,040 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02482 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,044 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02483 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,047 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02484 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,051 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02485 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,055 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02486 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,059 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02487 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,063 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02488 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,067 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02489 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,070 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02490 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,075 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02491 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,079 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02492 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,082 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02493 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,086 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02494 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,090 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02495 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,094 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02496 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,098 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02497 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,102 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02498 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,106 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02499 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,110 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02500 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,114 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02501 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,118 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02502 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,122 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02503 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,126 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02504 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,129 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02505 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,133 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02506 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,137 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02507 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,141 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02508 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,145 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02509 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,149 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02510 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,153 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02511 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,157 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02512 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,161 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02513 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,165 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02514 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,168 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02515 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,172 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02516 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,176 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02517 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,180 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02518 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,184 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02519 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,188 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02520 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,192 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02521 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,196 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02522 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,199 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02523 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,203 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02524 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,207 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02525 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,211 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02526 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,215 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02527 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,219 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02528 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,223 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02529 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,227 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02530 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,230 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02531 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,234 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02532 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,238 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02533 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,242 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02534 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,246 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02535 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,250 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02536 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,254 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02537 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,258 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02538 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,262 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02539 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,266 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02540 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,269 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02541 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,273 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02542 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,277 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02543 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,281 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02544 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,285 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02545 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,289 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02546 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,293 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02547 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,297 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02548 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,301 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02549 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,305 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02550 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,308 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02551 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,312 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02552 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,316 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02553 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,320 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02554 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,324 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02555 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,328 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02556 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,331 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02557 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,335 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02558 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,339 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02559 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,343 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02560 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,347 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02561 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,350 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02562 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,354 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02563 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,358 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02564 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,362 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02565 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,366 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02566 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,370 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02567 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,373 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02568 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,377 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02569 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,381 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02570 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,385 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02571 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,388 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02572 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,392 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02573 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,396 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02574 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,400 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02575 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,404 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02576 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,408 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02577 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,412 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02578 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,416 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02579 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,420 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02580 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,424 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02581 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,428 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02582 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,432 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02583 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,436 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02584 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,439 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02585 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,443 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02586 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,447 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02587 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,451 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02588 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,455 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02589 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,459 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02590 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,463 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02591 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,467 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02592 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,470 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02593 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,474 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02594 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,478 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02595 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,482 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02596 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,486 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02597 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,489 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02598 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,494 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02599 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,497 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02600 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,501 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02601 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,505 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02602 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,509 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02603 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,513 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02604 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,517 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02605 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,520 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02606 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,524 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02607 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,528 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02608 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,532 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02609 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,536 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02610 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,540 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02611 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,543 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02612 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,547 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02613 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,551 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02614 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,555 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02615 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,559 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02616 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,563 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02617 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,566 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02618 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,570 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02619 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,574 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02620 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,578 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02621 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,581 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02622 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,585 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02623 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,589 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02624 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,593 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02625 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,597 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02626 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,601 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02627 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,605 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02628 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,608 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02629 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,612 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02630 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,616 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02631 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,620 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02632 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,624 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02633 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,628 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02634 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,631 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02635 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,635 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02636 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,639 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02637 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,643 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02638 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,647 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02639 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,650 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02640 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,654 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02641 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,658 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02642 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,662 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02643 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,666 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02644 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,670 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02645 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,673 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02646 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,677 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02647 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,681 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02648 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,685 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02649 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,689 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02650 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,693 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02651 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,697 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02652 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,701 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02653 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,705 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02654 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,709 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02655 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,712 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02656 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,716 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02657 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,720 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02658 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,724 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02659 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,728 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02660 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,732 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02661 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,736 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02662 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,740 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02663 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,743 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02664 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,747 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02665 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,751 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02666 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,755 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02667 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,759 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02668 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,763 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02669 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,767 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02670 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,770 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02671 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,774 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02672 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,778 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02673 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,782 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02674 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,786 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02675 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,790 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02676 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,793 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02677 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,797 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02678 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,801 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02679 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,805 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02680 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,809 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02681 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,813 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02682 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,816 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02683 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,820 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02684 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,824 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02685 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,828 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02686 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,832 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02687 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,836 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02688 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,840 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02689 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,844 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02690 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,847 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02691 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,851 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02692 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,855 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02693 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,859 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02694 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,863 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02695 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,867 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02696 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,871 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02697 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,874 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02698 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,878 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02699 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,882 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02700 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,886 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02701 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,889 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02702 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,893 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02703 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,897 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02704 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,901 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02705 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,905 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02706 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,908 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02707 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,912 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02708 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,916 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02709 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,920 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02710 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,924 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02711 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,928 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02712 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,931 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02713 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,935 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02714 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,939 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02715 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,943 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02716 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,947 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02717 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,951 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02718 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,955 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02719 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,959 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02720 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,962 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02721 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,966 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02722 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,970 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02723 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,974 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02724 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,978 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02725 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,982 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02726 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,985 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02727 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,989 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02728 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,993 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02729 with 'simple' prompt is stored in the database.
2025-08-14 15:49:33,997 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02730 with 'simple' prompt is stored in the database.
2025-08-14 15:49:34,000 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02731 with 'simple' prompt is stored in the database.
2025-08-14 15:49:34,004 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02732 with 'simple' prompt is stored in the database.
2025-08-14 15:49:34,008 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02733 with 'simple' prompt is stored in the database.
2025-08-14 15:49:34,012 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02734 with 'simple' prompt is stored in the database.
2025-08-14 15:49:34,016 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02735 with 'simple' prompt is stored in the database.
2025-08-14 15:49:34,019 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02736 with 'simple' prompt is stored in the database.
2025-08-14 15:49:34,023 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02737 with 'simple' prompt is stored in the database.
2025-08-14 15:49:34,026 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02738 with 'simple' prompt is stored in the database.
2025-08-14 15:49:34,030 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02739 with 'simple' prompt is stored in the database.
2025-08-14 15:49:34,034 - Controller - INFO - A response by o3-mini-2025-01-31 for BenchmarkTest02740 with 'simple' prompt is stored in the database.
2025-08-14 15:49:34,035 - Controller - INFO - Generating reports for Experiment-exp11 based on LLM responses for 'simple' prompt.
2025-08-14 15:49:34,062 - VulnerabilityEvaluator - INFO - Evaluating model: o3-mini-2025-01-31
2025-08-14 15:49:34,101 - VulnerabilityEvaluator - WARNING - Unknown or invalid labels found in the predicted labels.
2025-08-14 15:49:34,181 - VulnerabilityEvaluator - WARNING - Unknown or invalid labels found in the predicted labels.
2025-08-14 15:49:34,263 - VulnerabilityEvaluator - INFO - Evaluation completed successfully.
2025-08-14 15:49:34,264 - VuLLMBench - INFO - Experiment exp11 finished.
